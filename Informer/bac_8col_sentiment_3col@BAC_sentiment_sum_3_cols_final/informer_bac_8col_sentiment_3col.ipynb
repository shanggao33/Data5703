{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Nov  7 13:05:20 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   32C    P0    48W / 250W |   4264MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1064      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1180      G   /usr/bin/gnome-shell               13MiB |\n","|    0   N/A  N/A      3399      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      3469      C   ...sean/anaconda3/bin/python     2594MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'BAC_sentiment_sum_3_cols_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 8 # encoder input size\n","args.dec_in = 8 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'BAC_sentiment_sum_3_cols_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 8, 'dec_in': 8, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 950\n","val 164\n","test 339\n","Epoch: 1 cost time: 8.604240894317627\n","Epoch: 1, Steps: 29 | Train Loss: 0.4314204 Vali Loss: 0.0946245 Test Loss: 0.1858555\n","Validation loss decreased (inf --> 0.094625).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 41.11312747001648\n","Epoch: 2, Steps: 29 | Train Loss: 0.0639277 Vali Loss: 0.0970057 Test Loss: 0.1394220\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 7.425880432128906\n","Epoch: 3, Steps: 29 | Train Loss: 0.0485241 Vali Loss: 0.1036544 Test Loss: 0.1453829\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 7.435367822647095\n","Epoch: 4, Steps: 29 | Train Loss: 0.0439036 Vali Loss: 0.1095293 Test Loss: 0.1587383\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 7.4625465869903564\n","Epoch: 5, Steps: 29 | Train Loss: 0.0421295 Vali Loss: 0.0917470 Test Loss: 0.1295397\n","Validation loss decreased (0.094625 --> 0.091747).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 7.4347288608551025\n","Epoch: 6, Steps: 29 | Train Loss: 0.0412426 Vali Loss: 0.0919812 Test Loss: 0.1266471\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 7.408282995223999\n","Epoch: 7, Steps: 29 | Train Loss: 0.0396755 Vali Loss: 0.0920939 Test Loss: 0.1233138\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 7.423267602920532\n","Epoch: 8, Steps: 29 | Train Loss: 0.0387721 Vali Loss: 0.0915206 Test Loss: 0.1241241\n","Validation loss decreased (0.091747 --> 0.091521).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 7.423125505447388\n","Epoch: 9, Steps: 29 | Train Loss: 0.0383919 Vali Loss: 0.0911579 Test Loss: 0.1235749\n","Validation loss decreased (0.091521 --> 0.091158).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 7.434683084487915\n","Epoch: 10, Steps: 29 | Train Loss: 0.0405464 Vali Loss: 0.0909253 Test Loss: 0.1240521\n","Validation loss decreased (0.091158 --> 0.090925).  Saving model ...\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 7.421272039413452\n","Epoch: 11, Steps: 29 | Train Loss: 0.0387018 Vali Loss: 0.0908353 Test Loss: 0.1247103\n","Validation loss decreased (0.090925 --> 0.090835).  Saving model ...\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 7.42021369934082\n","Epoch: 12, Steps: 29 | Train Loss: 0.0385672 Vali Loss: 0.0906574 Test Loss: 0.1241106\n","Validation loss decreased (0.090835 --> 0.090657).  Saving model ...\n","Updating learning rate to 4.8828125e-08\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 339\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.124110646545887, mae:0.2636837959289551, smape:0.25827986001968384\n"]}],"source":["\n","Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.3276001],\n","        [1.7342336],\n","        [1.712955 ],\n","        [1.6518412],\n","        [1.8256332],\n","        [1.7072992],\n","        [1.7010602],\n","        [1.7172425],\n","        [1.6551344],\n","        [1.764515 ],\n","        [1.6964965],\n","        [1.7022215],\n","        [1.5982996],\n","        [1.3947043]]], dtype=float32)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([2.1674738, 2.1903505, 2.0731077, 2.1674738, 2.144597 , 2.2389634,\n","       2.2303843, 2.3047333, 2.3905213, 2.2303843, 2.2275252, 2.4648705,\n","       2.5735343, 2.4963255], dtype=float32)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([1.250549 , 1.2239529, 1.2424566, 1.2140313, 1.2294741, 1.2744436,\n","       1.2695707, 1.2096759, 1.2521793, 1.1759554, 1.2449058, 1.2706612,\n","       1.1406585, 1.1288729], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(preds[:, -1, :], label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[{"name":"stdout","output_type":"stream","text":["1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.04462496083571984\n","Smape of Informer:  0.03192511435852118\n","Smape of Ensemble:  0.02824617074690291\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./BAC_sentiment_sum_3_cols_final.npy')\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (lstm_preds + informer_preds) / 2\n","ensemble_preds.shape\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
