{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Nov 13 03:47:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   20C    P8     8W / 250W |    112MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1023      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1138      G   /usr/bin/gnome-shell               13MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape\n","\n","# def divide_no_nan(a, b):\n","#     \"\"\"\n","#     Auxiliary funtion to handle divide by 0\n","#     \"\"\"\n","#     div = a / b\n","#     div[div != div] = 0.0\n","#     div[div == float('inf')] = 0.0\n","#     return div\n","\n","# def SMAPELoss(y, y_hat, mask=None):\n","#     \"\"\"SMAPE2 Loss\n","#     Parameters\n","#     ----------\n","#     y: tensor (batch_size, output_size)\n","#         actual values in torch tensor.\n","#     y_hat: tensor (batch_size, output_size)\n","#         predicted values in torch tensor.\n","\n","#     \"\"\"\n","#     if mask is None:\n","#         mask = torch.ones(y_hat.size())\n","#     delta_y = torch.abs((y - y_hat))\n","#     scale = torch.abs(y) + torch.abs(y_hat)\n","#     smape = divide_no_nan(delta_y, scale)\n","#     smape = smape * mask\n","#     smape = 2 * torch.mean(smape)\n","#     return "]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                e_layers, # self.args.e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# df_bac_indicators = pd.read_csv('/home/sean/5703/informer/data/bac_full_indicators.csv')\n","\n","# df_bac_sentiment = pd.read_csv('/home/sean/5703/informer/data/BAC_with_sentiment_1762_rows.csv')\n","\n","# # drop open, close, high, low, volume in df_bac_sentiment\n","# df_bac_sentiment = df_bac_sentiment.drop(['open', 'close', 'high', 'low', 'volume'], axis=1)\n","\n","\n","# # merge df_bac_indicators and df_bac_sentiment\n","# df_bac_sent_ind = pd.merge(df_bac_indicators, df_bac_sentiment, on='date')\n","\n","# df_bac_sent_ind.to_csv('/home/sean/5703/informer/data/bac_sent_ind.csv', index=False)\n","\n","#-----------------------------------------------------------#\n","# df_bac_sent_ind = pd.read_csv('/home/sean/5703/informer/data/bac_sent_ind.csv')\n","# # move the column 'Close' to the last column\n","# cols = list(df_bac_sent_ind.columns.values)\n","# cols.pop(cols.index('close'))\n","# df_bac_sent_ind = df_bac_sent_ind[cols+['close']]\n","# df_bac_sent_ind.to_csv('/home/sean/5703/informer/data/bac_sent_ind.csv', index=False)\n","\n","#-----------------------------------------------------------#\n","# df_bac_sent_3c = pd.read_csv('/home/sean/5703/dataset/BAC_sentiment_sum_3_cols_final.csv')\n","# df_bac_sent_ind = pd.read_csv('/home/sean/5703/informer/data/bac_sent_ind.csv')\n","# df_bac_sent_3c = df_bac_sent_3c.drop(['open', 'close', 'high', 'low', 'volume'], axis=1)\n","# df_bac_sent_ind = pd.merge(df_bac_sent_ind, df_bac_sent_3c, on='date')\n","\n","# # move close to the last column\n","# cols = list(df_bac_sent_ind.columns.values)\n","# cols.pop(cols.index('close'))\n","# df_bac_sent_ind = df_bac_sent_ind[cols+['close']]\n","# df_bac_sent_ind.to_csv('/home/sean/5703/dataset/bac_sent_indi_22c.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'bac_sent_indi_22c.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns minus 1\n","args.enc_in = 21 # encoder input size\n","args.dec_in = 21 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 2048 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 # num of encoder layers\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32\n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'bac_sent_indi_22c.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 21, 'dec_in': 21, 'c_out': 1, 'factor': 5, 'd_model': 2048, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import random\n","def seed_everything(seed: int):   \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm2048_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 952\n","val 164\n","test 340\n","Epoch: 1 cost time: 17.68836998939514\n","Epoch: 1, Steps: 29 | Train Loss: 0.8486336 Vali Loss: 0.1263875 Test Loss: 0.1910199\n","Validation loss decreased (inf --> 0.126387).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 17.560808658599854\n","Epoch: 2, Steps: 29 | Train Loss: 0.0598857 Vali Loss: 0.0656137 Test Loss: 0.1059907\n","Validation loss decreased (0.126387 --> 0.065614).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 17.565348625183105\n","Epoch: 3, Steps: 29 | Train Loss: 0.0407485 Vali Loss: 0.0632660 Test Loss: 0.1144468\n","Validation loss decreased (0.065614 --> 0.063266).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 17.58327627182007\n","Epoch: 4, Steps: 29 | Train Loss: 0.0352405 Vali Loss: 0.0611218 Test Loss: 0.1015894\n","Validation loss decreased (0.063266 --> 0.061122).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 17.59481120109558\n","Epoch: 5, Steps: 29 | Train Loss: 0.0316822 Vali Loss: 0.0578367 Test Loss: 0.1005196\n","Validation loss decreased (0.061122 --> 0.057837).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 17.625848293304443\n","Epoch: 6, Steps: 29 | Train Loss: 0.0314548 Vali Loss: 0.0585853 Test Loss: 0.1041991\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 17.600709915161133\n","Epoch: 7, Steps: 29 | Train Loss: 0.0317079 Vali Loss: 0.0578233 Test Loss: 0.1020238\n","Validation loss decreased (0.057837 --> 0.057823).  Saving model ...\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 17.589781045913696\n","Epoch: 8, Steps: 29 | Train Loss: 0.0303747 Vali Loss: 0.0576376 Test Loss: 0.1005696\n","Validation loss decreased (0.057823 --> 0.057638).  Saving model ...\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 17.586604595184326\n","Epoch: 9, Steps: 29 | Train Loss: 0.0297167 Vali Loss: 0.0562046 Test Loss: 0.1027513\n","Validation loss decreased (0.057638 --> 0.056205).  Saving model ...\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 17.60668158531189\n","Epoch: 10, Steps: 29 | Train Loss: 0.0307556 Vali Loss: 0.0568723 Test Loss: 0.1009382\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 1.953125e-07\n","Epoch: 11 cost time: 17.599052667617798\n","Epoch: 11, Steps: 29 | Train Loss: 0.0299281 Vali Loss: 0.0579440 Test Loss: 0.1022755\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 9.765625e-08\n","Epoch: 12 cost time: 17.58289647102356\n","Epoch: 12, Steps: 29 | Train Loss: 0.0306493 Vali Loss: 0.0571199 Test Loss: 0.1010941\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 4.8828125e-08\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm2048_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.10275130718946457, mae:0.23879972100257874, smape:0.3183121383190155\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[],"source":["# prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([1.5105506 , 1.4333572 , 1.4619476 , 1.4848195 , 1.5048324 ,\n","       1.4819605 , 1.4162029 , 1.2046365 , 1.0273784 , 0.79579896,\n","       0.78722197, 1.0159421 , 1.1245849 , 1.1017128 ], dtype=float32)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trues[0,:,-1]"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([1.3330501, 1.4712355, 1.4433161, 1.4959508, 1.3305272, 1.4968305,\n","       1.2630888, 1.3055446, 1.4039356, 1.4012908, 1.5198234, 1.4387447,\n","       1.2462567, 0.9582638], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["preds[0,:,-1,]"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(preds[:, -1, :], label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.08039283107950708\n","Smape of Informer:  0.0220893164649259\n","Smape of Ensemble:  0.025419686506412707\n"]}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./bac_sent_indi_22c.npy')\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","# ensemble_preds = (0.4*lstm_preds + 1.6*informer_preds) / 2\n","lstm_var = np.var(lstm_preds)\n","informer_var = np.var(informer_preds)\n","lstm_wgt = (1/lstm_var) / ((1/lstm_var)+(1/informer_var))\n","informer_wgt = (1/informer_var) / ((1/lstm_var)+(1/informer_var))\n","ensemble_preds = (lstm_wgt*lstm_preds + (informer_wgt+1)*informer_preds)/2\n","ensemble_preds.shape\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
