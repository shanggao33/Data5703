{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Nov  6 19:36:33 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   19C    P8     8W / 250W |    112MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1059      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1174      G   /usr/bin/gnome-shell               13MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.6)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# pf = pd.read_csv('../../../../5703/dataset/finbert_likes_sum_final.csv')\n","# pf"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'finbert_likes_sum_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 8 # encoder input size\n","args.dec_in = 8 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 512 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../../../5703/dataset', 'data_path': 'finbert_likes_sum_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 8, 'dec_in': 8, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 512, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df512_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 776\n","val 340\n","test 340\n","Epoch: 1 cost time: 5.361479759216309\n","Epoch: 1, Steps: 24 | Train Loss: 0.3111782 Vali Loss: 0.0986279 Test Loss: 0.2033761\n","Validation loss decreased (inf --> 0.098628).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 5.267864227294922\n","Epoch: 2, Steps: 24 | Train Loss: 0.0836811 Vali Loss: 0.0747510 Test Loss: 0.2021499\n","Validation loss decreased (0.098628 --> 0.074751).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 5.270212888717651\n","Epoch: 3, Steps: 24 | Train Loss: 0.0560226 Vali Loss: 0.0635892 Test Loss: 0.1542582\n","Validation loss decreased (0.074751 --> 0.063589).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 5.271286725997925\n","Epoch: 4, Steps: 24 | Train Loss: 0.0497305 Vali Loss: 0.0690247 Test Loss: 0.2127245\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 5.259740591049194\n","Epoch: 5, Steps: 24 | Train Loss: 0.0468496 Vali Loss: 0.0647273 Test Loss: 0.1995574\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 5.2590227127075195\n","Epoch: 6, Steps: 24 | Train Loss: 0.0452284 Vali Loss: 0.0607002 Test Loss: 0.1874586\n","Validation loss decreased (0.063589 --> 0.060700).  Saving model ...\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 5.269329309463501\n","Epoch: 7, Steps: 24 | Train Loss: 0.0462731 Vali Loss: 0.0621866 Test Loss: 0.1889731\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 5.260478258132935\n","Epoch: 8, Steps: 24 | Train Loss: 0.0448070 Vali Loss: 0.0635193 Test Loss: 0.1950590\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 5.2605369091033936\n","Epoch: 9, Steps: 24 | Train Loss: 0.0430216 Vali Loss: 0.0637342 Test Loss: 0.1971168\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 3.90625e-07\n","Epoch: 10 cost time: 5.258269786834717\n","Epoch: 10, Steps: 24 | Train Loss: 0.0445755 Vali Loss: 0.0639202 Test Loss: 0.1924223\n","EarlyStopping counter: 4 out of 4\n","Early stopping\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df512_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.1874585747718811, mae:0.3230174779891968, smape:0.22820183634757996\n"]}],"source":["\n","Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.3720988],\n","        [1.8225353],\n","        [1.8268465],\n","        [1.7129052],\n","        [1.7873434],\n","        [1.6485296],\n","        [1.7265484],\n","        [1.7008437],\n","        [1.7821981],\n","        [1.7364556],\n","        [1.8867788],\n","        [1.8124156],\n","        [2.0196788],\n","        [1.46583  ]]], dtype=float32)"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([2.0792735, 2.3894088, 2.4128153, 2.2928572, 2.3894088, 2.3660023,\n","       2.462554 , 2.4537764, 2.5298474, 2.6176221, 2.4537764, 2.4508512,\n","       2.6936932, 2.8048735], dtype=float32)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([1.1394079, 1.5030979, 1.4673405, 1.3805246, 1.3804749, 1.3415693,\n","       1.3103017, 1.3900557, 1.4319048, 1.3873209, 1.4072802, 1.3547498,\n","       1.4217983, 1.2928296], dtype=float32)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABahElEQVR4nO2dd3xb1fn/30fL8t6J7djxyN7OThghYYVZRoECZbWMsktbVhel0PZbft2MsqFA2Q2bsEkgIQnZew8ncex4b1uWJZ3fH+dKlrfkyJPzfr38knTn8ZX9uc99zjOElBKNRqPRDHxMfT0AjUaj0YQGLegajUYzSNCCrtFoNIMELegajUYzSNCCrtFoNIMELegajUYzSLB0tYEQIgN4EUgBPMBTUsp/tdpmPvAucMBY9JaU8oHOjpuUlCSzsrKCH7FGo9F8h1m3bl2plDK5vXVdCjrgAn4hpVwvhIgG1gkhPpNSbm+13TIp5TmBDiorK4u1a9cGurlGo9FoACHEwY7WdelykVIWSinXG+9rgB3AsNANT6PRaDShICgfuhAiC5gKfNvO6rlCiE1CiI+EEBNCMTiNRqPRBE4gLhcAhBBRwCLgDilldavV64FMKWWtEOIs4B1gVDvHuAG4AWD48OHdHbNGo9Fo2kEEUstFCGEFPgA+kVL+PYDt84AZUsrSjraZMWOGbO1Db2pqIj8/H4fD0eWYND2D3W4nPT0dq9Xa10PRaDTtIIRYJ6Wc0d66QKJcBPAssKMjMRdCpABFUkophJiFcuWUBTvQ/Px8oqOjycrKQp1W05tIKSkrKyM/P5/s7Oy+Ho5GowmSQFwuxwNXAluEEBuNZb8ChgNIKZ8ALgJuEkK4gAbgUtmNMo4Oh0OLeR8ihCAxMZGSkpK+HopGo+kGXQq6lHI50KnCSikfBR4NxYC0mPct+vprNAMXnSmq0Wg0vci/Pt/D+kMVPXJsLejtUFRUxOWXX05OTg7Tp09n7ty5vP322712/ry8PCZOnMgnn3xCbm4uubm5REVFMWbMGHJzc7nqqqsCOs7GjRtZvHix7/P999/PX//6154atkaj6YL1hyr4x+e7Wba7w3iRY0ILeiuklJx//vnMmzeP/fv3s27dOl577TXy8/NbbOdyuXp8LAsXLmTjxo1s3LiRGTNm8PLLL7Nx40ZefPFF3zZut7vD/VsLukaj6Vv++skukqLCuO7Engk60ILeii+//BKbzcaNN97oW5aZmcltt93Gf/7zHy6++GLOPfdcTj/9dMrLyzn//POZPHkyc+bMYfPmzUBbS3jixInk5eWRl5fHuHHjuP7665kwYQKnn346DQ0NAKxbt44pU6Ywd+5cHnvssU7HmJWVxQMPPMAJJ5zAm2++yfz5831lFEpLS8nKysLpdHLffffx+uuvk5uby+uvvw7A9u3bmT9/Pjk5OTz88MMhvXYajaZzNudXcc7kVCLDAk4BCoqeOWoI+P3729he0Dp/6dgYnxbD787tPIl127ZtTJs2rcP1K1euZPPmzSQkJHDbbbcxdepU3nnnHb788kuuuuoqNm7c2Onx9+zZw6uvvsrTTz/NJZdcwqJFi7jiiiv40Y9+xCOPPMJJJ53EXXfd1eXvYrfbWb58OQBPPPFEm/U2m40HHniAtWvX8uijar76/vvvZ+fOnSxZsoSamhrGjBnDTTfdpGPONZpeQEpJvdNFVA+JOWgLvUtuueUWpkyZwsyZMwE47bTTSEhIAGD58uVceeWVAJx88smUlZVRVVXV6fGys7PJzc0FYPr06eTl5VFVVUVlZSUnnXQSgO+YnfGDH/ygW7/P2WefTVhYGElJSQwZMoSioqJuHUej0QSH0+3BIyHcZu6xc/RbC70rS7qnmDBhAosWLfJ9fuyxxygtLWXGDJWYFRkZ6VvXXqi9EAKLxYLH4/Et8898DQsL8703m800NDQgpQw6XNB/HP7n6yrLtvX5e2MuQKPRQINTzXeFW3tO0LWF3oqTTz4Zh8PB448/7ltWX1/f7rbz5s3j5ZdfBmDp0qUkJSURExNDVlYW69evB2D9+vUcOHCg3f29xMXFERsb63OheI8ZKFlZWaxbtw6A//3vf77l0dHR1NTUBHUsjUbTMzQ0GYLegxa6FvRWCCF45513+Oqrr8jOzmbWrFlcffXVPPTQQ222vf/++1m7di2TJ0/m3nvv5YUXXgDg+9//PuXl5eTm5vL4448zevToLs/7/PPPc8sttzB37lzCw8ODGvOdd97J448/znHHHUdpaXM41IIFC9i+fXuLSVGNRtM31BsWekQPCnpAxbl6gvaKc+3YsYNx48b1yXg0zejvQaMJPVuPVHHOI8t58srpLJyQ0u3jdFacS1voGo1G0wt4XS49aaFrQddoNJpeQE+KajQazSDB60PXk6IajUYzwHE0aQtdo9FoBgXNUS46U1Sj0WgGNDoOvQ8wm83k5uYyceJELr744g6TigLhmmuu8SX6XHfddWzfvr3DbZcuXcqKFSt8n5944okWVRU1Gs3ApsGpsrK1y6UXCQ8PZ+PGjWzduhWbzdam8FVn5Wo745lnnmH8+PEdrm8t6DfeeGPAdc81Gk3/p6HJjcUksFl6Tna1oHfCiSeeyN69e1m6dCkLFizg8ssvZ9KkSbjdbu666y5mzpzJ5MmTefLJJwFV2+XWW29l/PjxnH322RQXF/uO5V/i9uOPP2batGlMmTKFU045hby8PJ544gn+8Y9/kJuby7Jly1qU4N24cSNz5sxh8uTJXHDBBVRUVPiOec899zBr1ixGjx7NsmXLevkKaTSaQKl3unvUOod+XJyLj+6Fo1tCe8yUSXDmnwPa1OVy8dFHH3HGGWcAsHr1arZu3Up2djZPPfUUsbGxrFmzhsbGRo4//nhOP/10NmzYwK5du9iyZQtFRUWMHz+eH//4xy2OW1JSwvXXX8/XX39NdnY25eXlJCQkcOONNxIVFcWdd94JwBdffOHb56qrrvKV1r3vvvv4/e9/zz//+U/fOFevXs3ixYv5/e9/z+effx6CC6XRaEKNo8ndo/5z6M+C3kc0NDT4ytueeOKJXHvttaxYsYJZs2aRna26jHz66ads3rzZ5x+vqqpiz549fP3111x22WWYzWbS0tI4+eST2xx/1apVzJs3z3csbynejmhdWvfqq6/m4osv9q2/8MILgeZSvBqNpn9S7/wuC3qAlnSo8frQW9O6bO4jjzzCwoULW2yzePHiLsvgdqdUbmd4y+HqUrgaTf+moRdcLtqH3g0WLlzI448/TlNTEwC7d++mrq6OefPm8dprr+F2uyksLGTJkiVt9p07dy5fffWVr6RueXk50HGp29jYWOLj433+8ZdeeslnrWs0moFDg3a59E+uu+468vLymDZtGlJKkpOTeeedd7jgggv48ssvmTRpEqNHj25XeJOTk3nqqae48MIL8Xg8DBkyhM8++4xzzz2Xiy66iHfffZdHHnmkxT4vvPACN954I/X19eTk5PD888/31q+q0WhCRIPT3aOFuUCXz9W0g/4eNJrQc9a/lpEWZ+eZq2ce03F0+VyNRqPpY1SUS886RbSgazQaTQ8jpaSszkmM/Tsm6H3lAtIo9PXXaEJPSW0jVQ1NjBwS1aPn6VeCbrfbKSsr06LSR0gpKSsrw2639/VQNJpBxZ6iWgBGD43u0fN0af8LITKAF4EUwAM8JaX8V6ttBPAv4CygHrhGSrk+2MGkp6eTn59PSUlJsLtqQoTdbic9Pb2vh6HRDCp2F6mQ5FE9bKEH4tBxAb+QUq4XQkQD64QQn0kp/UsHngmMMn5mA48br0FhtVp9GZQajUYzWNhTXEtsuJXk6LAePU+XLhcpZaHX2pZS1gA7gGGtNjsPeFEqVgFxQojUkI9Wo9FoBiB7imoYPTQqpFni7RGUD10IkQVMBb5ttWoYcNjvcz5tRR8hxA1CiLVCiLXaraLRaL4rFNc0khYX3uPnCVjQhRBRwCLgDilldevV7ezSZmZTSvmUlHKGlHJGcnJycCPVaDSaAUqtw0V0D4csQoCCLoSwosT8ZSnlW+1skg9k+H1OBwqOfXgajUYz8KlxuIgKs/b4eboUdCOC5Vlgh5Ty7x1s9h5wlVDMAaqklIUhHKdGo9EMSBpdbpxuT69Y6IGc4XjgSmCLEGKjsexXwHAAKeUTwGJUyOJeVNjij0I+Uo1GoxmA1DpUWeuosH4g6FLK5bTvI/ffRgK3hGpQGo1GM1iobew9Qe9XmaIajUYz2KjxWuj9ZVJUo9FoNN3Da6FHawtdo9FoBja12kLXaDSawYH2oWs0Gs0goaZRW+gajUYzKKhxqGbyMfZ+kFik0Wg0mu5T63BhMQnCLD0vt1rQNRqNpgepbXQRZbf0eKVF0IKu0Wg0PUqtw9UrE6KgBV2j0Wh6lJpGLegajUYzKOit0rmgBb1f0uB0M+n+T/h4qy5YqdEMdGobXURqC/27S2FVAzUOF795Z1tfD0Wj0Rwj9U4XkTYt6N9ZvMV8SmsbueWV9eSV1rVYf7TKwetrDqGKXGo0mv5MvdNNuM3cK+ca0II+WAWtqqHJ9/7DzYU8tmRvi/W/eWcL9yzawq6imnb3f/CD7b59nlm2n02HK3tsrBqNpnPqnW4itaB3ztsb8jnlb19RXO3o66GEHH9BB3h3UwFltY2+z26PupF9vbv9RtvPLj/AXz7Zhdsj+cOHOzjvsW/a3a620cXTX+/3Ha9Llj4E614IbFuNRgMol0u4drl0TFV9Ew+8v539pXX88/Pd4Hb19ZBCSqWfoKfG2nG6PKzJK/ctMxkJCkt2thV0p8vje7+vpLbT83y0pZA/Lt7B1iNVgQ1s6Z/g/dthw38D216j+Y7jdHlockttoXfGP7/YTVVDEyeOSiJnw/8h/5Q2qES92k/QL5g6DICCyuYnkaIa9X7VgTLeXHu4xb5Ffk8sn20v8r33tGOFHy6vB6C4prHNunYxh6nXL/8ILmdg+2g032EanG4A7UPviD1FNby48iCXzRrOtbOHcp15McLdCKW7+3poIaOqoQm71cSjl0/l1pNHEmYxUVjV4Ft/tKqR701JY052Ir9+ZyuOJrdvXUFl83afbDvqe3/Eb7mXwxVqWXFNAG4rjwfcTkibCjUFsPn17vxqGs13ivomZWjqsMUOKK6o5u7oT/ld9f1MP/JK84qC9c3v1z4Ha57p9bGFisp6J3HhNs6ZnEaEzcKwuHCfhd7k9lBW10hWUiTXnZiN0+Vho9+kZ4Eh/GEWE1v8XCl7ittOoB7yWujVAVjorgZAwvjzIG0afPkgNFR2tZdG852mrlEZWxHaQm+f4+u/4CeNz2M78DnRKx9iA2NxmCJhxSOw4WVorIFPfwuf/Abqy7s+YD+kqqGJ2PDmUpupcXafUJfWNiIlpMTYmZGZgBCw+kDz7+kV/jk5ifgHAe0pautPPxSMy8VphE7aouCcf0BdCSz7a7C/mkbzncLrconQk6IdMOUyuGYxTP8RAO8l/4RyYqBkJ7x7M6x+Cpy1yqJcPzAjMirrWwl6bDiFhlAfrXIQQx3Tit8i9ps/8FzUk4QtfYDlu0tYtC6fh7/YQ1yElbEp0QBYTILYcKtPvL00ON2UGEJeEojLxWncEGxRkJYLky6G1c9ATREUblYuGY1G04J6p3K59JaF3ju3jVBitkLW8ZA+E2Zei2WdmReOnsovzS+p9Uv+BEMngT0GNr4Cx98BvVC2MpRUNTSRkRDh+5wWF05RjYPS2kbue3cbt1neZuy6xWCyMtMcywJzKbf+J5MPPHMBaHR5GJ6o9k+ItDEkJqyNDz2/olngS4Ky0CPV67y7YOsi+OckcDfCWX+FWdcfw2+t0Qw+6p3a5RIYFhukTCIhMownm86k/pelEJcJHhecdj9MvFBNlBbv6OuRBk11K5dLWqwdKeGJJXs5dOQI55uX0zTyTPhNMZH37sI1dDJ/iH2Xm+ePYMGYZH4yL4fMBCW8iVFhpMdFkF/RStANgc9JigzS5WIIetIo9aQ07lz1efVTMEgTvTSa7lKvXS7B4a1iVtPohgW/ghN+BiNPhbHnAgK2v9On4+sOlQ1NxPkJ+rD4cFIo44frf8Am+w0ki2qsM64EkwlhtmCZ9H3iGg5x94nJPP+jWfzyrHEMNyz8pCgb6fHh5FfUt8israpXoZGjh0ZTUtPoC2vcXVTDG2tahkICLV0uXobPhouehfOfUDfPg+0nMGk031XqetnlMngE3dEEUy6FU+83VgyFoROhYEPfDa4LKuudPmH14nR5qHe6W1joUzLiOMuymmx5mA+jL4FZP4FRpzfvNGyaen1qPrxzMwBpcXYsJkFSVBjp8eE4mjyU1TnB44ZvnyRzy8P8x/oQU+MdWDwOKuqdICW/XrSRuxdtZumuYqoampozVFtb6P6MOxdMFtjzWagujUYzKGjoZZfLwPOht8LbeLXa0U5iUUwq1Bxtu7yfMOtPX+B0ecj789m+ZV5fd2pcuG9ZjN3KiZFHKHLEsXXCLzj7jLEtD5Q6Rb1WHYItb8KZ/w9LWBR/nnCI1OExNMSmApBf0UBS5V746G6mAphh2u6fck3YAUp2PA+123i5+K+8alnAAx9Ekp0YSWltI+/eekLngh4WBemzYP/SEF0ZjWZw0Gyha5dLQDRb6O0IenQK1Ba1Xd5P8Kbpe1+llL7KitlJES22nWjKY6snm/GpMW0PZI9tfu92woGvQUouOvggxx/9L8Pi1c3hcHk9qzZsAuD5UY/xJTOIqd5DmHCR+vENyGV/pUGGcbXlM2pK8vlyVzFbC6pV4pJ/2GJ75MyHwk0DNlRUo+kJGpxuhAC7tXektsuzCCGeE0IUCyG2drB+vhCiSgix0fi5L/TD7Jhow0KvcTS1XRmVouKlPe626/oR2wqqcLk9nPK3r/j9+6oGelainyXsrCfJkUeedSQzsxLaP8hJ98DoM5Xgrnseqg4rv3dVPhkJEZhNgj9+uIPPVq0DYI/I5I2w7+OMyeRS528oGXoCrugM7mhSLpvZ5l1IqQqB7Txa07mFDpBzEiC1H12j8aOu0U2E1dwrDaIhMAv9P8AZXWyzTEqZa/w8cOzDCpzOLfShID1K1Psx6w5WsGxPKftL68grqyfabiEh0ta8QdE2hPRw7cXnkxJrb/8gC34Fl78Gc2+BPZ/C61eo5VWHiQqz8L0paRytdpAqynGawil02DgSNZnK61azyjOezyb/jeVnfsrXnsm4LRGcFXMAi0n9EW4rqDIEXYA1vP3zp00Fsw0Ofxu6C6PRDHAamlxE9FLaPwQg6FLKr4F++xzdYlK0NVEp6rWmf7ZyC7Ooy7/hUCVvbTjiW56dFKnu6N4ni7I96nXIuK4PuuBXMPYc5f4AqC4Aj4eb54/AYhKkijKqrclUOlzERViJi1A3joo6JzuP1uDGjCd9Fgvse3jiiunE2C1sK6hWgm6L6jim3xKmRP3w6m5dC41mMFLX6O61CVEInQ99rhBikxDiIyHEhBAdMyAibRaE6MhCV5OB1PQ/P7rL7aHR8J3vK6nlq13F5CRFcr5pOXOiSuDQt/D/cmD9S1C+H4QZYjMCO3jSqOb3bifUlTBqaDTL7zmZLGsVJeZkqoxsVJvFRLTdQnmdk/c3FTA+NQbryPmEV+zk1HQ3E1Jj2HakSrlvOnK3eMmYpaKKXAFWb9RoBjHFNQ6W7y31GW69QSjOtB7IlFJOAR4B3uloQyHEDUKItUKItSUloXGDmEyCqDBLxy4XgNr+F+lS52z26+8prqXa4eJHk+380/ZvfpV3Dbx6KTgq4aO7VfRIXIZKpgqEpNEtP1flA5ASayeFMo7KBBXrHqHmHxIibXy1u4TthdVcNisDRhsethfO5emSy7in+B48NUfB1nKitg0Zc9QNRPvRNRrue2cb5XVO4iMC/L8NAccs6FLKaillrfF+MWAVQiR1sO1TUsoZUsoZycnJx3pqHzF2K9XtuVwih6jXfmih1zWqG9C41Bhfx6CZ+M07p0yEKxZBUz3kr4GEnMAP3lrQq5Wg43YR7ynnsCveV9ERlKAfKK3DbBJ8L3cYJBthkWV7ccRkM0tsx7Tnk64t9JGnQngCrH0+8LFqNAMc/6Yy/njrJ/3xgkktV3zxAOz9vEfGcsyCLoRIEcYUrhBilnHMsmM9bjBE2zuw0C02iEiCkv6X/u8t2jMhrTkMMaNqnQpBvK8crn5fCeQQw4OVMCLwgyeONF4N14thoVN7FBMedtRH45H4LPREYwJ2zNBoldAkhKqoOPlSKi76Hy+5T1P7d9VExGqHqT+EnR8q371GM4jxeCR3vLaBSfd/0m5PgbK6Ri6Zkc7IIX6hvg0VsOzvcKRnEh4DCVt8FVgJjBFC5AshrhVC3CiEuNHY5CJgqxBiE/AwcKns5e7NMXZr+5OioLJHt73d75Jeao06yd648nCriYiCFZB5Apj8JlG8SUMxqYEfPDxOzR+kToGwWCjZpZYb0T4lMg7Al43qnRidkuEXzz7jx3Dhk+SkJPCBOEktC+TGOOPHIN2w/sXAx6vRDEA+2FLIOxsLaHR52HiossU6t0dSWuskOTqs5U6H1wAShs/pkTEFEuVymZQyVUpplVKmSymflVI+IaV8wlj/qJRygpRyipRyjpRyRY+MtBM6tNABTv6NEre1z/XuoLrA63IZkxKN2SSYH1+GqMiDkSe33DBnvnqNSQ/uBJe+DKf8VlWmPPCVWlavHpzKpSqt6xXyWuPaTU6Pa3MYs0kQPnw6AJsjAvgjTMiBEafAuv+Au4ObrEYzwJFS8vn2Il8Ey/bC6uaV+7+i/tsXcHskyVGtBP3QSlUmY9j0HhnXgM8UhS4E3RoO2fPg4MrmaoD15fDcmZC/tvcG2QqvoMeGWxk1JIoL7OsBoUIO/Zl8CVzzoao/HgzDpkN8FuQsgIo8FSljZHFWoAR9vOHuaXSpp4XRQ9vPAn3mmpmcHfM/fmv/VWDnnn61ChXVk6OaQci2giqmPfgZ720q4MyJqeQkRbK9wBD0A8vgxe8R/clPiaSB5OhWeSOHVkFqbtcBBt1kkAh6Jy4XgOFzoa4Yyvapz3s/h0Mr4JlT+8yK9NZ4iAyz8Or1czhVrIGM2apcgT9CQNYJYOrmVzXCsPj3LWlhoV84dRjDjHoxD5w3kdtOHkluRny7h7BbzUzKHMqR6gCv1cjTwBIOOz7o3pg1mn7Ms8sPUGEU1Zs/JpnxaTHKQpcSPvmlb7tZpp0tXS7uJtUqM2N2j41tUAh6bLiVqoamdjvbA5B5nHrdtVi9+vzpEnZ91NPDaxdvr8HIMDPxpnpMRZth5CmhP1HiCLDHQdE2JejCxPM3ncpfLp7i2yQjIYJfnD4Gs6nj9OSUWDtldY0dzui3wBahfpedH+pORppBRXmdkw82F3Jebhp/vGAiZ0xMYXxaDPkVDdRs+wSOboGz/4bbFMYJpq0M8Rf04h3gcjRXR+0BBoWgx0VY8UiodXbgdkkarR5zPvut6rKzf6lybVgjVSGr1jRUwPt3wGNz4O0boXRvyMdc1+jChIdIi4AjhusnY1bIz4MQStTL9ylBD09gWmZip+LdHikxqslGe7P57TLqNKgpgMq84Mes0fRT3lx7GKfLw83zR/LD2ZlYzSamD1dPtsXLnqfRFg9Tr6Igdiqnm9aSbPeojG8pm0t5p03tsfENCkH3Rmu0ri3uQwj48ScqhHHNc1B9RLkiMudC3rKW23o88OY1sOEliEmDHe/DK5eEfMx1jS4etT5MxKMTYds7IEw9NlFCwgjlbqovg4jEbh3CW0PmaFWAgp5slCko3dOt82k0/Q2PR/Lfbw8yKzuBMUbPXlD9CiLMHpKPfs079VM4VOViadLlZJhKiHxsMjyQAG9erQQ9LDa4nJIgGRSC7o3WqOxI0EHFSA+dAAeXq8/DpkPWiaq5dG1x83ZfPaQs+LP+Ale+BSf/Vlm3lYdCMtatR6p4bMlethZUc5Z5NaKuWN08YjMgLLrrA3SHxBEqFr26oNuCnhqr/O2FgQq6t/xA6e5unU+j6W98uv0oh8sbuHJOZovldquZy4YcIkbU87lnGh9uKWRR5Uiet12mQofHnQvb31Xh02m5PdrjeMA3uIDmBJnKBmfnGw4Zr0L4TFZV6Eoa6fd5y2Di92HT6/DVn2HKZTD9R2pd1gnGNt9A7vBjHutjS/by0VZViqDKHkVs9jRlnY/uqqDlMZAwApAqqmfs2V1u3h5BW+gRCRCZ3BwDr9GEkoZKVUk1ooNy0iFGSsmjS/aSlRjBmRNT2qy/2LSEGhnOvuhZfPPlHuqdbi77/q9g5nBoaoDHZkFDFcy5qUfHOTgsdMPl4m+hP750H88uP9ByQ2+1wiHjVHXAlCkQFqNCjaSElY+ozMzzHmu+iw4ZD+HxzZa9l4ZK5Z5pcgTVHNnbkciKi1hqVSLRVe/27Bed6M0yld220GPsFuxWE39cvIOtR6oC2ylpjHa5aHqG58+E/5fda70O9pXUsvVINT8+IRuLuZVslu1jTPkX1E66mjvPyWV4QgSXzx7OxdONYnrWcPjJ1/DzbTDmzB4d56AQ9FjDQq9qaBb0hz7eyYMfbOdgWV3zhkPGq1dv9qXZoiJg8papsq9Ht8DMa1tmappMykrft6Q5YqNsH/xrMvz3QvjjUFjzTGADXfU4N5f9H5fMSCeeGrUsst2yN6ElcaR6CoBuC7oQgtPGK8vkuW8OdLG1QdIoKN2l5gjeu61b59Vo2iAlFG9X7x+bBV882LyuvrxHIqt27t3HhrAbONW9vO3K9S8ghInUhT/nrEmpfHzHPP50wSRM/oEH4fE951L1Y3AIenhLQfcPX7zqudWs2m+UlhkyThXsGnlq885ZJ0LZXlxv34TTnqQSeVoz9hw1kVqwXn1+9xZorIH9S9Tn1U91PcjyA/DxvZwhlzM8IYKnLzTu3lFDgvpdu4U9BnJ/eMyHeeSyqczMiudIRUNgOwwZryKG3rxalQLoqhaMRhMIFXnN78v2wrK/qr+t6gL452RVqTRU+SXf/As2voJt6+vEi1pSP78VPvhZc60ijwe2vqWyo73VXfuQQeFDD7OYibCZqaxXPvSyOvV66rihfLu/jNdWH2JOTqJqZnxXKxfAxO/T+O0zhFXs40bnHfzOYSG1VbYuo89Q6brb31UhkIdWwby7VNOHw6vgyDp49XI47fcta5H7s/ZZ39uMGBNT4ow/uMjQVZ3slDMfUpbN5B8c02HS4yNYfSDAfieto3ZqiyB22DGdX6OhcKN6vfoDNdn/zo0qpX7Ta9BUB3s+UQWw5t8T9KFfXX2IMIuJC6elK2v/M9VR8xRM1IsIImS9KiNSdQRSJys/ftVhFTzRDxgUgg7KSvf60AurlAV5yYx0CiobqG3sxDKMSeWV6W/w+kdfsFMO54Yqhy+iw0d4nLoDb37dqK0iVcz4qNNUSYHnz4BdH6obxoUdWOt+vuTh4U1QV6o+9Jag2yLh/MeO+TDD4sI5Wu3A5fa09SW2JmWiakvnNiarqwu0oGuOnYKNKrAhY5aKGnnfBq9dDo3VMOcWqDoEKx5R7tMgXJoej+Qvn+wiNtyqBN14InfP/AkHV7/HuhG3c/HkRDWftv5FdeMA1Qegm8EGoWZwCbrhcikwJh7T4sKJsluo7qjOi8HhKhc7pYpgKanpoNvOnJvgpfPhYyO1NzVXvWbMgnl3q6zIHR9AYy2ERdHk9rDraA0Th4RxqNpDXMFuvIVy0+wOKDIafPSWoIeI9Phw3B7J0WoH6fFd1KOwhEHKJPUEAyrRSKMJkrpGF4cr6hmbEqNcKdvfVck5ljD1c/of4OAKGLEApl6pIqt2fQSPzlBlqFMmdXmOPy3ewbf7yyivc1Je56S0tpGkIxsAwa7xt3PWspN4ePJUmJIGY85Q/7dTLldZ0TFpPX8RAmRQ+NBBhS56E4sKKlVoXVpcODF2i6+aIKi78N8/3dUi/C6/ot7nh+9Q0HPmqz+iUiMML8oQYpMZTv41nP039bi39X8AfLg+jw/+fTf8cSjn/eVdwmoOURiu3DGJ5noV+24O65WJklDiFfH8QP3o/nUrqvtnb1dN/+bxpfs445/L+HjrUWUZVxyAeXc2bzD7J3DJCzD9GvX/OHQ8XPsZuJwBVVmtqm/ihRV5bMpvjt5af7BCGSJJo9lQrCJppqQb5aXtsXDKfZA0sl+JOQwmQQ+3+eLQC6saCLOYiI+wqsJdjc0TJDuP1vDwl3u5/dXmAvP5FQ1MNr6s0toOBF0IuNCIZhl1etv1w+dAymRY+RisfppzPprDvdbXAJhr2k6YcLHGmQWApbFauVwik3s0yaAnSI9X7qiABf3EO1WWrsmqLXRNt9hfWgvAXW9uwrP+JfV03N7/oD/DpsGoU2HLItj+nooF74B3Nh6h0eXhYtsqboxajs1sYuu+w6qA37DpbD5cRVyEleEJPVMhMZQMGkH396EXVDlIiwtHiLb9Rr1VDg+U1eHxSNweSX5FPVmJkSRE2jq20EHdke/YChc82XadEHDc7SozcvGdCNl8zttHqBZ43ziy1AJHpWo20RshiyEmNc6OEOqpJiAiE9XNLjr1u2uhH1yhJux2fKBqCWmCorRWGWpRjUWYCjfAhPMDM4TGnguNVfDGlfDcQpU70uRQDdj9WL63lJGJdv4U+Qr3uJ/kwoxq0jb+Hemohtk3sPlIFZOGxSIGgPE1aHzo0XaLr8Z4SXWjr8pZtOFykVIihKDMsMBLahqZ8LtPcLjcSKksz6SoLgQdVLPmjph0kfpDqznKw3kZpOx5jcvkYkY3qKeBTR4jwaehUgl6b4Qshpgwi5m4cGvHTzIdEZOqaqR/F/niQfX4HpEIzloYfWaP1cMejBypaOC08UNJ3/0pAI0jz6R1IFq7jDsH5t4KUUNVYb41T6sSHutfhMteV75w4GBZHQtj8rAWlgKCB6p/h81TyJa0i6muz2DX0W85/eQOotf6GYPGQo8Ms1DndOP2SGoaXUTblU882m7F5ZE4mlSygfduD9DQ5PYleQ6LDyc5Oix4ofJHCCXqx93KLnc6z0X9BMw2TKW7qSOcvdLwt/ks9IE1IeolPsLmqwcdMNGpKpb/u4bTaPLtblQup8Zq2P5OX49qwNDk9lBY1cDYlGhOi9zLYU8yF75REtjO1nBY+Ec4/naVe7LiEVj/kkqy+/hecLvweCQHy+qZ716pavhf/gY2i5lN1lzud17B7a9uYNSQaK49Mbtnf9EQMWgEPdquHjbqnC5qG5t8n6OM1/J6J7e8sp7FW5qtxMRIG784bTQAOUlRJEeFUXIsgu5Heb2ThKgw36RJvi0HFxbc1qhmC30AulxATUB7Y/4DJmWS6prkXwjtu8DhVeDxu/nFpMP7P4Wlf+67MQ0gjlY58BhP0FOs+WyTWWwrqO64smpHzLsbLHYYvRDO+quaWP3kVzhfvBC7q5oRji3KNTj6dLhjM+9Pfox1+XWU1Tm57ZSRxBgGYn9n0Ah6VJgh6I0uah0u3+cYQ9BfXJnHh5sLWbGvzLfP3BGJ3HrySL6+awHj02JIigqjpKaR1j2uP9hcwOtrgqu2WFHnJCHSBjEq7roiegxCgIiIV499bqfKWh2AxEfYqKgL8h/Km52778vQD6g/c2CZSkqbcKHKSv7RYpV5vPT/YMPLfT26fo938n14NETWHmRs7lxAtYEDVTTr9lc38ORX+zo/0PDZcOduuPx1mHghCDOsfhJ73pc8afsHcbX7VEw7gMnM1MzmEhlzcrpXLqMvGDQ+9EhDwGscLmobXT7L3GupP/nVft+22UmRXDEnk4umpyOEYHii8mcmR4fhaPJQ0+hqcUd+dvkBqhqa+MHMwKstVtQ7iY+0gUcJ+sjJc/nnibmYVsVBmZFkNFBdLpE2dvg3xQ2ElMnq993zGUy5tGcG1h858LXKmP2+kSlsMsH3n1GT5xv+C1O7UZLB5VSdbyryoKlehYbuX6JKMHeUqTxA8dZiynLnAZLEEdNhDWw5UsWLKw9S2+hi+d5Sdh6t5icnjej0WD7C49U1O7SCyqiRzKndAR6aazwBucPjABgzNJqk1o2e+zGDx0I3hLus1kmTW/os9Kiwto9KyVFhXHtCti/23EuGEZZ0qKxlBMfh8gaKAi0bi4p1r6hvIjHS5nO5JI2cznm5w1Q7OG+N8AHqcomPsFIerMvFZFKPu7s+8jWrHvQ4qlVTg6wT1e/v7QtrMkP2SSoT0RXkdQT49Dfw5wx49nT4zzkqguOlC+D1KwZ2yz9nvZpAdijru6jawd8/2016fDhD6pQRFJ2Zy7C4cNbklfPFziKW71UZ17uLaimvC+JaTrkUEnJ4I+ePzcv8BD0t1s6oIVEsnND39VmCYdAIerQh4Eer1SNadCsLHWCqcddNjLK1e4ysxEgA8vwqNDY43ZTWNlLndLdbQsDp8vDnj3byizc2cbhc3QiqHU24PZL4CJuq5jhkQnOlx/C45p0HqIUeF2HD0eTB0RRk6dI5N6vkq/+XDe/c0jOD608cWqlq7mef2HZdxixlZR/dHNwxpYRNr6r3KZNUaeTSPapGT8lO2N03PXJDwvZ3VKGtLSo5792NRyiuaeSZq6Zj3vaWclHGZZKbEcfnO4ppcrd0ja7JC8JQmH413L6BL0tj2W0epcpox2X5Vgsh+PiOedxx6ugQ/GK9x6BxuXgtdG9HHa+F7i/op49PYcOhyo4FPUlZ6Et2luB0eSiscvDKt82+86JqB1HJUb7PW/KreGlVHm+szQdUpMzPTxvtsxQSIm3KKh29sPkksX5umwEYtgjKhw7KrdSm7k1nDJ0Aky6GLW+q9O0Q1Jbptxz4Gt7+CVgj2u/y7l12+FtInxH4cY9uVpEy5z8OuZerhBkpVc2cw6th8d2QPnNg/m3t/FC97l8CM68lPz+fmyO+ZOz2dap+ytl/ByG4fl4OHxrBDTMy4xmeGMGHmwtZtqeEhRPaNp/oCEeTm/WHKlk54ReMnmBpfoIyCLbvbn9g0Ah6pE39KkWtBd3P5XL8SDW5kRjZvk8swmZhaEwYi9bns2h9PgmRthaPcUVVDkYYgt7k9nDREytodHm4am4mGw9XsmpfGZymhA6Ur7kNOfNhlSFk3axN3tfEG/XnK+qaghN0gAufVnHBa55RQjQAkjW6xYpHVVTF5W+q8LnWxKRCfJbqhDU3iKeVXR+rV+8ks/+xL3kBnl0In98P5/+7uyPvG5z1sPcLQKibodvF+QfuZ5pnPSwDxpwN064GIDcjjivnZOKWkj+cN1H9CUlYtO4IeaX1XHtCNgvGDsHl9vDxtqMsGDPEN8fmpbS2kX98thuny0PG1JNh7MByrXTE4HG5tLbQW4UtAowcEkVarJ2Jw2I7PM6wuOZ/kNY+uaIa//ovDTS6PNw8fwS//94E5o5IZMPhChqcbg4aPvjk9iZTso5vfm8eGKFQrWnu4doN/68QavLO5VBNqwcjzjrVl3bCBZAxs+Ptsk9SzVUCrRPv8cCmV1SXq/Ys8NQpqp7/5jeUn70wSHdOb+PxwDcPQ/EO2PgyuBpgxo/BUYVn2d+Y1rSeT4fdCreth8teUQ1pDB48f6KviYQQgpsXjMDhcrN8bynPfXOA4moHv3xrC7e+soEb/7uOJnfLuYUXV+TxsvH0PTOrd9rY9QaDRtAjfT70lha6/2NThM3Cil+ewmnjO74bF1WrOHS7te2lKapu5Ndvb+Fnr29k0+FKAE4eOwQhBHNzEmlyS5bsKua9TQWkxdoZm9JO4S1bZLd+v/5EfKRhoQcbC+zFW0K3Kj9EI+pn7FuiEom6ajeWM1+5Two2dL6dlwNLVWTLjB91vE3uD1Xc+4pHVEnZhsrAjt0XbH9bZXD+9yJVvzxjtvJtA87dXwBQPf5SvxaKHTNySDTPXj2D6ZnxbDhUyYK/LuXNdfmcMDKJZXtKeWnlwRbbe3XiuWtm+JIQBwODRtCtZhN2q8lXRTHK7xHrX5fm8skd8wI6zk9PGYXFJHjo+5O5ck5mcwmBMAtHKhp4+dtDvL3hCHe8vhGATGMide6IREYNieK+d7eybE8p500d1rIFlT8/36msjgFKgmGhBx3p4iU2Xb0OVkE/sk7Fng+f2/l22Sep172fBXbcdf+B8ATVRb4jMmYp18Txd6jGC+tfDOzYvUXVEdXFSkr48g/K7VRfpvIyTnsQopQP3FK8lUZpJSst8GqGJ48dyg9mZlDb6MLh8rDoprm8dO0sThiZxCNf7qHG0WyAlNU6mZAWw8mDxNXiZdAIOigRLzZqsfi7Ws7LHcaY9qzldrhkZgZ7/3QW5+UO48HzJ/LFL05i3W9OZUhMGN/sK22xbaTNTJIxwRpmMfPo5dOIi7AxLC6cS2d2UvMlJjUgq6O/4nW5lNd2V9CNa+NfCsDjhufPavYRD2TK90FcZtcutchEyFlgtOfr4mmnpkhNGuZermqAd4QQ8L2HVfes2OHN3X36A846+Md4eOUH6rsv369qrdy1F+7co5J/IpNAmLC46igllvGduEfbY5bhPjljQgrTMxMQQnDDvBwq6pvYaDxVg/KhJw6g+PJA6VLQhRDPCSGKhRBbO1gvhBAPCyH2CiE2CyGmhX6YgeFvlUe3E3/eHaLtVhKjwshOimJ/iQpnvOa4LAAktKjANiYlms9/fhJf373AZ7kPRmwWEykxdg6W13W9cXtEJKoJw6rDzcuqDsPBb5RPeaBTtj/wG/acm1XRskemw87Fyv3y+PFwpNUT3KrHwONSNb8DJWVS//Kjr35avR7+VjVkB5VwFhbVIkZfGhnUjeFDiLAFF7eRmRjBg+dP5JdnjfUt85a9La5uLutRWuv0GWODiUAs9P8AZ3Sy/kxglPFzA/D4sQ+re3itcrNJtOsDPxbOmZzqe//D2Sr0sN4ZZBz2ICIrKYK80m4KuhAq4WrFI7DqCbWs/IB6rTkamgH2FVIqyzMhQEEfeaoSaY8bPvw5vPZDKNqqmhN7ObJOXaupVwSXCZo6WTVRdnbzezpWaktg85sqnBJg4yvN63YZ8fJDx7fZrcqsrOyIhODbFQohuHJOZotuWkNilCVeVOOgtLaR19ccorS2sf2ghQFOl6onpfwa6Cxi/zzgRalYBcQJIVI72b7H8IYuRoVZQl67+HS/jLGRQ6IYOSSK+89t+8f4XSE7KZK8Vhm1QTHnZkgao5rwVhxUxZJANZIeyNQWqeSpQC10kwnO/Rd8/2llqQsTjDkLdn6gerA661USVlQKnP7Hro/nT8okQCoXR10vRhTVl8Piu+CfE+Gt61Qm6+Y3VMmL0YZtuP4FiM9u07HrYFkdGyuV0CanduK2DIIIm4Vou4Xi6kYuf3oV9yzaQqPL02E+ykAmFHHowwC/Z2fyjWVtil8LIW5AWfEMHx54XZRA8YYuRtrMIT92hM3Cvy7NJSbcihCCz39+UsjPMZDISoykvM7J6N98hFkI/nvdLKZnBhH+Net6JVyPTIevHoIIY9++sNCbHEpME0JQIrXMKBKVkBPcfpnHwc2r1CRhzVHY8yn878dQvF2lwl/+Zsss40BIM7yfectUa8TZPwlu/+7y6W9VNmvuZTD9R/DhL+DdW0B6VGLZgWXqppcysc2un20vIsodCxYwx4TOLhwaY2ftwXJ2F9X6lg2kGi2BEgq/RHumsGxnGVLKp6SUM6SUM5KTQ5/2PiU9DoCqhm6G03XBebnDWDBmAGbg9QBZSWqOwOny0NDkZtPhqi72aIfYYeqffusi1ckdel/QG2vhX1Pg4dzQhPiV7VWv3Zn0HjJOJQolZMOsG1TpgIQcuOZDVdY1WGJS4faNYI1s9ln3NI21sO1tNXl73mMqC3balSqKBZTP/KLnYNRCyL2ixa5SSlbuK8MZbvyPRYUuAmVoTBhbj7QsKDcYBT0UFno+4P9slA70SfPIW08eSUZCRIt0f03PkJ3UPOlrs5goqg68eFkLZvxYNfL1ToY6a5TPt7fi9b99HGqNm8ihlSp2vHSvsorTpwd/vKObwRbdssRDd1jwKxUpk3uZakrcXRKylagWtRvTEHo2vqKs71y/KpIjTgbAY7Zz1JxK2pjRvm5BXrYeqeKa59dQWtvI90akwxFCKuhDou2AShw8UqnqPQ1Gl0soLPT3gKuMaJc5QJWUsk96jQkhOH/qME4ZN7hiS/sjWYmR5GbE8eSV0xkaE+ZL1AialEkw2SinazPq5Kx/SfXfdIWm2Uin7P4Ehk4Cc5hyBQC8dyu8dH73LPaCjSpj03SM/1ph0TDnxmMTcy8pk1Q2ZqAZqd3B7YJVj8Onv1bVJYfPaV6XkIMrNpNtTSlc+9JG32Kny8OlT63k9ldVNqe3W1hq9gTffqHCOzGaOzzOl2z4nbTQhRCvAvOBJCFEPvA7wAogpXwCWAycBewF6oFO0tg0gwWbxcQ7t6gyBs8s2+9L6OoWFzyhkmWctaqg1cf3qOUjT4NLXwFLCCyp+nJ48xo45XfNlnddGeSvhfn3Qt5yOPAV1JWqsDrpgUXXwuybVPf4ACivriOmYDNi9g3UOZr6T5eboRNVqYXyfZA8pmfOsfJR+Px3qizBD15qUaNHSsn/2W5nQ1MNB0qbfdhr88pZtV/FW2QnRfLGT+bikZKZWfEwdWqP5GpkJ0by5o1zeXFF3qCMculS0KWUl3WxXgLfgVqomo4YGmNn65Fu+NC9CKEa+hZta1526u+VQOz9DMaefeyD3LpICfaiH8MVbymx2L8EkOrGEZEIi++Ef+UqMU+bCns/V7Xrr/5AWcwRnU/6Lln2Nd+XTp7aF8M/vvmCD28/gRy/6px9hrcTz+Fve0bQPW5Y86yyzK/5oM3qpbtLePZwKkKkEuX35LJkVzE2s4kN953WpnhWqMXcW6NpemY804arn8HIoMoU1fQNKTF2jlY72rTuCxqjXR/jzm1OoPFOMh4rW/6nfLI1R1Vkzae/UVX9wmKU4M28TvnznTXKd339Ejjnn6pd4L/nKmu9C6QxD/ByfhINTW7ue3dbF3v0Eslj1bXd82nPHH/3J1B1SF3Ddnh51UHSYu3cefoYahpdVBsp+Et2lTA7J6GtmPcAP5ydyaKb5rJg7OAOatCCrjlmUmLtOJo8TL7/0zbdnoIiPA5uWQMX/Ue9D49vTjg6FqoLVbPmWdfDTzerBJ0Vj6gKf8PnqA5CQsA5/4Bf7Ibrv1SfvcW1mupUL9TiHR2fQ0pySz9ksyebgzKFYXHhLN9b6vML9ylCwKjTVdGwnpiX+OZfqpxDB09SxTWNjE6J9nUEK6x0sK2gir3FtZ0WygslZpMILqx2gKIFXXPMDI1REQQ1jS7WHTrG9nLJo5vLpMZnNyccBYvHAy98T02weiNoRp4G0UOV5R0zTKXSZx7Xcr/ooc2tAaNTVEXEUQtVqYI1z7R7qnqniydefo2RMo8l4adjM5v46akqozPo3qvtUNfoYtmekhbLnl1+gAfe3x74QUYvVHMUB1cc83hacHiNulked1uHtWsq6p3ER9gYFqf+TgqqGnht9WHCLCbOmxJ8NqimY7Sga44Zb0VKCHE5hISc7lvopbuVz/y9W2Hz6xAWa2ROom4YU69U7zOP7/gYAFe+A5e9ppKgti6Cr/4CRS2F9Jtdhczb/X+UyFhmn3cTy+9ZwOmG5bmt4NgF/eVvD3Lls6tZsbeURevyOVLZwIMfbOe5b4K4NtnzVCRPqN0u295Sx829vMNNKuqaiI+w+ZqhPPTRTl5bc4izJ6USG9FPJo4HCVrQNcfMjKwEfnuOKoPQ7QqM7ZGQrUrsdlWJsD0O+Vmiez+HYdOUa8XLcbfBBU+qdm2dIYQKQZx0sSr7uuQPsKRlCn743g8ZbzrIt+N+xayxWQyJsfuqbm4PgaB7bwqXP/Mtv3hzEze/3Fy4y+MJcN7CFqlEfXcIq1lKCTveV3HmrVL4vThdHmobXcRHWH03/p1HazhhZBL3fYdLZ/QUWtA1x4zZJLj2hGyiwiyUBdN5vSvis1WT5cpDXW/bmoMr1SToRc+rzyMWtFwfFqU6vwda82fkqc3JQq3qzQw58hklMpaFF13Xogb+uNQYthdW4/bINh1zgmFnYU2Lz5sOV/qS54LKih69UBUOC1XWaOFGVSVz3DkdblLp147RYm6Wm0eMUtOa0KIFXRMyWvdgPfYDGokl5fuD3/fQKtVgYuKFqkbK7BuPbSwWG9y2Vh2naLtKpNnwX6gtJrP8G5aKWVgtLaM1xqfFsL+klkueXMmE+z7p1mkbXW72lTTHbmcnRXLiqCR+e7ayboO6gU64ULmePrtPWdfHyr4v1euojssSeJugeBuLv3zdbBbffmKLUtea0KEFXRMyQi7o3lKxpbuD26+hQoXRpU1Vn4eM67wpRKBYwpQfvqlOxci/ewu8cxNhngY2hc9us/mEtBg8EtYdrMDp9gQc1rlqf5nPlbKvuA6XRxJn+Jr/dskUXrp2NmlGXHVZMFE0kYlw0t1KiAs3Bb5fR+xfqpKWjP6mUkpfSKKXijr12du28PiRSYxPizn2c2vaRQu6JmQkRtpC63KJTFIt14IVdO+k5dAJoRuLF+/E6spH1avhfnFGtW2VNj61pXBVN3Sder/xcCWXPrWKv322C2iOkrl1wUjm5CQwyejgkxBpdI0K9npPuki9HvgKKg+3rFEeDM569RSUMx9QYn77axvJ/f2nVPn1mq1oZaFrehYt6JqQoSz0EMc5J42G0j3B7VNsCPqQHph0Sx7XsnmFUS7XGtM2njo9PpwYv0JxgdS7qXUo0X97vWrPtzm/kgibmR8dn81rN8zFavihvd12gr6BRqeoOvT7v1L1yt+5CZoagjsGqFBFt9Mn6O9tKuD9TQV4JKw/VOHbzCvo3huQpmfRgq4JGQlRyuVyzBmj/iSNUlUQv31KxZYHQvF25SuOCbzBcMBYbHD7evh1kcoobVKJVPbYtuWghRAt3AuBCLq3kXFBlQOPR7Ipv4qJw2J9BaW8xBsCWdadqKKck2DfF82fuyPo+5eCyQrD5yKl5Mmv9pMeH45JKBeTlwrjhhOnwxN7BS3ompCRGGmjyS2paQxhVb+EHFVb5aO7oHBDYPsUbVetzULctaoFVrsvAalSRpIQ3X6539PGp5CVqDIkiwIoYOYftXLbqxvYeLiSKeltKy5azSZi7BZeW3OIj7cGWdx00sWQOLL5c1M3snv3fwUZsyAsinUHK9heWM3N80cyIS2WtQebk8vK65qItJkJs4S+6YymLVrQNSEjIVJNPIY0Fj1jVvP70gDqutSVqkbL3gnRniRSWeVlMqbDyn3XnpDNJz+bBwRmoXsnFc+cmMKHW5RQTzYat7QmwmahsMrBA+9vD+6pKGMW3LYOLjSaNjcFWSmzrlRNqhruls92FGE1C76Xm8b0zHg2Hq7E6fLw8dajPPfNAR2e2ItoQdeEDG/iSLdro7dH5vFw5x4QZtWTsivWPg/uRph2dejG0BERykIvI4bk6I6jaMIsZhIibYEJeoMLs0nw7x9O47HLpzE8IYLZOe3XIPEer6DKwUMf72LpruLgxm9Rqfi4gnS5rHkWkKqIGrBsdynThscTFWZhTk4ijiYPGw5VsGh9PgBXzMkM7viabqMFXRMyxqaqbMFQpLv7EEKFxcVndl150eWENU/DiFNgyNjQjaEjIhMBZaEPT4zodNOhMfaAXS4xdtXk/OzJqXx99wJft53WXDIjHYvhW3/iq31c8/ya4MZvNcYcqA/dWQfPn4Vc/g+Wm2bwVWUSv3t3K9sLq5k3Wj2tzB2RiNkkWL63lPyKBk4ZO4Sb5oe+rrmmfbSga0LGkGg7Q6LD2HYstdE7InFk1y6XbW+rMMI5N4f+/O1huFwqiGF4QueCnhpr97U+64xqRxMx4YFNIP6/i6aw+w9ntlgWlOvFatwoAhX0DS/DwW8ojJ3CHxou4tZX1vPCyoMAnGyUpY0NtzIlPZav95SSX1FPenx44OPRHDNa0DUhZdKwWLb0iKCPUhZ6R5EuHo8qiZs02tfDsscxXC7u8ERfOGFHjBoaxf6SOpyu5vE/+MF2PtzcckKzuqGJ2AAFHcBkEjx55XROHacEtSCYzlFWQ2wDEXQpYdVjkDGbeyMfZKccTo3DxcRhMaz59amM84u5P35kEpvzK6lxuEiP7/xGpwktWtA1IWXCsFj2ldRS7wxx/8qkkcrXW53fcnnJLtj6Fqx+Coq2wIl3Hns/z0Axolws0V03TRifGoPT7WFvsUrjb3J7eHb5AW55ZT0uvzovyuUSXIjfwgkpPrfGzmDK9VoMQQ/Eh+6sg4o8Gkeczqp9ZT4Bv2J2Zpv5g2mZ8b7KAsO0hd6r6IIKmpAyNiUaj4S80vrQpnh7k4SKtkPc8Obl794K+avV+9RcFZLXS7gihmAB7PFdx7tPSFOhh9sLqxmfFsORimYR/WjrUc6doo5R7XCREtu+z7wzRg9V8xc7CqsDb5IejIXuUpb/vkqJ0+3hvnPGI5HMzk5ss2muX1SOdrn0LtpC14SUxC5S0ivqnBR3JwpmyDj1Wmy0ddvwX3jxfCXmoxbC5W+ofpa9ZJ3vLa4hz5LNT5w/wz36zC63z06KJNxqZluBckflldX51j34wXZfTZaqIF0uXqLtVobFhbO7qLbrjb0EI+jGNluLncTYLczIiue4EUltEp5AJT1lJ6m4fO1y6V20ha4JKb4aI/XtC/pp//iK0loneX8OsvGzPVZZ5l88oFqeNdaohCOAhX9sLuTVC5TWNnLq37/GZjHh9MzkF5lts0RbYzYJxqZG8+3+ct5Yc5hPth0F4PkfzeTa/6zhxZUH+dlpo6nuhsvFS0ZCOAUBTLz68Aq6ywGOKvXj//Tjj2GhbzrayEljhnQ5ZzBteDylNY3E6wzRXkULuiakeAW9ogMLvdRIOiqvcwZf3yNpjKqN7qiC8eepeudl+3pVzAEOGn1TnS4PSVE2Rg2JCmi/H8zI4N63tnD3os0AhFvNzB+dTFZSJDuPVuNoctPo8gQc5dKatLhwVu4r63I7KSVCiGYfelM9PDoLao/C/R1MaBsWeqnDxInZXffmvGvhGC6blaHOo+k1tMtFE1Jiw60I0XUVwDV53eg9ajMe33/wX7jkRTjrL3DlW90Y5bGRX9GcKj8nJzFg0bpoejpjU6J9tcAbmtwIIRg1JIo9RbW+LNHuCnp6XDhF1Y5Om2ks3lJI9i8Xc7i8XvUAFWaVKVp7tPODG4LuwEZKTNc+/pRYOzOyBn9T5v6GFnRNSLGYTcSGWzsU9Eibqumx+kA3BP3U+2H+r1R/zz4k329Cc96ort0tXixmE2/dfBxf3626J0Ubwj56aDR5ZXUs3aUaQXubKQfLsPhwPBKOdhK6+Opq1f1pX0mtStqyhkOdXwPqjsJCjUgYh7R1mhWr6Vu0y0UTchIibO360D0eSUOTaiLdrVj1hByYf8+xDu+YOVLZQEKkjVevn8PIAN0tXiJsFiJs8OKPZ/miWUYNVZFBd/9vM+NSYzhpdNdhkO0xLE49weRXNJDRQaJTtVH8y241imVZwyHfL8PUWQv2dqKTjHovDqwMidGC3l/Rgq4JOQmRtnZ96DWNLrw9jauD6YXZz8ivaCA9PpwxKe03Rg4Eb6o8wOihzTeF354zrt3IkUDwxnx3lpFaY9Rb995YsYQ314+HjgXdsNAbhY2kDgqRafoe7XLRhJz4DlrRVfpZ7V5h6QvySuu4/71twTVY9iO/op5hcaGLr85JimJKRhz/d+EkjhuR1O3jpBoWv3+Me2uqjevucBqCbm3l3mmsURPPhZta9h01LPQwe1SXES6avkN/M5qQkxDRkaArAR2eENGm92RP8Z9vDnCorHkSs8bRxNXPr+Y/K/L495IAyvG2QkrJEcNCDxU2i4l3bzmey2Z1EDIYIHarmZQYe4sY99Z4G2jU+wS91e/RWKN6pT45T4WIejEs9Mio4FxMmt4lIEEXQpwhhNglhNgrhLi3nfXzhRBVQoiNxs99oR+qZqAQH2mjor5t56JKwyLOSAinttHla4TcU1Q1NHH/+9s555FlvmWr9pdzsKyeMUOjeX5FHiU1wbXMq6xvotHlISW2f2ZAjkuN9vUhbY9Go5ZMvb/LBVScPyhBL9uv3u/8sHlHw0KPju6+m0nT83Qp6EIIM/AYcCYwHrhMCNFes8ZlUspc4+eBdtZrviN4OxfVtupc5HW5ZMRHICXUhrreSyu82ZfVDpfv5lJYpSzNX589DqfLw2fbi1o0Ne7ymMaTh7enZ39jQlose4prcXgF2w//ZQ3ea++10JPGqNfGGuVHB1UMzWXc8IyuRnHRISznoAk5gVjos4C9Usr9Ukon8BpwXs8OSzOQSTTErrX163W5eCMwetqP7u/22VVUA0BhlQOrWXDCyCQyEsL51dtbmPmnz9l0uDKgY3pvEomR/XNicHxaDG6PZE87JQCKq5u/jwanEZ7ojaFPNgS9oQIclapqpXT7GnRvO1SERwoSYrWF3p8JRNCHAYf9Pucby1ozVwixSQjxkRBiQkhGpxmQeAX7cKvJOa+ge/3PNT3sRy/1a4X3klG3u7CygaExdkwmwfHGBGST28Mdr28MyAXkvUn01y72E4yCaNsLW4aFHiitY95flvg+1zcZN9OGSvXqFfRKdZ3IOlG9luyk2tHEip1HcAorp44PsPCXpk8IRNDbi6Fq/Ze/HsiUUk4BHgHeafdAQtwghFgrhFhbUlLS3iaaQUCGUZBpzYFyFq1rLndb2eAkOsziE8PqhtBa6B6PpNHV7Fbwiu9Zk1J4ZfUhth6porDK4YsGuWXBSG5ZMIIHzpvIgdI69pcqq3blvrIOGy/3d5dLRnwEETYzu462tND/b/EO7FYT0zPjAWjwToo6KtWr1+VSbvjPh88BkwXP0W1sPlxFGE7MYZFMz9TZn/2ZQAQ9H8jw+5wOFPhvIKWsllLWGu8XA1YhRJv4KynlU1LKGVLKGcnJgWfYaQYWQ6LDsFlMPLpkL794c5PPl15R5yQm3Eq0UXwqlBZ6XmkdC/62lEm/+5RnlilRKq9TLob7vzcBKeGr3SWGoKsnhIyECO5aOJa5Rs/ODYcq+d+6fK549ltu/O96Fm9pK+plhtUf308tdJNJkBEfwWG/8gQ7j1bz6fYibpk/kkU3HUdarL1Z0Bsq1Gt8JpjDoCJPfY5OhbhMvlixiiue/RY7Tsy2/jkRrGkmEEFfA4wSQmQLIWzApcB7/hsIIVKEUdBCCDHLOG7XVYI0gxIlKs3//N4ko81Hqhg9NIoYu8pnC5UP3eOR3PjfdVQ3NJEQaWP53lJAuVyiwywMibaTFmtnd1ENR/0sdC85SVFE2y3cs2gzd765ieNGJDI2JZpHv2wb1lhe10hsuLVfx2Knx4erWi0GH205iknA5bNVWKTdZm6OcvEKekwahEVD+QH1OTIZjz0Wi0uFQEaZmzC1DnHU9Du6/KuUUrqAW4FPgB3AG1LKbUKIG4UQNxqbXQRsFUJsAh4GLpVBNTfUDDb8U8+rGpooqnawv6SO40YkhdxC/2xHETuP1vC7cycwIS3GNxlbXuckwXCNjBqqStc63Z42gm4yCZKiwvBIlcH5zNUzmJOTyMGyujahl6V1Tl/N9/5KRkIE+RUNvrF/ur2I6ZnxJBoZnhE2c7OF/oOXIWeBEvOwqGYXTGQSTlM4EUJdyyizq23MuqbfEVDqv+FGWdxq2RN+7x8FHg3t0DQDGf+myRX1Tl/rtbkjEok2LPTqEFnor3x7iPT4cM6ZnMrKfWW+OjHlfuI7emgUX+1W8zap7WR5XnNcFo8v3cc/LplCmMXM8IQI6pxuyuqcLVLdy2udviie/kp6vIrzr2pooqzOyY7Can511ljf+girpblF4Lhz1A8oUQdAQHg8dTKMSBx8f1o606rCgI6rOGr6B7qWi6ZHGJHcnFFYXN3Ia2sOERdhZVxqDGaTwGY2hSRbVErJpvxKzpiQgsVsIjk6jLI6Jx6PpLS20dcxZ9TQ5nC7uSPatk27+rgsrpqb6SuFm5mo9jtUXt9S0OucZCX17y483t/52hfWYhaCMIuJC6am+9bbbeb2yx6EGTHmEQlgMlPjCSMCB784fTRRb7nApC30/k7/dQRqBjQ/mJnBc9fMAOBvn+5iTV4Fv//eBF/hqZhwS0h86EcqG6isb2LCMJXpmBRlw+2RVNQ7Ka9z+qJRvE0ozpmc2mFHIP+65l5B31FY3SIhp6yukYR+GoPuJSNBCe+6gxWszivnslnDW5S8jbCamxOLUGGbVfVNYDaePCJUPEOly0akaGRojF3VQ9cul36PFnRNj2C3mjlhpIpkKqhykJMcyXm5zekL0XYrNQ4X/166ly93FnX7PFsN98okQ9CTo5V//GB5vSHoSshyM+J47PJp/PXiKQEd12vl/vrtrdz88noAXG4PFfVN/TZk0Yv//MWjl0/lzoVjWqyPsJmba7mgLPkpD3yKJzVXNbw46W4AypqsRAmHugm7HGDpXp12Te+hXS6aHsNmMRFpM1PndPti073ERVgpqGzg462FnDQ6mZPHdi9hZeuRatWv0yhl67VE31hzGJdHcsIoZW0KITh7cmrAx/XVCwe+3FkMqLK5bo/ssNZ4fyHGbuUvF01mTk5iu2O1+02Kbi+o5mtjbmHbuJ8x6dTfgRDUNbrIrzMRjkNVXdQW+oBAW+iaHiUuQlmzw1pVJ5yYFsu6gxU0uSUHSjuuDtgV+0pqyUqM8Amw13p+bc1hkqLCmHkMbdBOHaduMt6WaweMKobejvb9mYtnZHR444mwmn310N/b1JxSsnJ/qa8UwM9e38jRBjMmDDHXFvqAQAu6pkeJM7q+ty43m5sR53t/uFxZvt2hsr6pRRq+v6/4nMmp3W4WAfD0VdO5ef4ISmobcXskecaNJyux/wt6Z0TYlKBLKSmpaSQt1k5OcqSvwXSNo4kvdxYzZYThInPWqnh1baH3e7Sga3qUeMNCT2/lcpk6PM733un2UNBJl53OqGpoItavqbK3ATPA9fNyunVML0IIUuPCcXskZbWN5JXWERVm6fc+9K6w28xICY4mD2V1jSRGhTErK4GNRoGylfvKcHkkI4alqB3+PRfcTr+wRk1/RfvQNT1KbAcWenZSJLHhVprcHuqdbg6U1nXLN13taGKsvVlovL7yUUOiQtJVyOtuOVrt4EBZPVlJES2iYQYiEYZ7qqHJTZkRV5+REEFFfRP1Thdf7S4h0mYmK83obVpfCnGZMOuGPhy1JhC0oGt6lHivoLcSVyEED31/Em4P3PLKevLK6phH8PV9qhqaiAlvGYb42OXTuj/gVgw1GiIXVSsLfYqfq2igEmFT//Z1jS7KahsZPTTad8MtqGzgq90lHDcyCavdr2Lj8T+FqO41r9b0HtrloulRRiZHkRJjb7ex8BkTUzlrUgrhVjMH/drEBYrbI6lxuFq4XELNUMNC/3x7EYfK65mSHttj5+otIg23VJ3TZWTC2kgzbrjL9pSSX9HASaOTwebXbi46pS+GqgkSbaFrepSr5mZx2ezhmDqYnBRCkGC0rAuWWiMxqbWFHkq8N6LX1x4mxm7hBzMzutij/xNllF4oqm6k0eUhMcrmc0+98u0hACXozhq/nbSgDwS0ha7pUUwmQZjF3Ok2MeHWbtVG96av96SF7h8l89NTR/sKiw1kosLU93HQCMNMjAxjaIwdi0mwp7iWnKRINZ8R5meha3fLgEBb6Jo+J8Zu6VZdF6+ge8vx9hQv/HgWFpPg+JFtSvwPSKLC1E3J6+ZKig7DbBLqKcojmxOwbFrQBxpa0DV9Tmy4lUPlwfvQvTeBnrTQwXA/DCIi21joKgzT6VLVFM+fasSf2/zi7S39u36NRqEFXdPnKJdLcBb6hkMV/OsL1cDYGxqpCYxow0LP81roxjzBXQvHsHJfWXOlTJ0ZOuDQgq7pc2LDre2Xc+2EHzy5CqdbWZQdVU/UtI/XQvc+FXkzbVWP1ZHNGw7wePvvInpSVNPnxNit1DnduNyBN1Bw+m3b0y6XwYbFbMJuNeF0eYixW7BZtAwMFvQ3qelzYsLb7zHqaHLz+NJ9OIy6I/V+Nby9CT+gapNogsM7MdpefkALrvsS7tjaCyPShAIt6Jo+x2tht3a7fL27hIc+3snyPaV8vqOY6Q9+TkWdEykllfXN2w70VPy+wBu62GU7vfTpEDfwY++/K2gfuqbP8frAW4cuesPqDpbXU9fooqHJzYGyOjJlBI0uDzOz4pmT07adnKZrvMlFif28+5ImOLSga/ocb6Zn6+Qib/3xw+X1NBohdYWVDqwm9WB53Yk5LJygMxi7Q6RRz6W/N7zWBIcWdE2f05HLxRsnfbCszudWKaxqwGJW79NidX3u7hLttdC78qFrBhRa0DV9jndStLXLJa+02eViN8oHHKlswGKk46fG6Tjp7uIt0DXQa7trWqIFXdPntGehO5rcFFQp8c4vb/DFThdWOpAS7FaTL8NREzzeRiDahz640FEumj4n3Gom3GpmS35z/e3D5fVICdMy43G6PVQYUS2FVQ1sOFTBlPQ4Hd1yDPgEXVvogwot6Jo+RwjBtSdk8+GWQl9fS29a+lkTmyc9bRYT+0rq2FZQzfTM+D4Z62AhSrtcBiVa0DX9gltPHkmkzcxHWwsBfA2ZfYWigIlpMdQ2unB5JDOytKAfCymxdmwWE0Ni9DzEYEILuqZfYLeamZAWy9Yjyu2SV1ZHXISVuAgbl80aDqgwRS/ThmtBPxbOnzqML35+kq6DM8jQk6KafsPEYbG8svogLreHvLI6MhNV+dYHz5vA+blpzM5JZP1vT6OgsoG4CO0qOBasZlO3mnJr+jcBWehCiDOEELuEEHuFEPe2s14IIR421m8WQoSuS6/mO8PEYTE4mjzsL60jr7SerEQlOBazidlGRmhCpI2JwwZ+X0+NpifoUtCFEGbgMeBMYDxwmRBifKvNzgRGGT83AI+HeJya7wCTDKFed7CCgqoGshIju9hDo9H4E4iFPgvYK6XcL6V0Aq8B57Xa5jzgRalYBcQJIVJDPFbNICc9XlnkGw5VICUM1y4BjSYoAhH0YcBhv8/5xrJgt0EIcYMQYq0QYm1JSUmwY9UMcuxWE2aT4EhlA9DceEGj0QRGIILeXvaG7MY2SCmfklLOkFLOSE4eXH0aNceOEIJIm5mjVQ6guSKgRqMJjEAEPR/wL4icDhR0YxuNpkui7VaKqhuB5uQXjUYTGIEI+hpglBAiWwhhAy4F3mu1zXvAVUa0yxygSkpZGOKxar4DRIaZqW1UZXS1oGs0wdHlf4yU0iWEuBX4BDADz0kptwkhbjTWPwEsBs4C9gL1wI96bsiawYy/iEdrl4tGExQB/cdIKRejRNt/2RN+7yVwS2iHpvkuEukn6JHaQtdogkKn/mv6FV6r3G41YTXrP0+NJhj0f4ymX+FtjebtSq/RaAJHC7qmX+ENVdT+c40meLSga/oV3klRHeGi0QSPFnRNv0ILukbTfbSga/oV3sgW7XLRaIJHC7qmX+EVcp32r9EEjxZ0Tb/CG+USrV0uGk3QaEHX9CuitIWu0XQbLeiafkXzpKiOQ9dogkULuqZf0Szo5j4eiUYz8NCCrulXDE+I4NYFIzltfEpfD0WjGXBoR6WmX2EyCe5cOKavh6HRDEi0ha7RaDSDBC3oGo1GM0jQgq7RaDSDBC3oGo1GM0jQgq7RaDSDBC3oGo1GM0jQgq7RaDSDBC3oGo1GM0gQUsq+ObEQJcDBbu6eBJSGcDi9jR5/3zKQxz+Qxw56/KEgU0qZ3N6KPhP0Y0EIsVZKOaOvx9Fd9Pj7loE8/oE8dtDj72m0y0Wj0WgGCVrQNRqNZpAwUAX9qb4ewDGix9+3DOTxD+Sxgx5/jzIgfegajUajactAtdA1Go1G04oBJ+hCiDOEELuEEHuFEPf29XgCQQiRJ4TYIoTYKIRYayxLEEJ8JoTYY7zG9/U4AYQQzwkhioUQW/2WdThWIcQvje9ilxBiYd+MupkOxn+/EOKIcf03CiHO8lvXb8YvhMgQQiwRQuwQQmwTQvzUWD4grn8n4x8o198uhFgthNhkjP/3xvIBcf0BkFIOmB/ADOwDcgAbsAkY39fjCmDceUBSq2X/D7jXeH8v8FBfj9MYyzxgGrC1q7EC443vIAzINr4bcz8c//3Ane1s26/GD6QC04z30cBuY4wD4vp3Mv6Bcv0FEGW8twLfAnMGyvWXUg44C30WsFdKuV9K6QReA87r4zF1l/OAF4z3LwDn991QmpFSfg2Ut1rc0VjPA16TUjZKKQ8Ae1HfUZ/Rwfg7ol+NX0pZKKVcb7yvAXYAwxgg17+T8XdEfxu/lFLWGh+txo9kgFx/GHgul2HAYb/P+XT+B9NfkMCnQoh1QogbjGVDpZSFoP4RgCF9Nrqu6WisA+n7uFUIsdlwyXgfmfvt+IUQWcBUlJU44K5/q/HDALn+QgizEGIjUAx8JqUcUNd/oAm6aGfZQAjTOV5KOQ04E7hFCDGvrwcUIgbK9/E4MALIBQqBvxnL++X4hRBRwCLgDilldWebtrOsP45/wFx/KaVbSpkLpAOzhBATO9m8341/oAl6PpDh9zkdKOijsQSMlLLAeC0G3kY9lhUJIVIBjNfivhthl3Q01gHxfUgpi4x/VA/wNM2Pxf1u/EIIK0oMX5ZSvmUsHjDXv73xD6Tr70VKWQksBc5gAF3/gSboa4BRQohsIYQNuBR4r4/H1ClCiEghRLT3PXA6sBU17quNza4G3u2bEQZER2N9D7hUCBEmhMgGRgGr+2B8neL9ZzS4AHX9oZ+NXwghgGeBHVLKv/utGhDXv6PxD6DrnyyEiDPehwOnAjsZINcfGFhRLsbM8lmo2fN9wK/7ejwBjDcHNRO+CdjmHTOQCHwB7DFeE/p6rMa4XkU9FjehLJBrOxsr8Gvju9gFnNlPx/8SsAXYjPonTO2P4wdOQD2ybwY2Gj9nDZTr38n4B8r1nwxsMMa5FbjPWD4grr+UUmeKajQazWBhoLlcNBqNRtMBWtA1Go1mkKAFXaPRaAYJWtA1Go1mkKAFXaPRaAYJWtA1Go1mkKAFXaPRaAYJWtA1Go1mkPD/AVwi6fck2nusAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, 2, :], label='GroundTruth')\n","plt.plot(preds[:, 2, :], label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[{"name":"stdout","output_type":"stream","text":["The index of the smallest SMAPE is:  2\n"]}],"source":["def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","# check which index has the smallest SMAPE\n","current_smape = np.Infinity\n","for i in range(14):\n","    smape = SMAPE(preds[:, i, :], trues[:, i, :])\n","    if smape < current_smape:\n","        current_smape = smape\n","        index = i\n","\n","print('The index of the smallest SMAPE is: ', index) "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0.0492226328800395\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./finbert_likes_sum_final.npy')\n","lstm_preds.shape\n","# drop the first 13 samples\n","lstm_preds = lstm_preds[13:,:]\n","lstm_preds.shape\n","\n","informer_preds = pred_inver[:, -1, :]\n","informer_preds.shape\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (lstm_preds + informer_preds) / 2\n","ensemble_preds.shape\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","SMAPE(ensemble_preds, trues[:, -1, :])\n","print(SMAPE(pred_inver[:, -1, :], trues[:, -1, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
