{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Nov  6 19:30:45 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   19C    P8     8W / 250W |    112MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1059      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1174      G   /usr/bin/gnome-shell               13MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../../../5703/dataset'\n","args.data_path = 'BAC_sentiment_sum_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 6 # encoder input size\n","args.dec_in = 6 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.00001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 12\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../../../5703/dataset', 'data_path': 'BAC_sentiment_sum_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 6, 'dec_in': 6, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 1e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 12, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import random \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 952\n","val 164\n","test 340\n","Epoch: 1 cost time: 8.466838836669922\n","Epoch: 1, Steps: 29 | Train Loss: 0.2777683 Vali Loss: 0.1258226 Test Loss: 0.2096418\n","Validation loss decreased (inf --> 0.125823).  Saving model ...\n","Updating learning rate to 1e-05\n","Epoch: 2 cost time: 7.430342674255371\n","Epoch: 2, Steps: 29 | Train Loss: 0.0880863 Vali Loss: 0.1002233 Test Loss: 0.2609696\n","Validation loss decreased (0.125823 --> 0.100223).  Saving model ...\n","Updating learning rate to 5e-06\n","Epoch: 3 cost time: 7.478466749191284\n","Epoch: 3, Steps: 29 | Train Loss: 0.0693887 Vali Loss: 0.0829253 Test Loss: 0.2182792\n","Validation loss decreased (0.100223 --> 0.082925).  Saving model ...\n","Updating learning rate to 2.5e-06\n","Epoch: 4 cost time: 7.441015720367432\n","Epoch: 4, Steps: 29 | Train Loss: 0.0647220 Vali Loss: 0.0825135 Test Loss: 0.2304008\n","Validation loss decreased (0.082925 --> 0.082514).  Saving model ...\n","Updating learning rate to 1.25e-06\n","Epoch: 5 cost time: 7.459030628204346\n","Epoch: 5, Steps: 29 | Train Loss: 0.0583169 Vali Loss: 0.0824460 Test Loss: 0.2303311\n","Validation loss decreased (0.082514 --> 0.082446).  Saving model ...\n","Updating learning rate to 6.25e-07\n","Epoch: 6 cost time: 7.409682750701904\n","Epoch: 6, Steps: 29 | Train Loss: 0.0589801 Vali Loss: 0.0786067 Test Loss: 0.2209547\n","Validation loss decreased (0.082446 --> 0.078607).  Saving model ...\n","Updating learning rate to 3.125e-07\n","Epoch: 7 cost time: 7.411337614059448\n","Epoch: 7, Steps: 29 | Train Loss: 0.0597475 Vali Loss: 0.0787051 Test Loss: 0.2167219\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 1.5625e-07\n","Epoch: 8 cost time: 7.439070463180542\n","Epoch: 8, Steps: 29 | Train Loss: 0.0599880 Vali Loss: 0.0770736 Test Loss: 0.2178741\n","Validation loss decreased (0.078607 --> 0.077074).  Saving model ...\n","Updating learning rate to 7.8125e-08\n","Epoch: 9 cost time: 7.450664281845093\n","Epoch: 9, Steps: 29 | Train Loss: 0.0586680 Vali Loss: 0.0810551 Test Loss: 0.2244931\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 3.90625e-08\n","Epoch: 10 cost time: 7.4131457805633545\n","Epoch: 10, Steps: 29 | Train Loss: 0.0582750 Vali Loss: 0.0808124 Test Loss: 0.2225832\n","EarlyStopping counter: 2 out of 12\n","Updating learning rate to 1.953125e-08\n","Epoch: 11 cost time: 7.4108500480651855\n","Epoch: 11, Steps: 29 | Train Loss: 0.0589759 Vali Loss: 0.0802791 Test Loss: 0.2166450\n","EarlyStopping counter: 3 out of 12\n","Updating learning rate to 9.765625e-09\n","Epoch: 12 cost time: 7.415414571762085\n","Epoch: 12, Steps: 29 | Train Loss: 0.0587014 Vali Loss: 0.0790763 Test Loss: 0.2199610\n","EarlyStopping counter: 4 out of 12\n","Updating learning rate to 4.8828125e-09\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.21787409484386444, mae:0.3639850318431854, smape:0.30357232689857483\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.02027  ],\n","        [1.3257866],\n","        [1.5004903],\n","        [1.485956 ],\n","        [1.563546 ],\n","        [1.4671371],\n","        [1.5154563],\n","        [1.5040219],\n","        [1.5925207],\n","        [1.6183927],\n","        [1.5010353],\n","        [1.5164062],\n","        [1.6400064],\n","        [1.093021 ]]], dtype=float32)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"ename":"NameError","evalue":"name 'setting' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2526/3772265779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/pred.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/true.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'setting' is not defined"]}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([1.862208 , 2.1652627, 2.1881347, 2.0709155, 2.1652627, 2.1423905,\n","       2.2367377, 2.2281604, 2.3024945, 2.3882654, 2.2281604, 2.225302 ,\n","       2.4625995, 2.5712414], dtype=float32)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([0.8943244, 1.2601175, 1.1687926, 1.1488801, 1.0938219, 1.2184304,\n","       1.131128 , 1.2472363, 1.1353642, 1.2205607, 1.0476714, 1.1740115,\n","       1.1111869, 1.0080222], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0.032546477741272714\n","0.06006448699057989\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./BAC_sentiment_sum_final.npy')\n","lstm_preds.shape\n","# drop the first 13 samples\n","lstm_preds = lstm_preds[13:,:]\n","lstm_preds.shape\n","\n","informer_preds = pred_inver[:, -1, :]\n","informer_preds.shape\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (lstm_preds + informer_preds) / 2\n","ensemble_preds.shape\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(SMAPE(ensemble_preds, trues[:, -1, :]))\n","print(SMAPE(pred_inver[:, -1, :], trues[:, -1, :]))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
