{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Nov  7 12:59:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   32C    P0    48W / 250W |   4264MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1064      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1180      G   /usr/bin/gnome-shell               13MiB |\n","|    0   N/A  N/A      3399      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      3469      C   ...sean/anaconda3/bin/python     2594MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'BAC_sentiment_sum_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 6 # encoder input size\n","args.dec_in = 6 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.00001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 12\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'BAC_sentiment_sum_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 6, 'dec_in': 6, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 1e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 12, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import random \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 952\n","val 164\n","test 340\n","Epoch: 1 cost time: 7.511308908462524\n","Epoch: 1, Steps: 29 | Train Loss: 0.2777683 Vali Loss: 0.1258226 Test Loss: 0.2096418\n","Validation loss decreased (inf --> 0.125823).  Saving model ...\n","Updating learning rate to 1e-05\n","Epoch: 2 cost time: 7.450637102127075\n","Epoch: 2, Steps: 29 | Train Loss: 0.0880863 Vali Loss: 0.1002233 Test Loss: 0.2609696\n","Validation loss decreased (0.125823 --> 0.100223).  Saving model ...\n","Updating learning rate to 5e-06\n","Epoch: 3 cost time: 7.43145489692688\n","Epoch: 3, Steps: 29 | Train Loss: 0.0693887 Vali Loss: 0.0829253 Test Loss: 0.2182792\n","Validation loss decreased (0.100223 --> 0.082925).  Saving model ...\n","Updating learning rate to 2.5e-06\n","Epoch: 4 cost time: 7.425131559371948\n","Epoch: 4, Steps: 29 | Train Loss: 0.0647220 Vali Loss: 0.0825135 Test Loss: 0.2304008\n","Validation loss decreased (0.082925 --> 0.082514).  Saving model ...\n","Updating learning rate to 1.25e-06\n","Epoch: 5 cost time: 7.4240031242370605\n","Epoch: 5, Steps: 29 | Train Loss: 0.0583169 Vali Loss: 0.0824460 Test Loss: 0.2303311\n","Validation loss decreased (0.082514 --> 0.082446).  Saving model ...\n","Updating learning rate to 6.25e-07\n","Epoch: 6 cost time: 7.4209840297698975\n","Epoch: 6, Steps: 29 | Train Loss: 0.0589801 Vali Loss: 0.0786067 Test Loss: 0.2209547\n","Validation loss decreased (0.082446 --> 0.078607).  Saving model ...\n","Updating learning rate to 3.125e-07\n","Epoch: 7 cost time: 7.410298585891724\n","Epoch: 7, Steps: 29 | Train Loss: 0.0597475 Vali Loss: 0.0787051 Test Loss: 0.2167219\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 1.5625e-07\n","Epoch: 8 cost time: 7.418178081512451\n","Epoch: 8, Steps: 29 | Train Loss: 0.0599880 Vali Loss: 0.0770736 Test Loss: 0.2178741\n","Validation loss decreased (0.078607 --> 0.077074).  Saving model ...\n","Updating learning rate to 7.8125e-08\n","Epoch: 9 cost time: 7.411325454711914\n","Epoch: 9, Steps: 29 | Train Loss: 0.0586680 Vali Loss: 0.0810551 Test Loss: 0.2244931\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 3.90625e-08\n","Epoch: 10 cost time: 7.409521579742432\n","Epoch: 10, Steps: 29 | Train Loss: 0.0582750 Vali Loss: 0.0808124 Test Loss: 0.2225832\n","EarlyStopping counter: 2 out of 12\n","Updating learning rate to 1.953125e-08\n","Epoch: 11 cost time: 7.415588855743408\n","Epoch: 11, Steps: 29 | Train Loss: 0.0589759 Vali Loss: 0.0802791 Test Loss: 0.2166450\n","EarlyStopping counter: 3 out of 12\n","Updating learning rate to 9.765625e-09\n","Epoch: 12 cost time: 7.41100287437439\n","Epoch: 12, Steps: 29 | Train Loss: 0.0587014 Vali Loss: 0.0790763 Test Loss: 0.2199610\n","EarlyStopping counter: 4 out of 12\n","Updating learning rate to 4.8828125e-09\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.21787409484386444, mae:0.3639850318431854, smape:0.30357232689857483\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.02027  ],\n","        [1.3257866],\n","        [1.5004903],\n","        [1.485956 ],\n","        [1.563546 ],\n","        [1.4671371],\n","        [1.5154563],\n","        [1.5040219],\n","        [1.5925207],\n","        [1.6183927],\n","        [1.5010353],\n","        [1.5164062],\n","        [1.6400064],\n","        [1.093021 ]]], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([1.862208 , 2.1652627, 2.1881347, 2.0709155, 2.1652627, 2.1423905,\n","       2.2367377, 2.2281604, 2.3024945, 2.3882654, 2.2281604, 2.225302 ,\n","       2.4625995, 2.5712414], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([0.8943244, 1.2601175, 1.1687926, 1.1488801, 1.0938219, 1.2184304,\n","       1.131128 , 1.2472363, 1.1353642, 1.2205607, 1.0476714, 1.1740115,\n","       1.1111869, 1.0080222], dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.05476126853570538\n","Smape of Informer:  0.05543040383810379\n","Smape of Ensemble:  0.04034529617933087\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./BAC_sentiment_sum_final.npy')\n","lstm_preds.shape\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (0.5*lstm_preds + 1.5*informer_preds) / 2\n","ensemble_preds.shape\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
