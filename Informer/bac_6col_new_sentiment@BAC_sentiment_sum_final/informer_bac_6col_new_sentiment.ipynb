{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Nov  7 12:59:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   32C    P0    48W / 250W |   4264MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1064      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1180      G   /usr/bin/gnome-shell               13MiB |\n","|    0   N/A  N/A      3399      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      3469      C   ...sean/anaconda3/bin/python     2594MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'BAC_sentiment_sum_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 6 # encoder input size\n","args.dec_in = 6 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.00001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 12\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'BAC_sentiment_sum_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 6, 'dec_in': 6, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 1e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 12, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import random \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 952\n","val 164\n","test 340\n","Epoch: 1 cost time: 7.511308908462524\n","Epoch: 1, Steps: 29 | Train Loss: 0.2777683 Vali Loss: 0.1258226 Test Loss: 0.2096418\n","Validation loss decreased (inf --> 0.125823).  Saving model ...\n","Updating learning rate to 1e-05\n","Epoch: 2 cost time: 7.450637102127075\n","Epoch: 2, Steps: 29 | Train Loss: 0.0880863 Vali Loss: 0.1002233 Test Loss: 0.2609696\n","Validation loss decreased (0.125823 --> 0.100223).  Saving model ...\n","Updating learning rate to 5e-06\n","Epoch: 3 cost time: 7.43145489692688\n","Epoch: 3, Steps: 29 | Train Loss: 0.0693887 Vali Loss: 0.0829253 Test Loss: 0.2182792\n","Validation loss decreased (0.100223 --> 0.082925).  Saving model ...\n","Updating learning rate to 2.5e-06\n","Epoch: 4 cost time: 7.425131559371948\n","Epoch: 4, Steps: 29 | Train Loss: 0.0647220 Vali Loss: 0.0825135 Test Loss: 0.2304008\n","Validation loss decreased (0.082925 --> 0.082514).  Saving model ...\n","Updating learning rate to 1.25e-06\n","Epoch: 5 cost time: 7.4240031242370605\n","Epoch: 5, Steps: 29 | Train Loss: 0.0583169 Vali Loss: 0.0824460 Test Loss: 0.2303311\n","Validation loss decreased (0.082514 --> 0.082446).  Saving model ...\n","Updating learning rate to 6.25e-07\n","Epoch: 6 cost time: 7.4209840297698975\n","Epoch: 6, Steps: 29 | Train Loss: 0.0589801 Vali Loss: 0.0786067 Test Loss: 0.2209547\n","Validation loss decreased (0.082446 --> 0.078607).  Saving model ...\n","Updating learning rate to 3.125e-07\n","Epoch: 7 cost time: 7.410298585891724\n","Epoch: 7, Steps: 29 | Train Loss: 0.0597475 Vali Loss: 0.0787051 Test Loss: 0.2167219\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 1.5625e-07\n","Epoch: 8 cost time: 7.418178081512451\n","Epoch: 8, Steps: 29 | Train Loss: 0.0599880 Vali Loss: 0.0770736 Test Loss: 0.2178741\n","Validation loss decreased (0.078607 --> 0.077074).  Saving model ...\n","Updating learning rate to 7.8125e-08\n","Epoch: 9 cost time: 7.411325454711914\n","Epoch: 9, Steps: 29 | Train Loss: 0.0586680 Vali Loss: 0.0810551 Test Loss: 0.2244931\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 3.90625e-08\n","Epoch: 10 cost time: 7.409521579742432\n","Epoch: 10, Steps: 29 | Train Loss: 0.0582750 Vali Loss: 0.0808124 Test Loss: 0.2225832\n","EarlyStopping counter: 2 out of 12\n","Updating learning rate to 1.953125e-08\n","Epoch: 11 cost time: 7.415588855743408\n","Epoch: 11, Steps: 29 | Train Loss: 0.0589759 Vali Loss: 0.0802791 Test Loss: 0.2166450\n","EarlyStopping counter: 3 out of 12\n","Updating learning rate to 9.765625e-09\n","Epoch: 12 cost time: 7.41100287437439\n","Epoch: 12, Steps: 29 | Train Loss: 0.0587014 Vali Loss: 0.0790763 Test Loss: 0.2199610\n","EarlyStopping counter: 4 out of 12\n","Updating learning rate to 4.8828125e-09\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.21787409484386444, mae:0.3639850318431854, smape:0.30357232689857483\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.02027  ],\n","        [1.3257866],\n","        [1.5004903],\n","        [1.485956 ],\n","        [1.563546 ],\n","        [1.4671371],\n","        [1.5154563],\n","        [1.5040219],\n","        [1.5925207],\n","        [1.6183927],\n","        [1.5010353],\n","        [1.5164062],\n","        [1.6400064],\n","        [1.093021 ]]], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([1.862208 , 2.1652627, 2.1881347, 2.0709155, 2.1652627, 2.1423905,\n","       2.2367377, 2.2281604, 2.3024945, 2.3882654, 2.2281604, 2.225302 ,\n","       2.4625995, 2.5712414], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([0.8943244, 1.2601175, 1.1687926, 1.1488801, 1.0938219, 1.2184304,\n","       1.131128 , 1.2472363, 1.1353642, 1.2205607, 1.0476714, 1.1740115,\n","       1.1111869, 1.0080222], dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.05476126853570538\n","Smape of Informer:  0.05543040383810379\n","Smape of Ensemble:  0.030849323816617036\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./BAC_sentiment_sum_final.npy')\n","lstm_preds.shape\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (lstm_preds + informer_preds) / 2\n","ensemble_preds.shape\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
