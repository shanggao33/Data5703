{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Nov  8 11:44:25 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   19C    P8    15W / 250W |    112MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1078      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1192      G   /usr/bin/gnome-shell               13MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                self.args.e_layers, # e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac_full_with_sentiment.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'BAC_sentiment_sum_final.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns in data minus 1\n","args.enc_in = 6 # encoder input size\n","args.dec_in = 6 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 #[3,2,1] # num of encoder layers if informerstack\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.00001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 12\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'BAC_sentiment_sum_final.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 6, 'dec_in': 6, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 1e-05, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 12, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import random \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 952\n","val 164\n","test 340\n","Epoch: 1 cost time: 7.511308908462524\n","Epoch: 1, Steps: 29 | Train Loss: 0.2777683 Vali Loss: 0.1258226 Test Loss: 0.2096418\n","Validation loss decreased (inf --> 0.125823).  Saving model ...\n","Updating learning rate to 1e-05\n","Epoch: 2 cost time: 7.450637102127075\n","Epoch: 2, Steps: 29 | Train Loss: 0.0880863 Vali Loss: 0.1002233 Test Loss: 0.2609696\n","Validation loss decreased (0.125823 --> 0.100223).  Saving model ...\n","Updating learning rate to 5e-06\n","Epoch: 3 cost time: 7.43145489692688\n","Epoch: 3, Steps: 29 | Train Loss: 0.0693887 Vali Loss: 0.0829253 Test Loss: 0.2182792\n","Validation loss decreased (0.100223 --> 0.082925).  Saving model ...\n","Updating learning rate to 2.5e-06\n","Epoch: 4 cost time: 7.425131559371948\n","Epoch: 4, Steps: 29 | Train Loss: 0.0647220 Vali Loss: 0.0825135 Test Loss: 0.2304008\n","Validation loss decreased (0.082925 --> 0.082514).  Saving model ...\n","Updating learning rate to 1.25e-06\n","Epoch: 5 cost time: 7.4240031242370605\n","Epoch: 5, Steps: 29 | Train Loss: 0.0583169 Vali Loss: 0.0824460 Test Loss: 0.2303311\n","Validation loss decreased (0.082514 --> 0.082446).  Saving model ...\n","Updating learning rate to 6.25e-07\n","Epoch: 6 cost time: 7.4209840297698975\n","Epoch: 6, Steps: 29 | Train Loss: 0.0589801 Vali Loss: 0.0786067 Test Loss: 0.2209547\n","Validation loss decreased (0.082446 --> 0.078607).  Saving model ...\n","Updating learning rate to 3.125e-07\n","Epoch: 7 cost time: 7.410298585891724\n","Epoch: 7, Steps: 29 | Train Loss: 0.0597475 Vali Loss: 0.0787051 Test Loss: 0.2167219\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 1.5625e-07\n","Epoch: 8 cost time: 7.418178081512451\n","Epoch: 8, Steps: 29 | Train Loss: 0.0599880 Vali Loss: 0.0770736 Test Loss: 0.2178741\n","Validation loss decreased (0.078607 --> 0.077074).  Saving model ...\n","Updating learning rate to 7.8125e-08\n","Epoch: 9 cost time: 7.411325454711914\n","Epoch: 9, Steps: 29 | Train Loss: 0.0586680 Vali Loss: 0.0810551 Test Loss: 0.2244931\n","EarlyStopping counter: 1 out of 12\n","Updating learning rate to 3.90625e-08\n","Epoch: 10 cost time: 7.409521579742432\n","Epoch: 10, Steps: 29 | Train Loss: 0.0582750 Vali Loss: 0.0808124 Test Loss: 0.2225832\n","EarlyStopping counter: 2 out of 12\n","Updating learning rate to 1.953125e-08\n","Epoch: 11 cost time: 7.415588855743408\n","Epoch: 11, Steps: 29 | Train Loss: 0.0589759 Vali Loss: 0.0802791 Test Loss: 0.2166450\n","EarlyStopping counter: 3 out of 12\n","Updating learning rate to 9.765625e-09\n","Epoch: 12 cost time: 7.41100287437439\n","Epoch: 12, Steps: 29 | Train Loss: 0.0587014 Vali Loss: 0.0790763 Test Loss: 0.2199610\n","EarlyStopping counter: 4 out of 12\n","Updating learning rate to 4.8828125e-09\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 340\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.21787409484386444, mae:0.3639850318431854, smape:0.30357232689857483\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[1.02027  ],\n","        [1.3257866],\n","        [1.5004903],\n","        [1.485956 ],\n","        [1.563546 ],\n","        [1.4671371],\n","        [1.5154563],\n","        [1.5040219],\n","        [1.5925207],\n","        [1.6183927],\n","        [1.5010353],\n","        [1.5164062],\n","        [1.6400064],\n","        [1.093021 ]]], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([1.862208 , 2.1652627, 2.1881347, 2.0709155, 2.1652627, 2.1423905,\n","       2.2367377, 2.2281604, 2.3024945, 2.3882654, 2.2281604, 2.225302 ,\n","       2.4625995, 2.5712414], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([0.8943244, 1.2601175, 1.1687926, 1.1488801, 1.0938219, 1.2184304,\n","       1.131128 , 1.2472363, 1.1353642, 1.2205607, 1.0476714, 1.1740115,\n","       1.1111869, 1.0080222], dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1765\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.05476126853570538\n","Smape of Informer:  0.05543040383810379\n","Smape of Ensemble:  0.04316680326368928\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","pred_inver.shape\n","\n","lstm_preds = np.load('./BAC_sentiment_sum_final.npy')\n","lstm_preds.shape\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (0.4*lstm_preds + 1.6*informer_preds) / 2\n","ensemble_preds.shape\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
