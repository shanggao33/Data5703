{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Nov  6 15:10:32 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   19C    P8     8W / 250W |    110MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1059      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1174      G   /usr/bin/gnome-shell               13MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def c(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                e_layers, # self.args.e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","# import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../../../5703/dataset'\n","args.data_path = 'bac.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","args.enc_in = 5 # encoder input size\n","args.dec_in = 5 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 # num of encoder layers\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../../../5703/dataset', 'data_path': 'bac.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 5, 'dec_in': 5, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 950\n","val 164\n","test 339\n","Epoch: 1 cost time: 8.1810781955719\n","Epoch: 1, Steps: 29 | Train Loss: 0.4154265 Vali Loss: 0.0684064 Test Loss: 0.1427869\n","Validation loss decreased (inf --> 0.068406).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 7.413358449935913\n","Epoch: 2, Steps: 29 | Train Loss: 0.0611279 Vali Loss: 0.0524488 Test Loss: 0.1159881\n","Validation loss decreased (0.068406 --> 0.052449).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 7.41790509223938\n","Epoch: 3, Steps: 29 | Train Loss: 0.0433687 Vali Loss: 0.0480468 Test Loss: 0.1169080\n","Validation loss decreased (0.052449 --> 0.048047).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 7.415571451187134\n","Epoch: 4, Steps: 29 | Train Loss: 0.0383795 Vali Loss: 0.0442172 Test Loss: 0.1173055\n","Validation loss decreased (0.048047 --> 0.044217).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 7.414299726486206\n","Epoch: 5, Steps: 29 | Train Loss: 0.0365114 Vali Loss: 0.0439341 Test Loss: 0.1138676\n","Validation loss decreased (0.044217 --> 0.043934).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 7.415401935577393\n","Epoch: 6, Steps: 29 | Train Loss: 0.0372512 Vali Loss: 0.0516572 Test Loss: 0.1290029\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 7.414486646652222\n","Epoch: 7, Steps: 29 | Train Loss: 0.0354067 Vali Loss: 0.0492508 Test Loss: 0.1241275\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 7.413269281387329\n","Epoch: 8, Steps: 29 | Train Loss: 0.0347471 Vali Loss: 0.0483978 Test Loss: 0.1224426\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 7.410498857498169\n","Epoch: 9, Steps: 29 | Train Loss: 0.0344538 Vali Loss: 0.0463260 Test Loss: 0.1211760\n","EarlyStopping counter: 4 out of 4\n","Early stopping\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 339\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.1138676255941391, mae:0.24152646958827972, smape:0.2557471990585327\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"ename":"NameError","evalue":"name 'Exp' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2049/3047755126.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Exp' is not defined"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","args.inverse = True\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[18.424824],\n","        [19.431557],\n","        [19.596897],\n","        [19.437403],\n","        [19.622278],\n","        [18.979614],\n","        [19.329079],\n","        [19.57586 ],\n","        [18.866402],\n","        [19.18063 ],\n","        [19.862171],\n","        [18.863277],\n","        [19.532711],\n","        [18.329174]]], dtype=float32)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([2.1674738, 2.1903505, 2.0731077, 2.1674738, 2.144597 , 2.2389634,\n","       2.2303843, 2.3047333, 2.3905213, 2.2303843, 2.2275252, 2.4648705,\n","       2.5735343, 2.4963255], dtype=float32)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["trues[-1,:,-1]"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([1.1556499, 1.3018626, 1.2832167, 1.2101624, 1.2035301, 1.1525701,\n","       1.1976925, 1.254664 , 1.2313414, 1.1520268, 1.2246318, 1.0449752,\n","       1.1959194, 1.1588285], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["preds[-1,:,-1,]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]}],"source":["flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","# pred_inver.shape\n","# informer_pred = pred_inver[:, -1, :]\n","# informer_pred.shape\n","# informer_pred"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(pred_inver[:, -1, :], label='Prediction')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["0.044761906725203325"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["SMAPE(pred_inver[:, -1, :], trues[:, -1, :])"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["(320, 1)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["lstm_preds = np.load('./bac.npy')\n","lstm_preds.shape\n","# drop the first 13 samples\n","lstm_preds = lstm_preds[13:,:]\n","lstm_preds.shape"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["(320, 1)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["informer_preds = pred_inver[:, -1, :]\n","informer_preds.shape\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (lstm_preds + informer_preds) / 2\n","ensemble_preds.shape"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["1.052919945286286"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# calculate the sMAPE\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","SMAPE(informer_pred, trues[:, -1, :])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
