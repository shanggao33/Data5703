{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Nov  7 12:56:21 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   32C    P0    48W / 250W |   4264MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1064      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1180      G   /usr/bin/gnome-shell               13MiB |\n","|    0   N/A  N/A      3399      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      3469      C   ...sean/anaconda3/bin/python     2594MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape"]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["import numpy as np\n","import torch\n","\n","def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from utils.masking import TriangularCausalMask, ProbMask\n","# from models.encoder import Encoder, EncoderLayer, ConvLayer, EncoderStack\n","# from models.decoder import Decoder, DecoderLayer\n","# from models.attn import FullAttention, ProbAttention, AttentionLayer\n","# from models.embed import DataEmbedding\n","\n","class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def c(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                e_layers, # self.args.e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# #--------------------------------#\n","# import pandas as pd\n","# # move price to the last column\n","\n","# import pandas as pd\n","# bac_full_with_sentiment = pd.read_csv('/home/sean/5703/informer/data/bac.csv')\n","# cols = list(bac_full_with_sentiment.columns.values)\n","# cols.pop(cols.index('close'))\n","# bac_full_with_sentiment = bac_full_with_sentiment[cols+['close']]\n","# bac_full_with_sentiment.to_csv('/home/sean/5703/informer/data/bac.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../dataset/bac'\n","args.data_path = 'bac.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","args.enc_in = 5 # encoder input size\n","args.dec_in = 5 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 # num of encoder layers\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32 \n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../dataset/bac', 'data_path': 'bac.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 5, 'dec_in': 5, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","    \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 950\n","val 164\n","test 339\n","Epoch: 1 cost time: 7.587549209594727\n","Epoch: 1, Steps: 29 | Train Loss: 0.4154265 Vali Loss: 0.0684064 Test Loss: 0.1427869\n","Validation loss decreased (inf --> 0.068406).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 7.425863027572632\n","Epoch: 2, Steps: 29 | Train Loss: 0.0611279 Vali Loss: 0.0524488 Test Loss: 0.1159881\n","Validation loss decreased (0.068406 --> 0.052449).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 7.421139240264893\n","Epoch: 3, Steps: 29 | Train Loss: 0.0433687 Vali Loss: 0.0480468 Test Loss: 0.1169080\n","Validation loss decreased (0.052449 --> 0.048047).  Saving model ...\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 7.423981428146362\n","Epoch: 4, Steps: 29 | Train Loss: 0.0383795 Vali Loss: 0.0442172 Test Loss: 0.1173055\n","Validation loss decreased (0.048047 --> 0.044217).  Saving model ...\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 7.420279264450073\n","Epoch: 5, Steps: 29 | Train Loss: 0.0365114 Vali Loss: 0.0439341 Test Loss: 0.1138676\n","Validation loss decreased (0.044217 --> 0.043934).  Saving model ...\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 7.421839237213135\n","Epoch: 6, Steps: 29 | Train Loss: 0.0372512 Vali Loss: 0.0516572 Test Loss: 0.1290029\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 3.125e-06\n","Epoch: 7 cost time: 7.4112489223480225\n","Epoch: 7, Steps: 29 | Train Loss: 0.0354067 Vali Loss: 0.0492508 Test Loss: 0.1241275\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 1.5625e-06\n","Epoch: 8 cost time: 7.406083345413208\n","Epoch: 8, Steps: 29 | Train Loss: 0.0347471 Vali Loss: 0.0483978 Test Loss: 0.1224426\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 7.8125e-07\n","Epoch: 9 cost time: 7.402921915054321\n","Epoch: 9, Steps: 29 | Train Loss: 0.0344538 Vali Loss: 0.0463260 Test Loss: 0.1211760\n","EarlyStopping counter: 4 out of 4\n","Early stopping\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 339\n","test shape: (10, 32, 14, 1) (10, 32, 14, 1)\n","test shape: (320, 14, 1) (320, 14, 1)\n","mse:0.1138676255941391, mae:0.24152646958827972, smape:0.2557471990585327\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","args.inverse = True\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","import numpy as np\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[{"data":{"text/plain":["array([[[18.424824],\n","        [19.431557],\n","        [19.596897],\n","        [19.437403],\n","        [19.622278],\n","        [18.979614],\n","        [19.329079],\n","        [19.57586 ],\n","        [18.866402],\n","        [19.18063 ],\n","        [19.862171],\n","        [18.863277],\n","        [19.532711],\n","        [18.329174]]], dtype=float32)"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((320, 14, 1), (320, 14, 1))"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]}],"source":["flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","# pred_inver.shape\n","# informer_pred = pred_inver[:, -1, :]\n","# informer_pred.shape\n","# informer_pred"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABUxklEQVR4nO2dd3hb5dmH71dbnvKOVzyy994kYYdZZih7Q9MPaKGFlpaW1U2BQhlhlVFmKBBGy84EshOylzOcxLHjvWVLlnS+P15J3iOOZFvmva8rl6Vzjo4eHcc/Ped5nyE0TUOhUCgUoYeutw1QKBQKRfdQAq5QKBQhihJwhUKhCFGUgCsUCkWIogRcoVAoQhRDT75ZfHy8lpmZ2ZNvqVAoFCHPxo0bSzRNS2i5vUcFPDMzkw0bNvTkWyoUCkXII4Q41NZ2FUJRKBSKEEUJuEKhUIQoSsAVCoUiROnRGHhbNDQ0kJeXR319fW+b8oPFYrGQlpaG0WjsbVMUCsVx0OsCnpeXR2RkJJmZmQghetucHxyaplFaWkpeXh5ZWVm9bY5CoTgOej2EUl9fT1xcnBLvXkIIQVxcnLoDUihCkF4XcECJdy+jrr9CEZr0CQFXKBSK/kpBZR2PfbmHA8U1AT+3EnCgsLCQK6+8kuzsbCZNmsSMGTNYvHhxj71/bm4uo0eP5osvvmD8+PGMHz+eiIgIhg0bxvjx47n22mu7dJ7Nmzfz6aef+p8/+OCDPProo8EyW6FQdIGj5XU8tXQfeeV1AT/3D17ANU3jwgsvZM6cORw4cICNGzfyzjvvkJeX1+w4l8sVdFvmzZvH5s2b2bx5M5MnT+bNN99k8+bN/Pvf//Yf43a72319SwFXKBS9j90p/2bDTPqAn/sHL+BLly7FZDKxYMEC/7aMjAzuuOMOXn31VebPn8/555/PmWeeSVlZGRdeeCFjx45l+vTpbN26FWjt6Y4ePZrc3Fxyc3MZMWIEt9xyC6NGjeLMM8+krk5+C2/cuJFx48YxY8YMnnnmmQ5tzMzM5OGHH+akk07iP//5DyeffLK/JUFJSQmZmZk4nU7uv/9+Fi1axPjx41m0aBEAO3fu5OSTTyY7O5t//vOfAb12CoWic+oapIBbjIEX8F5PI2zKQ5/sYGd+VUDPOTIligfOH9Xu/h07djBx4sR2969evZqtW7cSGxvLHXfcwYQJE/jwww9ZunQp1157LZs3b+7w/XNycnj77bd58cUXueyyy3j//fe5+uqrueGGG3jqqaeYO3cu99xzT6efw2Kx8O233wLw3HPPtdpvMpl4+OGH2bBhA08//TQgv1h2797NsmXLqK6uZtiwYfz0pz9V+d4KRQ9SpzzwnuO2225j3LhxTJkyBYAzzjiD2NhYAL799luuueYaAE499VRKS0uprKzs8HxZWVmMHz8egEmTJpGbm0tlZSUVFRXMnTsXwH/Ojvjxj3/crc9z7rnnYjabiY+PJzExkcLCwm6dR6FQdA+fB24NgoD3KQ+8I085WIwaNYr333/f//yZZ56hpKSEyZMnAxAeHu7f19YAaCEEBoMBj8fj39Y0p9psNvsf6/V66urq0DTtuFP3mtrR9P06y99u+f49EctXKBSN+DxwaxBCKD94D/zUU0+lvr6ehQsX+rfZ7fY2j50zZw5vvvkmAMuXLyc+Pp6oqCgyMzPZtGkTAJs2beLgwYMdvqfNZiM6OtofEvGds6tkZmayceNGAN577z3/9sjISKqrq4/rXAqFIrgE0wP/wQu4EIIPP/yQFStWkJWVxdSpU7nuuuv429/+1urYBx98kA0bNjB27FjuvfdeXnvtNQAuueQSysrKGD9+PAsXLmTo0KGdvu8rr7zCbbfdxowZM7Barcdl8913383ChQuZOXMmJSUl/u2nnHIKO3fubLaIqVAoepc6pxudAJM+8HIr2goLBIvJkydrLQc67Nq1ixEjRvSYDYq2Ub8HhSI4/OG/O1m0/gjbH5rX7XMIITZqmja55fYfvAeuUCgUwcTudAclhRCUgCsUCkVQqW9wYzUFR2qVgCsUCkUQsTtdhBmDk/CnBFyhUCiCSF2DB0sQMlBACbhCoVAElXqnmzAVA1coFIrQw97gCkoOOCgBB2SF4vjx4xk9ejTz589vt5CnK1x//fX+4pqbb76ZnTt3tnvs8uXLWbVqlf/5c88916zzoEKhCH3qnO6gVGGCEnAArFYrmzdvZvv27ZhMplbNojpq4doRL730EiNHjmx3f0sBX7BgQZd7fysUitCgvsGjPPCeYvbs2ezbt4/ly5dzyimncOWVVzJmzBjcbjf33HMPU6ZMYezYsTz//POA7I9y++23M3LkSM4991yKior852ra9vXzzz9n4sSJjBs3jtNOO43c3Fyee+45/vGPfzB+/Hi++eabZm1pN2/ezPTp0xk7diwXXXQR5eXl/nP++te/ZurUqQwdOpRvvvmmh6+QQqE4HuxOV9A88D7VzIrP7oVj2wJ7zgFj4Oy/dulQl8vFZ599xllnnQXAunXr2L59O1lZWbzwwgtER0ezfv16HA4Hs2bN4swzz+T7779nz549bNu2jcLCQkaOHMmNN97Y7LzFxcXccsstrFy5kqysLMrKyoiNjWXBggVERERw9913A7BkyRL/a6699lp/u9n777+fhx56iCeeeMJv57p16/j000956KGH+PrrrwNwoRQKRTCoa3AHpZUs9DUB7yXq6ur8LV9nz57NTTfdxKpVq5g6dSpZWVkAfPnll2zdutUf366srCQnJ4eVK1dyxRVXoNfrSUlJ4dRTT211/jVr1jBnzhz/uXztadujZbvZ6667jvnz5/v3X3zxxUBje1qFQtE38Xg06hs8QavE7FsC3kVPOdD4YuAtadlK9qmnnmLevOb9DD799NNOW8N2p31sR/haxKr2sApF36beFbxOhKBi4F1m3rx5LFy4kIaGBgD27t1LbW0tc+bM4Z133sHtdlNQUMCyZctavXbGjBmsWLHC32a2rKwMaL/9a3R0NDExMf749uuvv+73xhUKRegQzGk80Nc88D7MzTffTG5uLhMnTkTTNBISEvjwww+56KKLWLp0KWPGjGHo0KFtCm1CQgIvvPACF198MR6Ph8TERL766ivOP/98Lr30Uj766COeeuqpZq957bXXWLBgAXa7nezsbF555ZWe+qgKhSJA+AYaByuEotrJKgD1e1AogsGeY9XMe2IlT185gfPGpnT7PN1uJyuESBdCLBNC7BJC7BBC/Ny7PVYI8ZUQIsf7M6bb1ikUCkU/JLe0FoD0mLCgnL8rMXAX8EtN00YA04HbhBAjgXuBJZqmDQGWeJ8rFAqFwsu+ohoABiVGBOX8nQq4pmkFmqZt8j6uBnYBqcAFwGvew14DLuyuET0ZxlG0Rl1/hSI47C2sJtVmJcLcB9rJCiEygQnAWiBJ07QCkCIPJHbHAIvFQmlpqRKRXkLTNEpLS7FYLL1tikLR78gprGFwkLxvOI4sFCFEBPA+cKemaVVdzWsWQtwK3AowcODAVvvT0tLIy8ujuLi4q6YoAozFYiEtLa23zVAo+hVuj8b+4hpmDY4L2nt0ScCFEEakeL+padoH3s2FQohkTdMKhBDJQFFbr9U07QXgBZBZKC33G41Gf4WiQqFQ9BcKKutwuDxkJwTPA+9KFooA/gXs0jTt8Sa7Pgau8z6+Dvgo8OYpFApFaFJVJ6ukY8KMQXuPrnjgs4BrgG1CiM3ebb8F/gq8K4S4CTgMzG/75QqFQvHDo8YhBTzC3IsCrmnat0B7Ae/TAmuOQqFQ9A9qHLLtRoQleAXvqheKQqFQBIHqep8HrgRcoVAoQgpfCCVSeeAKhUIRWtQoD1yhUChCkxqHCyGC10oWlIArFApFUKiudxFhNgR0mEtLlIArFApFEKhxuIgMYvgElIArFApFUKipdwU1hRCUgCsUCkVQqHW6grqACUrAFQqFIihU17uIsASvChOUgCsUCkVQUDFwhUKhCFFq6lUIRaFQKEKSGodaxFQoFIqQw+PRpIArD/yHhcPlJqewurfNUCgUJ0CtM/h9UEAJeJ/jL5/u5ox/rKSgsq63TVEoFN2k1uEGIMykBPwHxda8CgAOFNficnt61xiFQtEt7F4PPNwcvD4ooAS8z5EQaQbggY93MOtvS6n1tqT08diXe1i4fH+7ry+qrkfTWo0eVSgUPYjdKT1wq1EJOC+uPMBNr673Py+udlBa4+hFi4KH7xe+r6iGwioHH3x/tNn+p5bu42+f78bjaS3S+4trmPqnJby+5hDbj1aSee//OFxq7xG7FQpFIz4BVyEUoLKugeV7i3G6PNQ53Vz4zHdc+txqGvphiKGyrqHZ8zdWH/I/bupZ78ivavVan1i/s+4IH2ySwv/J1vw23+f1NYf4y6e7TthehULRGl8IJUyFUGBwYgRuj0ZuaS0vrDzA0Yo6DpbUsmj9kd42LeA0FfBxadHsLarG6ZJfVL4p1wBf7Sps9drCqnoACirrsHknYZfXOtt8n08257O4hXevUCgCQ6MHrgScwYkRAHyTU8LCFfs4d0wyI5Oj+Hhz295lKOMT8EizgfPHpaBpjcJcWF3vP+7ZZftY0kLE8yvl/nJ7A8XVMsRUUFlPWxwpt1Na68TdRihGoVCcGD4BD1chFMhOCAfgD//diUeDe88ezsQMG7sKqvrdgl1lnYsfT07n21+fypCkSKBRhI95f758/WRSY6y8/N3BZq8tqGhMPVy2pwiAnKLWOeUOl5tjVfW4PRpl7XjoCoWi+/hCKFblgcuFALNBmnr5lHTSY8MYmRxNtcNFXnn/yZfWNI3KOicx4Saiw4ykRFsA/DnhPk98cEIkJw9NYNOhimbrAAWV9SRFySwW33U5WFLbaq3gaHkdvu89n6euUCgChwqhtMDhjQNfNzMTgJEpUUDbi3mhSl2Dmwa3RrRVxq+TbVYA8iukcBd5xTYxysyUrFjqGtzNPn9+ZR0T0mMw6Rt/rQ1ujUMtMlGONPnSK6puO8SiUCi6j93pRgiwGJSAA/Cv6yZzz7xhDEqQ8fDhAyLRCdhZ0H8E3Bf/9gl4hNlApMXQzAOPthqxGPVMzYwF4JqX1vL66lwuWbiKA8W1pMZYSYuRwp8RFwZAXnlzAT9c1vhceeAKReCxO1xYjXp0uuDNw4QQEvDTRiRx2ymD/c8tRj3psWEcLKntRasCS0sBB0iJtpJfUc876w7z79WHiIswAZAYZeHiCamEmw38/qMdbDxUDkBsuImBXuEel2YD4GhF8zBTXpkdg/c/VnE/zadXKHoTe4M76OETgOAukQaZaKuR6vqGzg8MESrsrQU82WahoLKOV77LBeCMEUn+fY//eDwNbg+LNx1lZEoUb6w5xDljkv2x8hHJUXy6raDVOsGxqnpSbFbKa50UVSkBVygCjd3hCnoRD4S4gEdaDFTXuzo/MERoywPPjAtn3cEynC4P/3fyIH511vBmrzHqdVw2JR2Av14yFoCBsdIDT4w0k2KzcrSFgFfYG7CFGTHoRDMP/C+f7WLEgCgunJAa+A+nUPyAsDt7xgMPmRBKW0SaQ9cD/3z7MX+qkY8Ku0zp8xXhAEzJjMXudOPyaP6F287wCXhchIlUm7VVDLyiroFoq5GESDPFXg+8we3h+RUHuHPRZvIr6li6u1ClGCoU3aSuwR30FEIIdQEPUQ88r9zOgjc2cvtb3zfbfrjMjl4nGOBNHwSYnh3rfzwyuWsCPmdoAnefOZQZg+JIi7G2ioFX2p3YwkzER5gprZUCfqi0cS3hvsXbuPHVDbz8bfM8c4VC0TVqHa6gF/FAyAu4MSQF3JcjunR3kX/bodJackvtpMVYMTZJA4yLMDMsKZIwk56MuPAund9i1HP7qUMwG/SkxYRRWOXg+8PlPPblHm+ueQM2q5HYcJPfy84prAEgPdbKsj3FAGzPrwzI51UofmjYnT3jgYd8DLzG4cLt0dAHOV0nkNQ0aRGraRpf7ChkwRsbiTQbmJgR0+r4m2ZnccTrnR8vQ5Nk2uVFz64C4OaTsqn0hlB0OkFFXQNuj8bewhqEgJ/MGcTvPtwO9K8ce4WiJ1Ex8C7gG1dU4wgtL9zundYBMmzy3kbZlKva4SIrvrWXfdnkdH555rBuvdfpI5NI9RYEARwoqcGjyTh7bJgRTZOx95yiatJjwjh3TDIGnSDSYqC42qEKfRSKbiAFXIVQOsQn4KG2kNn0C2f5nmKWe0MWAJneHO5AYdTruOuMof7n+4pkqCTaaiQ2Qpbdl9U62ZlfxdCkCGLCTbz/05k8Nn8coLxwhaI71DldygPvjEiLzNYIOQ+8SfbJexvzcHk0xqXbAMhswwM/US6dlMbnd84GYF+xFHBbmInYMFkUtHxPMQdKajlleCIA49JtTB8UB8BOJeAKxXHx1c5CavtKCEUI8bIQokgIsb3JtvFCiDVCiM1CiA1CiKnBNbNtGj3w0BJw35g0o16w7ahcKLzztCEkRJoZlRIdlPdM8Hrb+4t8Ai4XMQEWrtiP1ajnR+NS/MdHWYwMjA1jh1rIVCi6TIPbwy3/3gDIOoxg0xUP/FXgrBbbHgEe0jRtPHC/93nwWfYXeO8mfK30fB54qIVQar1ZKL60wPgIM6cMT2T9faf7Z2IGmpgwE3qdIKdpCMUr4GW1Tk4bkei/nj5GpUSpEIpC0QY1DlebYx1La2RW13UzMvjxlIFBt6NTAdc0bSVQ1nIz4EtKjgaCP1mhvhJW/RO2vwcHVwKh7YELAcMHyEvo63ceTHQ6QVy4yd+Z0GY1EhPeKNgTBrbOfhmVEsWhUjtVIfYFqVAEk4MltYx+4Asue351q32+5nAnDUnAZAh+hLq773An8HchxBHgUeA37R0ohLjVG2bZUFxc3N5hnbPpdWiwgzkaVkiHP9JiwIyTupqK7p+3F6h1uAk3GciIlwuWvg6Lwaapdx9lNWJu0upyXFrr0I0vnLNLeeEKhR/fLNn9xbWtqqmLa2TWVrDupFvSXQH/KXCXpmnpwF3Av9o7UNO0FzRNm6xp2uSEhITuvdvu/8HXD0LWHJhzNxz6Fgp3Ysv5gLXm27j865nwzePdO3cvUOuQK9SZ3sKcQZ154Ds/ghdOhv/+4oTeN94bB7cYdViMzRdY2irTHzZATgQ6UFAC3z0J9UrIFT9cNE2j0t7At/tK/INTdh9rPvHK54H3dQG/DvjA+/g/QHAXMY9th+Sx8OM3YMLVoDfDO1dg+vin5Ghp5IePhHUvgsfd+bn6ALVOFxFmA6NSojDqRZvhCz/VhfDhbVCSAxv+BUXdnCRfvIcYZwEAJw2Ob7Xbn7O65zMozwXkIoxOQNqe1+Cr+2HNs917b4WiH/D4V3sZ9/CX2J1uf2vrlllaPgGP97Z9DjbdFfB8YK738alATmDMaYe5v4LrPwVLNITFwpl/BGMYTFvAbYaHWJ5wJVTnw/6l4LRLMS/eE1STToRah4tws4GMuHC2PTiPSW1UX/pZ8jC46uGaD+VnXvEI5G+G8kNdf8Plf4NnpvL4sRs4V7eGB84f5d/11i3TePuW6fLJ4bXw9uXwzWMAGPQ6MiI0Jh59Xe5f+zz89y5wtJ6zqVD0Z+ob3Px7dePf3KWT0oi2GlsNlCmudhDdIjwZTDotFRJCvA2cDMQLIfKAB4BbgCeFEAagHrg1mEYiBBgbGzwx7Vb5DwjfsZx1pmlcGRYHa5+Drx6Aoh0gdHDz15A6KaimdYemOaItQxnNOLoRNr8BM38G6VPkzxV/hR2LITwebvgcotPg3WvA6v1ii0gAl0OK8IZXYObtsPLvMOJ8qCnm6fznEfqfADL+PnOQ1xt3N8B/75SPm3j5s8KOEF5ZBXPukWGqDS9DZArMvScIV0ah6Jt8siWfyroGHps/joy4MMJMBkYmR7H9aPM02+IaR4+FT6ALAq5p2hXt7OoTyhhlNVJWD4y9HNY8Izf+6Cn4+A6ZrdIXBdzhYkCUpfWOqgJY/yKMvAAGjIXP7oXwRCmeIO9Eyg+CxwUHVsCiq2HMpZDzpfzCssbA2Pky1bL8IITFydCHLQPOewJdgx2emgSf/0aKvTUGtr0rM3wq86BoJ8QPlXcvmgZCMNIowy5MugHm3guLroLVT8P0n4K5ZxZfFYre5o21hxmcGMHFE1MRQvYkmphh4/kVB3h3wxGSoy3MHpJAcbXDX3PRE4R0MyuQ6XAVdqeMja95RorfxGth2Z+haHdvm9cmdqebMHMbl37VU/IzfPO4FMi8dXDBM2DxLjDq9HDxC/Lxvq/hjUtg6R8g+xQwWmHtQhknjxgAV78PyRNg52IY+2MwywVJZtwO3z4uY93mCKgrb3z/URdDxkz49G6oOgrRaWSLfGo1C+FRKfJOaNbPYe/n8vVj5wf3QikUfYDtRyvZcqSCB84f6RdvkL36n1m2n1+9t5Ws+HCW/nIuxdUOxnpHGfpxOaG2CKJS5d9QAAl9AQ8zkltaC0kj4Yp3IH2a3JE4Aoq7ueAXJF5blUut00VhVX2zPt+AXIDd8QGkT4eyA3LBMHM2jLuy7ZMNPh2uWAQle2H8lVLQ93wKbifcslSGUgCm3Nz8dafdL4//7kmwl8HsX0DcYBnXjk6DQ9/J44p3Q3Qaqa4j7NNSGOR0E2E2SPsiU2QYRwm44gfAi98cIMyk5+KJac22T8qIQSfAo8nc8C93FnK0oo6zRic3P0HhdnjxFJmEMeL8gNoW+gJuNfpnSTLs7MYdCSOkN+pxS8+1l3G43Dzw8Q7/81adynK/heoCGdqwRMv49QVPg66DdeZhZ8l/AMPOkeJ68q8bxbsthID4IfLcTbHa5M+EEfLnykcheiBx9bms1wYTXlnP4MQIac+oC2H9S9J7t3awAKtQhDiHSmv5ZEs+N8/ObjbqEGQl+Jg0G5V2J0fK67jj7e8x6XVcPzOz+Ul8CRUJzcchBoKQbmYFEB1moqpe9rQGqHO6ueZfazliGCizN/K/hy3vgLt3qzWPVTZvy9rqRmr1MzJmPewcGHIGXPGWzLjpKpYouOkLGHTqiRkaHie99sKd8NZlhNUdY78nhdvf2uSf2cm4K6Sn//2bJ/ZeCkUf59Ntx/BocOOsrDb3L7xqIm/fOp0Fc7MZkxrNo/PHNZuoBci7WZ0RYto+x4kQ+gJulT2tff1Q9hRW801OCTcu8Urky/Ng8U9kCX4v4hssfLs3f7RZeXreBsj5Aqb+BEyBbSfbLc59DC5/EyoO4bHEsNY0jd3Hqvkmx1tJmzwWBs6AdS+ETO69QtEdth2tYGBsWGtR9pJis5IcbeWeecN5/6czOXtMcuuDivfIu1594AMeIS/gNu9tjc87LPDOf8zR0ngi4SE8yRMgeqD0cL1NsJqiaRqbDpf7+2QHizyvXfMnp/G3S8Zw95nD5F3B2hfgnSuljdOCm415XGTNhp99j+6Xu3n519cBNJ9uP+0nUHFIZsAoFP2ULUcqGdNGm4k2KT8EdRWttxfvDkr4BPqDgHsnuPvi4PneUMUVU9N54sgQlp30piy/P7YVdn3c6vVPfJ3Dxc+u4hfvbg6qnfkVdQgBydFWfjxlIIlRFlj+Z/jsHgiLh6ve7Xvx5JhMMFqIshiJshiaD0cefp5czFz7XJtfjApFqOBye7hv8TZ2H2telFNa4+BoRV2bfYJaUbofnp0BC2fK8KMPp11WNisBbxu/gDfxwM0GHTfPzga8wx7GXwVJo2X+c0PzWPRKb1igmXcZBI6W15EYaW7sUFa6XxbbTLgG/m+VzJrpw6TFhJHX9BrpjTB9ARxYLlM2FYoQZevRSt5ce5h31+e12g4wJtXW9gsdNbKGQtPgw/+TfxMNdbJ62kfRLkCDxOAIeMhnofhWhivssg9vQWU9KTarv9VsVb1Lxp7OeBjeuFh64WMv87/eJ0rV9S40TWuW59ldSmocOF0eUmxWlu4uJCHCwtGKumazKdm/VP486a4Tfr+eIDXGymFvK1o/M+6Q3sbKv8OEq6THrlAEiKMVdRj1gsTItuPPJ0qD28MlC1fR4JZ3kBsPlzfbvy2vEiFgdGrrRm94PPDquVBbDGc/AkfWwDmPSm977XNyXeuzX8lCPGhMbw4wIe+BR1tl0xhfDDy/so7kaAuRZu+4NV+v8OxTaIjKIH/JQjSPB5D9DYqrHURZDDjdHqrsjubZKprWrUW6G19dz8y/LmX5niJufHUDt76+gfyKOlKaCvjBFRCdDrHZ3fjUPU9ajJW8cjta03CJTgen/V6mJm56vfeMU/RLLn9hNVP/tISCyuDcHS/ZVcTWvEp2efuZ7DhaSX1D49/71rwKsuPDWw06kTsXQcFmqMqXrSws0bK+YuxlslL65bNkK4y9n0HsIIgcEJTP0A8EvHkMvKCinuRoKxajDoNONE7r0el4w306KZWbsC+6EaoLyffGdMcPjGGs2E/4M2PhwwXy+AMr4LHh8HAcbP3Pcdm0u0A2e7r+lfWAd3pHeTm3lj8Gez6XYZyD30DW3IBXZgWLVJuVWqe7MZXQR3QaDD4DtrytYuGKgHKkTP59/vF/wSnIe2f9YX9Pooy4MFwejS1HKvz7t+ZVMq5lVSXIMMnSP0DKBLjmAxh9CZz1VzCFyxYYs+6ULS6Gems0MmYExX7oByEUk0FHmElPZV0DLreHoup6UmwWhBBEWAzNpvW8Z/wRFQ0V/HzvR/DctxSfuRiAySkWfnzoMQz2Ctj2H5nO99aPwTZQFgFteeu4qg6TbRYOldq5ZnoGtQ4XH3yfx0vGfzK2+HtY/I0sda+vkGX/IUJajExvzCuvwxbWolXm4NNlGmRlHtjSe8E6RX+j6aDylXuLcbk9GPSB8zfdHo1V+0q5enoGI5IjGZ0azYXPfMei9UeYlh1HYVU9RdWO1hkoDXXw2a9lq4mLX4DMk5rXXggBZzwkH5fuh/3LYMiZAbO7JSHvgQNEmA3U1LsorXXi0ZAZHsiJPU3/I9giLDzpvoQbzX+ntqYKz3u3Ahrn2j8iSVSwacqjIPTw1nxwO+CKt2H0xdJbru/6cN+yWifXz8zkDxeOZubgeGbrtnG6/ntKR10vu/55GuCq92Fo8H6xgcbXYa24jTmApHkbhh3d2IMWKfozvqSCeaOSqK53sSWvonn47gQpqKzD6fYwJCmC+ZPTGZEcxfWzMlm8+Sh7C6t5Y41sHTs+3SZfcHgtfHGfbLe86TWYfpsU746IGwR374URPwqY3S3pHwJuMVDjdPm97SjvAmaE2dhs4LGvWnN5RRL/ENcyQ7+Tm/Sfkr3zGb5yT2KL7XRZyu60y2rDuEEw7FwpuLs/7ZItDW4P1fUuTq74ANY+T1aclbsM73FUiyfs3L/AXTvgtvUw5PQAX4XgEhPWfLG4GUmjQW+Coxt62CpFf+VohVwwv2yyvKO7ZOFqnlq6TzoJAehH75sNmxHbWDh380nZaBr846u9PLV0H5dOSpMCXrBFJkCsflpmXf3oKTiri5lXVltQw6T9Q8C9Hnit19uO8Hb6i/SGUHIKq7nzne8paFLOnjj3Fg54BvB745tgMPGA+0ZKahww4//g7j1w3hPywPRpsj/IN49Bzlfw5Dh4fCRsf7/RgNL9cuwbUG53ki3ymXPwCfj6IYaWLmWibh9vm+djDQuT5fFBqMgKNjHesEl5bRsDjg1mGfs7sr6HrVL0V3zZYWNSo7lmegZmnKRsegxePBVevxictSd0fr+AxzeOM0yINJMRF8ahHWv4neF1fj/HhnA54P2bwRwF134sG1JNvPaE3juQhJ6StEGE2UCtw+UPl/gF3GygoLKei55d1SyUAnD66FQSst6h4sAKbGPOwf3iYUqqvd6lt6BG0zSeWb6fyyb/ksTPboY3L4X4YXJ4wns3ykW7qFQZL3dUws1LKTcM5RcGb9l+Qy2Rn9zMURLISQnebVRPEGU1IkQ7HjjIplpL/wg7P4aRof1ZFb3P0fI6TAYd8RFm/nD+cG7ffQ1JtQfQMmcjcr9Be2wEv4t4gGvmz2f4gDbS/DrhUGktJr2ueV9+dwN/ML7KLNNH6IUGb26DyCTZ8fPqDyB7bvsn7CX6jwfuaAyhRFgaPfCdBVXNxPucMQP43bkjyE6IIDJzArZT74SEocRHmCmqbl7kc6yqnke/3MtbVd55nGf9TTaMuvELGDhTJu+/dZns/hcWB8v+SE3RIc7SraNg+PVykAKwf9bfufWU4CTy9xR6nSDaaqTc3oYHDjDz55A0RhX1KALCkXI7qTYrOp2APZ+SVH+AexpuZecZb3CH9a9UufTMK3qF/24p6Nb5D5XaSY+1otc1CW9seo05FR/ypvt03hj6T5n6V3EELn4JBp8WoE8WWPqNB15d3+iB+3LAfULelKmZsVzfRmextBgr+4ub35b5buOKapyt+/j++A348j44ugmufEd6nl8/QFqtBx0adeNvgLPvBqFjTmRSID5mrxMTZqK8PQ/cYJJx/VVPy1z6EAwTKfoGq/aX8OWOQn40LkVuWPcCzog03i+Zg/u7XD4pH0i6/nR+ZXyX/+WshXnDjvs9cktryYzzhk+2viv/jrcuwp48lQdzr+eNadNh0HUB/FTBoX944BYDtc4mMXC/B+4VcrOBzDi5WBHXzrijzPhwDpfa/QudAEfKZJyssEUrWADC4yg49R88MvjfvLJLoE28DozhJB1bzmLPSUQlD4aoZHkL1k+whTXpvd4WcYPlgm/l4Z4zStHveGbZPgZEW3jwglFQWwq536KfcBVGg4EPNh0F4E336RRr0fys+CEcpd5hw10surM7XewvrmFIUqRM8/vgFplZEptF2IVPsOF3ZzbOiu3j9As3ybeI6cs4CTfr/dtBetcpNiu5pXbiIkxtniMrLhyn28N/t+YzPt3Gnz/dRW6JV8BbhFY0TWNHfhW/XbyNrXkyvfDU4SeTMetnFK3/gAdKr2NTy1zpfkBMmInCqja+zHzEyVa5lO4PmQpTRd9jb2ENJw9NIMpihK1LAA398LO4us7Cv749iF4nqNNF8dLAv3H74bsQL50GcVkyC2rC1XDu47IvSTtsyC2nwa0xIzsWliyQFdG3b/APTj+OLvy9Tr8Q8HCzAZdHo7TWiUmvw2yQAu5LJ0yMspDlXW2OC2/bA8/w3k79/J3N3rLxxvLdwqrmuc/LvCXyAHefOZRHv9zL6v2lZJx8LwurzkNsPNrYtKofYQszsudYBylcfgHfJ4dSKBTHSYXdSXG1gyFJ3oHZe7+Q/USSx3ObzcXb6w7z+/NGctaoARgNOm74SzW/d71BXHEpCSMuwrTp3zijMimt85BculZmjDRZVM8rt/P2usMYdIJp9d/KgS8XPOsX71CjXwi4r3HVscr65nFvb/5lUqSZ8ek2wkx6km1t/6KymqQT5bXoTFhS42hWCbbbK2LvLZjBpIwYXlt9iNUHSrl86kDyK+uJbcfLD3U6jIGDXMi1REsBVyi6QY63L/+QpEgZEtn3NQw/F3Q6YsNN7HhoXrOGczNnncyPlqQC8MTgcZxbX4lp+cMkAw5TDOYDy+DuHP90q9ve3MSWvErGpkRi+eZBmVU27vKe/pgBo18IuC9Ucqyq3v8YGqf0pNisnDc2mbnDvLdlbZAU1dwz1+uEPx6uaXLR48kl+7hgXAqHSuzER5iZnCn/U0zPjmPV/lLKa52s2FvMJS2Gn/YXYsKM2J1uHC63/y6nGUJILzx/s7xoIdLnRdF32FsonaMhiRGQt162nGhyN9eyW+jNs7MQQvb1X7jiAI8UX8SFIo6KqCHsrbHynv4+Oex7zGXgqGZfoWxc9beJZfD1HrjohT4xM7e79AsBD/eKdmFlPdFNYs9XTcvgSFmd95cs2hVvkP8xYsKMJEZaSI2xMiHdxmNf7fVPnf7w+3w+2SL/mQ06Rqc29ki4dFIan2zJ54oX11Df4OGiCanB+7C9iK8HSoW9gaSodv7Tj5kPn98L37/epwoeFKFBTmEN4Sa9bL286UvZ2iL7lHaPj7QYufP0oWw+UsHyPcUMjE1l3hWPEBtu4rTHllNhScT20W3w0W0AfKxLoTZ9MiM2bpV3jKMu7KFPFhz6hYBHegW8oKre33QJZKfCv1w8psvnWf2b0xACv3c5e2gCdoeLK19ay7I9Rf7jHC4PGXGN7zN3aAK3zsnmhZUHGD4gkkkZfWyyToDwVWOW1TpJimonZjj1J7BjMaz4O4y/WracVSi6yHf7ShiTFi2Hfu/8WM5etdo6fd2UzFiW7ynmxlmZjPP2L7loQhrPbD2H36ZtRQydh10zYVv+OAPLvgJbKsz5lawiDmH6hYD74t6a1nbud1exGJt7lePTbZTXypjvjvwqsuPDMRl07D5WTUZseLNjf3vOCO48fQhmgz4gQyH6Iqkxsp/5kTI7I5LbqX7T6eRU+w9ugcOrOm/4o1B4ySmsJqeohmtmjIIDy6A0R45D7AIXTUglr7yO+ZMbu2EOSgznz84z+dm1jxJpMZJfVM3FX6Tyl/PGce6U0C6s89Ev3KPwJnHvpjHwQBATbmJalox1j0iO8k/VSYxq/c0dZjI0r+zqZ2R5M3VySzvpQzH8XDBFwJZ3esAqRX/hPxvzEALOGpEAKx+F8AQYdVGXXptis/KXi8c00wLfXWJhlYP8ijo2HiqnighsMaGR490V+oUHHtlUwE/AA2+PM0cNYO3BMsLNei4Yn8KS3UWMSY3u/IX9jOgwIzFhRg6W2Ds+0BQum9nv+UxmEoTwIlG3+OI+MIbBKb9VC7ldZNnuIl785gDXjrKQ+PUdcOg7+NHTJxTi8I1iK6yq56qX1vq3x7dTzBeK9AsBbyragfbAAS6bnMaaA6XcOmcQgxMj2PbgmW2PWfoBkBEXzidb8tlZUMWAKDPPXjWp7buO4efA9vfgyLqgTiTpc5QdlG1HAYQOTvlN79oTIry59hCDo+CB8l/LuZJz74WJ15zQOX13yb7e3j7i+1Gab78IoViNen+/aqsx8N5epMXIi9dOZnBihP/5D5Ws+HBqHC62HKngix2FHGuvMnPwGaAzwp7/9ayBvc3mNwEB6dPhuyfkzMRAc2w71FcF/ry9hNujsfZgGQ9ELkZXtl+OKQvAF58vhPLZ9mPNtreaKBXC9AsBF0Lw7k9mcO6YZE4bkdjb5vRrfEVTad4FzWNt9YkBsETBwOmyAf4PiR2LIftkuPh5GT764FbI+br7/avtZfKfj/zN8Nws+Or3gbC2R6hxuNqdprN8TxFzHllGbb2TydXLYPh5kDUnIO8bYTb4Z17OGhzn396f1qn6hYCDrNx65qqJjG1rCKkiYMwcJP8Q7jx9KEDHvVGy5khvsakA9WeqC2UV6qBTISYTLngGDq2CNy+RvdK7w78vgEey5Ei/L+6DNy6R2/O/D5jZwWTdwTJGP/AF/9vW2Pb1WGU9v35vK4vWHeLht5dxtKKOSWIvFkdJwOfEOlweAM4enRzQ8/YV+kUMXNFzzBs1gB0PzaO+QXZ+61DAM2cDmlyQatmOtx9xrLyWmvo6Bpd+JzdkzJI/x/0Y0qfA57+F79+EU38nF3i7iscNx7bKx+/fDDlfQspE2ae6LLfPV7vWN7i5a9FmADYeKue8sbI97LsbjrBow2EmbH6RpYblHB36I1xuDY6ZYei8gNrgq6Yen25jRnacv9Fdf6HfeOCKnkEIQbjZQGy4CZNe134MHCB1kszG2OadUHRwZb+K3fo48K/riX9+PBuXf4hDZ4XkcY07Y7Nh1s/lxKYdHx7fiUv3y5+mSCneABc9B1NvlecrOxAQ+4PFa6tyOVoh+wr5hq2ADJvcFbuayw3LcWfNJfXwx2Qc/UTWD5gjg2LLsAGRvH3rdF66bkpQzt9bKAFXdAshBIlR5rZ7pfswmGDmz2Dnh/DdP+G18+GzX/eYjT2B5nEzs+ZLbFQzqeQjljWM5us9pc0PGjgdIpNh31fHd3Kf933B04CA+KGQMAxSxsvteX13BqnHo7FwxX5OHpbA+HQbBZVSyMtrnRw4ksfNDW9D+nT0134kv+CiB3a5aOd4+N/PTuLZqyZi1PdPqev0UwkhXhZCFAkhtrfYfocQYo8QYocQ4pHgmajoqwyIsvDJ1gL+8dXe9g+acw8kDIevH5DPt74DJTk9Y2APULJ/o//xAc8A/iRu4ZVVB5sfJIRc2DywAjyerp/82FaZyTPsHBl+OeW3cnviSCl4//slfPsENNR1eJreoKq+gQp7A7OHJJBis1BQUQ9uF3kfPcQq0x2EucrhjIfltTnjYfj5Fn/HwEAyKiWac8b0z/g3dM0DfxU4q+kGIcQpwAXAWE3TRgGPBt40RV8nMcqM26Px5JKcZpOMmqE3wKQbQPOAbSAg+k2FZnmtk+3ffATA6dqzXGV6kpljR7Ajv6p11kX2KVBX1uhVdwFP/mY8CSPkncycu2HURby59hA7C+vkbNb0qfKL8V9nyAXUPoRvdmpsuJHkaCv5lXa0T+9mzN6n2WCcBLcuh4HTGl+geuZ0i06vmqZpK4GWaQQ/Bf6qaZrDe0xRqxcq+j1ltY29wdudVg8w9jJZWj/uShkXP7iiB6wLPk8uycF+cB25niQev+VcnrtuOqNTo6iwN1DQMrTkm2ie+03XTu7x4Di0gWU16RRV1VNe62TdwTLuW7yd+z7cBlEpcM1iuPJdKNkHi289Pu8+yPj+b9jCTCRHW7jJsxix8RWedf2IvXOfQTRdJ1B0m+5+7Q0FZgsh1gohVggh2l0ZEELcKoTYIITYUFxc3M23U/RFfnHGMH/hVFMxb0VYLNyxSXqR2SfD0Y0yLS7EOVpRR4YoQovNZmyajXHpNkamyCZfO/NbLNZGDpCphYfXdHxSTQOXA0r2YvXU8lVVOtP/soSpf/6av3y2CwCbtUkh2dB5cNafZb79vq8D9+FOEN8XepL7GBdsu417jO/ygfskVmXcxuVTB/aydf2H7gq4AYgBpgP3AO+KdlrwaZr2gqZpkzVNm5yQkNDNt1P0RaZmxfLSdZMBKO1IwEEOd9YbpSeqeSD32x6wMLhU1DrI1heRNWS0f9uwAVEIATsL2si2SZ8mWwu0U9QCyEXef06kbufnAKx3DcKjQYNb4/vDFQDUOlsM7x13BegMcHj1iX6kgFFubyCKGoZ9/CNiy7fxh4ar+VXDrbx207SgtLv4odJdAc8DPtAk6wAP0H9afCm6TNMe4V0idTLoTZ17oiGAs6aUMM0OsVn+bRFmA5lx4ez0Dr3+YkeTMu70aVBbBOUH2zgbULwX1r8IVXmYV/6JKi2MA1rjAty0rFjOHj2g9bU2WmHAmD6VlaIV7eJa/Vfo68txXfUBx0bexCc/P6VfVUH2Bbor4B8CpwIIIYYCJqAkQDYpQoi4iOMUcKMFksdLb3HXf6GhgzTEPk5YzRH5ICar2faRyVGsyy3jrbWH+cnrjVkqZMyUP3PaTifUNr0ms05m3Ul5eBb/cF2CXqfHZNCx7r7TeP2macRFmCitcbR+cdpUOLoJ3K7W+4LNF/fBK+fA3i/l3cXSP3Hp2vncbfwPWtJozJlTeeaqie33kFd0m66kEb4NrAaGCSHyhBA3AS8D2d7UwneA67T2mh0o+jXH7YGDzJ7IWw+LroIvQrNbX32Dm4QGb6Oq2BYCnhLlvx7NAouJI+QdyJe/h92fgqvxmr22Kpfvvl2GJ3EUnPEQj2S8xEeWC5ieHcf07DgSIy2YDDpiw81U1DW0zvpJmwINtVC0Mxgft208HrTNb8Pqp3HkbYb3bpCjy1Y+whbbaWwQoxCnhk7PllCkK1koV2ialqxpmlHTtDRN0/6laZpT07SrNU0brWnaRE3TlvaEsYq+h8mgI9JiOD4BT53U+HjDy7JfSohRUuNgoPCm7sVkNts3somn2ar39Iz/A7cD3rkC3rgYKo8CsuXpMN0RisMGAbA9v5KRyVE8e/VEnrlygv/lceEmNA3KW2b9pHiPOY40xRPmy98hPlzALs9AzrY/hOZxy26MM+/gudjf8JvIv8Cwszo/j6LbqORLxQkTF27qfBGzKYNPk8Upl70unxfuCI5hQaSkxkmGKKTemihj0E3wZaIA2B0tQhojL4LL34JzHpULms9Oh6p8piS4SBBVbHOlUd/gZs+xasamRRNlMTZrXxwbLu94SmtaXO/YLDCGw7Ftgf2gbeFyQNlBtC1vsYwpXOh8mANaCgUXvAM3L4Ez/0h5XYP/7kwRPJSAK06YmHATZbVtxGXbwxINV7ztbVwkoGx/0GwLFiXVDgbqinBFZbbalxhpZoC3F3Wt0011fUPjTp1Ojpybegvc/BU4qmDnxwyol31NPi2K5aPNR3F5tDY7a/rWHNbllvkbisnz6iFpVM8I+P9+Af8cj6gr5x3nLH5/4UQAVjkHQ5rMSqqwN2AL++H2ze8plIArTpi4cBNltQ2dH9gSgxmi03unKVNVvj980R1KahxkiEJEi/g3yD4xi34ynQfPHwl00LExeZxsM7D7vyTVyNj1svIEfv2+FOGxaa3H9sWFy5DM7z/czosrW1y3AWOkgAdzOaqmGLa+63+aHzeTK6cOJMpiYOMhWe+37mAZewqr/XcLiuChBFxxwsSGmyhpKzOiK8RlN3bd6wkcNVCwFR4fAS+d3u3TlFdWMkCUY0oc1Ob+jLhwhg2QoZTCqg6uzfDz4NB3nF79ETnmkXz+28YhvsnRllaHNxXFb/aVsKugiga3twJzwBjp0beXphgINr8BbieOyxZxtev3TB+ejk4nmJIZy5oDZWiaxs2vyXTGQQkRwbNDASgBVwSA7IQIiqsdHZfTt0dsds954O4GOSDh+dnyeXW+9Ci7QV2htNkY37aAAwzwCnC7U4tAhlLCE4nzlLI87gqSoixs+v0ZLPnlXNqqjYtpEpZYd7CMs5/8hjd9Mx8HemePBmkK0oHiGopXv4UnbQof1IzkW9cIThoii/NmDY7nYEktOwuqqKp3sWDuIG6e3fruRBFYlIArTpjRKfJWf0fL8vGuEDsI6iuCM7WnZU70qn/C0Q0w607wpbc9Ohi+euC4T91Q4r1riGlfpHxx8A57pkcOgGs+4BlxBYcT5Cix2HBTu96rQa/jrVum8fhljb1Edh+rlg8ShoEtA/Z+cRyfpOt88NVyEmr38u/KifzmAxnmmZopOwjOHiLr+Batl7nx49Ki2/wCUgQWJeCKE2aUN+ti+9Fu9DeJzZY/A+2F7/4f/GkAHGlSnbj7U1kNecZDcNJdjdu/ewI2vQ5L/9TlUWWGylz5oI0YuA+rSU9CpJn9xTX+bZqm8eWOY41hD0BLHMk/HD8i0to6ZNIWMwfFM2/UAAYlyOk+B0q88zaFgKFnSQ+8uzM428Hj0bDs+wyAhcVjCDfpWXjVRKzemZODEyNIijLz4fdyXSEtJiyg769oGyXgihMmJtxEqs3Ktu4IeJw3BHGiAl5f2XzxbuOr4GmA926UYua0Q8HmxmpInR4ufRkufkmOQPv4dlj5iBx/1gkVdicnuddSZUkBa0yHx45MjmJXQbX/+eoDpdz6+kb+9L9d/m11DW5cHo0oa9ezNsLNBpb88mSunDaQPceqG9vXjrkUXPWwoo0W/c5aqKvo8ns0ZUd+FWMatrJXS6eQWP51/RTObtJnWwjB5IxYqryTd1JjrO2dShFAlIArAsKolCh2tdXAqTNsGYA4sYXMiiPw1wy5KFm8V5bn534nJ9hUHoY1C2UHRI+rMU4MMPoSGDsfrnpPjikLT5Qhlk7GvhVu/Zpput0UDL++05mUI1Oi2FdUjdM7XDevXA5f+PfqXDzeasrKOpnBE2U5/rS7EQMiqaxraAzTpE+FCdfAqqfkdWnK01Pgkezjfg+AZTuPMlm3B/PgOVw3I4NpWa2HL4xPtwEQZtI3i9UrgocScEVASLFZKaruRiaK0QLRaSfmgR9ZC2hSfJ+dJsu5G2ph3p9h6Nmw4m/w0f8BQgpcS0xhcM7f4bJ/g9sJXz/Yfgji4DcM/uIajmkxmKde36lpI5OjaHBr5BRJL/xQqTyvR5PDfQGq6qTXGn0cHriP4d6qz91NvHxm/xI0N2z7T+M2px2qjsrtTe9UdizuUu74kR2rCBcOMiaeyUMXjG4zvj1+oA2AVJtVxb97CCXgioAQE2aiut7VLLbrQ9M0Fry+kc+3H2vjlXgzUU7AA8//HvRm+MVu2Wtk+3uQNRcGnQrnPwmTroe4IXDa/R2HPNKnyrS+Df+CJX9otXv70Uo+f+9FXBi52PMIaUmdt0f2VWXuOFpFQWUduSV20mOtzBwUx0Of7KSoup4qb6FPlPX426xmxMlY8+Eye+PG2CwZ69+6qFGsmw7RqCuXP90uWLxAfmF1QFFVPZElm71vOLPd40anRKPXCRU+6UGUgCsCQmy49B5b9ehAxng/33GMBW9sbLVPvvgEUwkLtsCA0RCVLMvUT/md9KZ1etmH/Jy/wzUfwOxfdHwenR4ufxPGXAbfvwGO6ma7Fy7fT1z1Lra60xmUmYGhC4NyM+PCSbVZeXJJDjP/upT/bSsgKz6Cu+cNo67BzfeHK6g6gRBKfLgZk0FHfkWLuZjjroDi3fD+TbBwFqz8e+O+8lz5s2y/jJcf/KbDRc/VB0oZLI7iMsdARGK7x1lNeq6dkcF5Y1OO+3MouocScEVAiPEWmJS3UZFZYW/c1mbTyrhB0iusOHz8b+zxSAFPHi+fRyTA3HvAajv+c/mYtgCc1bDuhWaboy06RopDbPdkMT07rkun0usEd54+hKMVdX5nOCM2jKFJkQDkFFY3xsC7EULR6QSpNit5bQl4xADY/j4U78ZTsI3dg26S+3zXudDbRMztkAOX26Ggsp5BunxEwtBO7Xng/FFcOintuD+HonsoAVcEhNgO2so2FXB/yltTBp8uGzG9fpEstjke8jfJ6sO0dqf6HT9pk2QoZeWjzcrttdJ9hAsH2z1ZzBjUNQEHuHhiGveePZyzRw8ApKhHmA2k2qzkFNX452d2JwYOkGKztPbAjRY48w8ypPTzLcyyP8b8Hd4F3Apv4c+x7XKSj8EKB1e2e/7iageDRAH6Lgi4omdRAq4ICLHeJktthVAq6hq3bchto2AncQSc/iCU7oPqduLk7fH9G1KAhp97fK/rjDP/CA122PqOf1NkuexXkjlmOmNTW/cpaQ+9TrBg7iB+f95IBsaG+T3UwYkRbM2r5NVVuUzOiOl25kaqzcrR8rrWO8ZeBrcsgeg0CoijmjCw2Jp74PHD5B1QByGsmopi4kWlzOpR9CmUgCsCQkceeGUTD7zVtHYf4d6JfM6atve3hcspQwSjLgRLgKe9xGbJZlN7vwRk6Ceudj9uoeeO+ed2Kf7dkhSblZW/OoXRXvEfkhjBwZJaiqsd3Hv28G5nbqTawiiqduBwuTs/OCYDyr0eeOEO2cEwNqv9/iluF5MLvc2rlID3OZSAKwKCLcwXA28t4OVNBLy6vp2RXyZv6bjjOAS8ZI8MnwzuWlMqp8tzfIMnhsyDvHVgL6Os1km2doSqsAwwBKbL3uBE+ZlvmJXJ5MzWedVdJcXWcc+VpusOHlum9LbtZTKtcMBo2Q6g/JBcT2jJro+ZX/2GfJw0sts2KoKDEnBFQDAZdESaDZR1EEKxhRmb98Zuitkr4E098M7aohZ5qxmTRrXa1dIbrXO6mf/8as54fIV/0bBThs4DzQP7lnC0oo4hIg9HTOC80AsnpPLKDVO4/7wTE0Zf2l5eW2EUmn+BNsQMklkovpYBPg/c7ZDNvVpyZB0Az454HWwDT8hOReBRAq4IGDHhpjY98Ep7A2aDjoQIcwceuOzr4Rfw5X+Fx4Z1PPS4cIccAhw3uNnmZXuKGPa7z5v1Znl+5X625lVQWuvk+RVdzDlPmQhh8ZDzBQXFZQwUReiSRnTttV3AYtRzyrDEEy56GZIoM1r2HKtuc3/TfuT10YNkMc/u/8oNSWMaG3KVtQ6jePLWs9YzHC1Red99ESXgioARE26izN52GqEtzEikxdB5CMWXj7z8L1BTKItq2qNop4zL6psv/m3MlYUqi79vzCDJKaohMy6cc8ck88aaQ20WHLVCp4MhZ8C+r3EX7kQnNMwprb393iYh0kxCpJmd7bQyaFoha4/0ivWOxfLLKSKxsaFYyzi4y4k4to3NnkEkRLaY7anoEygBVwSM2DBjm6PVKuqc2KwmIi1Gf9VhK8zSi8RR7W0t6/VK1z7f/hsW7mwzLmsyyP/WW45U+Lcdq6xnQJSF88elUFXv4rcfbOM/G460em0rhpwJdeWM2PMMAGEDJ3Tygt5hZHIUO9tp59vUA68Kz5QP6spl/FsI2crAYJHXsyl7P0O4HWzxDCJRCXifRAm4ImAMiLZQUNE65FFhbyC6Uw/cF0KphcOrAU2Wwlccanths64CqvKgjVt730LllrwK/5CJY5X1JNsszBkqs13+szGPX72/lVX7Szr+UMPOgeh0sspXsZoxGBMGd3x8LzEyJYqcJk2zfJTXOnlvQ57/ea1o0uZ10g3yp04vS+9zv4WGOrnIeWQ92n9uYI+WzkrPWNJUeXyfRAm4ImCkx4ZRWuuktsUk9sq6BmxWOV293UVMYxggZAz88GrQm2D8VXJf8Z7Wx3ewgFnqFXC3R+PvX+zB7dEorKonOdpCmMnAWaMGEGkxkBZj5cmvc/yva7NK1GiB0x/Eg2CR9fJOr0FvMcLbNGtfUfMvu3ve28K6Jrn3dU43jLwQUifByAsaD8yaDYXbZA/1f06Af/+IOmMM8x338+yNJzPYG2dX9C2UgCsCRrq3if/Mvy7l/95s7Hvii4FHWQ3+ftGtEELGwR01cnEycURjeXzx7tbHF+0AoD52GM+v2M/b6w77p7SX1TqYONDGtTMyeWvdYfYcq8bl0RgQLb3IJ68Yz7rfns5pw5PYmleJy+1h97EqZj+yjD9/uqv1e425lAVJb5MXNbF7F6YH8A138HU7BFifW8bXu4q4dkYGf7l4DOAV8Pmvwk1fN2+FmznH/9Az/TZosPNGxA1ERMcxZ2jnTbsUvcPxtz9TKNphYKwU8Mq6Bj7dJisq6xvclNY6iI8wE2424HR5cLjcmA361icwR0gPvHCnDJ/EZMoug8W7wOOWt/o+inahmaO44f0CVh+UHmaYSc8F41MprXGSFhPG6SOSeHVVLiv2yrmXyd4RZ773njDQxqurclm04Qh/+2w39S4PL6w8wJjUaM4f17whU259GFnxfXfKum8CTtNUwrfXHibaauQ3Z4/gaIXsVmhvcEvhbpn5kjoRBp0GU25irXE6C5aPozI/grNG2XrqIyi6gfLAFQEjPbb1GK1Nh8ppcGtMzowh0iL9hQ7j4BWHoeaYXJzUG+QC26qn4OFY+OTOxmMLd1IWPojVB8v43bkytc9X5Vla6yQu3MSQJJnZstIn4LbmI8t8AwjuW7yd2HATX981l0iLgXUHW5f7l9U6iQ3vuwt50Va5xnCkXAq1y+1h6Z4iThueiNWkx2KUX1r1znaqNfVG2bFx+LkUVNZRibx2Qweo0ElfRgm4ImDEhBkJNzX3rNccKEUnYEpmbBcEPEJOzoHGxcnxV8hGVenTYdt7snze5UAr3M6amiSGJEZw46wsrEY9xdUONE2jvNZJbISJxEgzURYDqw+UApAc3XwhbmCTL5zXbpzKwLgwMuLCmvfWRs6DLLc3EBfedz1wkCEsnwe+4VA5FfYGzhiZBECYSV57u7Oda9+Epp/fN6xY0TdRIRRFwBBCkB4b5p+S7vZofLuvhDGp0URajESaZb52uwuZpojGQh7f4uSce+S/Xf+FRVfJ6TuVeQhHFe84x3PFnIHodIKESDMlNQ6q6ly4PBpx4SaEEAxJimTjoXJiw02tmkUJIXj2qonYrEYy4mQMOSM2vFU+dWVdA26PRmwfF/C0GCu5pbXUOFwsWn8Eq1HPbG/82ur1wO0NnfdLOVJWx4AoC1//ci4RZiURfRnlgSsCyjljkjF5Gz39c0kOmw5XcI53+G2nHrivnN4aCxFJzfdlz5WtT/d+DmueoSZqEN94xjDOGwaJjzBRXO2g1JuHHuftjujxZpZcPzOzzYrHc8YkM3Nwo5eZHhtGXrkdt6cxI6XlOfsq6bFh7C2sYcyDX/DR5qNcNW2gX4AtRh1CdBBCacKRcjk1SIl330cJuCKg/Oy0ITxy6VgAnlqaw4zsOG6ZLSv9Ii2NHniNow0R91VjJo1qvchmjoShZ8GaZ+HYNr5NugadEIxIljHa+AjpgftywH3x6htnZRFpNnDdjMwu2T8wNowGt8aDH++gyFsAU1rjO2ffFnCffZoGA6Is3DKncYCxEAKrUY+9iYAv/j6vzfa+R8rsba5nKPoeSsAVASfaG6rwaDAtOxadToqxzwPffrSKCQ9/yer9pc1f6Cvmaa/vxrw/yayUAWN4v2EmgxIi/LFdGUJxsiVP9j/J8oZEzh+XwraH5vlt6gzfjMnX1xzilVW5AP6J70lRlvZe1ieYlCHnfb5+01RW/ea0VvZajXrqvCGUnMJq7lq0hStfXNvsGIfLzbGqen9KqKJvowRcEXBsTSbLpNoaFw4TIs0YdIL3N+XR4NbYmlfR/IW+cvr22pbGZMoBBVd/wLb8Gn9fbZAeeFmtk4+35DMiOYqBcd0ToKYLmx5vGCW3xN5qX19kenYcOx+ex+whbedtW016mQcOPLFEFjA53R5//jzAs8v2o2n4M3gUfRsl4IqAExPWGGpIa+LJWYx6RiRH+dP9ckubZ3s0euAdNIxKGoUnLIHC6nrSY5p/OYDsf3LumAHdtj3VZuUnc2XowdcEKre0lpRoiz8Vry/juyNpi6YhlK15Ff47ok2HZfOv/cU1PLkkh4snpHLWqO5fQ0XPoQRcEXBsTcIVLXtoTBho8z/ObTkfMyYTzNGyCrMDqh0uNK35EOD4iMYc7QvGpx6/0V50OsFvzh7BpIwYfxOogyW1ZMaHd/ucfYUwU2MIpbTGyTmjk9EJWOMNZa3YI/Pl7zpjaLcmDil6HvVbUgScKIsRIUAnZIOrpviKZ0B6ts0Yeznctb0xG6UdqrwDGaKbCbj0+icOtAVkAS4pyuwX8EOltf40w1DGYpQhFLvThd3pJiM+jMy4cPYVy9TNlTnFZMeHqwXMEKJTARdCvCyEKBJCbG9j391CCE0IobL9FX50OkG01ciAKAvGFp7clMxY9DrB8AGRFFTW+2Oy3hd2abalb6JOUw98fLqN+84ZwSvXTw3IZ0iMtFBY5aDS3kC5vYGs+NAXNZ8H7suqiQ83kxojByLXN7hZc6BU9T0JMbrigb8KnNVyoxAiHTgDOBxgmxT9gJgwU7P4t4/02DC++dUp/PTkQQCtqh67QlseuEGv45Y52V3ONumMAdEWahwuNh2R8eHMfuCBh5kN1DpcTVItTXKifUU9G3LLqW/w+NvtKkKDTgVc07SVQOtkUfgH8Cugk8GFih8iV00byBXT0tvcl2Kz+m/T8yvanuPYEb6hEFGWwIh1WyRFyZj63z/fQ4TZwLTsuKC9V08RYTJQ43A1K0xKtVkpqXHw1c5jmPQ6pveDz/lDolulVkKIHwFHNU3b0tk8PyHErcCtAAMHqqGoPxRunp3d4X6f99zuhJ4OqKqTRUCB8rbbIilSxu53FlTx05MHNfP2Q5Vwrwde4guhRJhJ8aZ5vrP+CJMzYzrMYlH0PY57EVMIEQbcB9zfleM1TXtB07TJmqZNTkhQ8TWFxC/gXZ0Q3wR/DNwSPLHxZZ0MSghnwdxBQXufniTCYqDW6aa4uokH7s0Scrg8nDIssTfNU3SD7vwFDAKyAJ/3nQZsEkJM1TTtWCCNU/RffDnIld0Q8Kr6BnQCwoPoLabYrKy77zTiw83+StJQJ8Is89jzyu1YjXrCTIZmhVbnjUvuLdMU3eS4/wI0TdsG+L+qhRC5wGRN0zoZLqhQNGI26LEYde1P6OmAyroGoqzGoAtrYmTfLp0/XiK83SAPldr9fVOapnm2bLer6Pt0KuBCiLeBk4F4IUQe8ICmaf8KtmGK/k+UxXjcIZQbXlnHsj3Ffb6svS8S7vXAD5Xa/XnzRr2O+88b6e+joggtOhVwTdOu6GR/ZsCsUfygiLYaj2sRU9M0lnmrBfvDomJP4wtb5VfWMazJpJ0bT8rqLZMUJ4iqxFT0GlFW43HFwJse62lrgryiQ3xrBppGn58upOgaSsAVvUaUxeBPCWzKFzuO8ct3twBwuNTO7mNyQk5+Rb3/mJzCmp4xsh8R3mRAQ1xE353vqeg6SsAVvUZUOyGUz7YV8P6mPOxOF3/4305+/vZmAAoq65q8VuUrHy+RTdIu4/v4dCFF11B/BYpeo71FzIPeNrOHy+zklddxpNyOpmnke9vQ/umi0apisBs09cD7+nQhRddQAq7oNeQipgtN05rNqzzk7VJ4uNROYVU9dqebqjoXBRV1GHSCy6cMRN9PcrN7kggVQul3qBCKoteIshpwezRqm3QkrLA7qbBLrzynqMbfeCm/so6CynqSoixKvLuJ2aDD4L12ahGzf6AEXNFr+JpRNQ2jHGoypafpwN2CyjryK+pIsfWv4pqeRAhBhDcOHq888H6BEnBFrxHVRkMr35CHcJOedQcbBTy/op79xTUMjA39tq69iS+VUMXA+wdKwBW9hm/y+ZJdRf5tPg98enZcs9DKmgOllNQ4mZhh61Eb+xsRZgORFgMmg/rT7w+o36Ki1xiTFs28UUk8tTTH3yEvt6SW5GgLMwY1ZplEmg38d2sBgCr5PkEiLAYVPulHKAFX9CoL5g6ivsHDxkNy8k1uaS0ZcWFcNKFxMPHw5May7yGJka3Ooeg6I5IjGZsW3dtmKAKEEnBFrzIiOQq9TrD9aCUgQyiZceHERZgZPiASq1HPXWcMRQg4e/QAlYFygvzxwjE8efmE3jZDESBUHriiV7EY9QxJjGB7fiVV9Q2U1jr9E+A/un0WLrdGuNnArodbjWVVKH7wKA9c0euMSolm+9FKDpXIBUzfBHizQe+vHrQY9ViM+l6zUaHoiygBV/Q6o1OjKKlxst6b953RDybAKxQ9gRJwRa+TFCWLc7Z54+BpMWoyjELRFZSAK3odX4+O/Io69DrRrGeHQqFoHyXgil7HF+curKonwmxo1thKoVC0jxJwRa/j61N9zCvgCoWiaygBV/Q6Pg+8vsHTbOiAQqHoGCXgil4nwtQo2soDVyi6jhJwRa8TbtY3eawEXKHoKkrAFb2OQa/DYpT/FSNUCEWh6DJKwBV9ggiz7A0eqTxwhaLLKAFX9AkivGEUFQNXKLqOEnBFn8AXOlEhFIWi6ygBV/QJfKO+lAeuUHQdJeCKPoEv/1vlgSsUXUcJuKJP4Esf9C1mKhSKzlECrugT+EInKgauUHQdJeCKPoFfwFUMXKHoMkrAFX0Cn3CrGLhC0XWUgCv6BL4YuCqlVyi6jvprUfQJ5o0eQEVdAynRlt42RaEIGTr1wIUQLwshioQQ25ts+7sQYrcQYqsQYrEQwhZUKxX9nlSblV+cMVQNc1AojoOuhFBeBc5qse0rYLSmaWOBvcBvAmyXQqFQKDqhUwHXNG0lUNZi25eaprm8T9cAaUGwTaFQKBQdEIhFzBuBzwJwHoVCoVAcByck4EKI+wAX8GYHx9wqhNgghNhQXFx8Im+nUCgUiiZ0W8CFENcB5wFXaZqmtXecpmkvaJo2WdO0yQkJCd19O4VCoVC0oFtphEKIs4BfA3M1TbMH1iSFQqFQdIWupBG+DawGhgkh8oQQNwFPA5HAV0KIzUKI54Jsp0KhUCha0KkHrmnaFW1s/lcQbFEoFArFcSA6CF8H/s2EKAYOdfPl8UBJAM3paZT9vUco2w7K/t6kr9ieoWlaq0XEHhXwE0EIsUHTtMm9bUd3Ufb3HqFsOyj7e5O+brtqZqVQKBQhihJwhUKhCFFCScBf6G0DThBlf+8RyraDsr836dO2h0wMXKFQKBTNCSUPXKFQKBRNUAKuUCgUIUpICLgQ4iwhxB4hxD4hxL29bU9nCCFyhRDbvFWqG7zbYoUQXwkhcrw/Y3rbTh/tDO1o114hxG+8v4s9Qoh5vWN1I+3Y/6AQ4qj3d7BZCHFOk319xn4hRLoQYpkQYpcQYocQ4ufe7SFx/TuwP1Suv0UIsU4IscVr/0Pe7SFx/dE0rU//A/TAfiAbMAFbgJG9bVcnNucC8S22PQLc6318L/C33raziW1zgInA9s7sBUZ6fwdmIMv7u9H3QfsfBO5u49g+ZT+QDEz0Po5EDkgZGSrXvwP7Q+X6CyDC+9gIrAWmh8r1DwUPfCqwT9O0A5qmOYF3gAt62abucAHwmvfxa8CFvWdKc7Q2hnbQvr0XAO9omubQNO0gsA/5O+o12rG/PfqU/ZqmFWiatsn7uBrYBaQSIte/A/vbo6/Zr2maVuN9avT+0wiR6x8KAp4KHGnyPI+O/4P0BTTgSyHERiHErd5tSZqmFYD8Tw8k9pp1XaM9e0Pp93G7d27ry01ugfus/UKITGAC0gsMuevfwn4IkesvhNALITYDRcBXmqaFzPUPBQFva8ptX899nKVp2kTgbOA2IcSc3jYogITK72MhMAgYDxQAj3m390n7hRARwPvAnZqmVXV0aBvb+qL9IXP9NU1za5o2HjkacqoQYnQHh/cp+0NBwPOA9CbP04D8XrKlS2ialu/9WQQsRt5iFQohkgG8P4t6z8Iu0Z69IfH70DSt0PuH6QFepPE2t8/ZL4QwIsXvTU3TPvBuDpnr35b9oXT9fWiaVgEsRw5xD4nrHwoCvh4YIoTIEkKYgMuBj3vZpnYRQoQLISJ9j4Ezge1Im6/zHnYd8FHvWNhl2rP3Y+ByIYRZCJEFDAHW9YJ9HeL74/NyEfJ3AH3MfiGEQLZn3qVp2uNNdoXE9W/P/hC6/glCCJv3sRU4HdhNiFz/Xlk57cZK8TnI1e39wH29bU8ntmYjV6m3ADt89gJxwBIgx/sztrdtbWLz28jb3Aakh3FTR/YC93l/F3uAs/uo/a8D24CtyD+65L5oP3AS8hZ8K7DZ+++cULn+HdgfKtd/LPC9187twP3e7SFx/VUpvUKhUIQooRBCUSgUCkUbKAFXKBSKEEUJuEKhUIQoSsAVCoUiRFECrlAoFCGKEnCFQqEIUZSAKxQKRYjy/4StZCxS5+yzAAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(pred_inver[:, 0, :], label='Prediction')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1762\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Smape of LSTM:  0.07599279782440131\n","Smape of Informer:  0.026172610981077205\n","Smape of Ensemble:  0.022894770106142305\n"]}],"source":["setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, 0)\n","                \n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","flag = 'pred'\n","\n","if flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)\n","\n","# get the inverse transformed\n","pred_inver = data_set.inverse_transform(preds)\n","trues = data_set.inverse_transform(trues)\n","\n","lstm_preds = np.load('./bac.npy')\n","# drop the last 13 sample\n","lstm_preds = lstm_preds[:-13, :]\n","\n","informer_preds = pred_inver[:, 0, :]\n","\n","\n","# average the predictions of Informer and LSTM\n","ensemble_preds = (0.5*lstm_preds + 1.5*informer_preds) / 2\n","ensemble_preds.shape\n","\n","plt.figure()\n","plt.plot(trues[:, 0, :], label='GroundTruth')\n","plt.plot(ensemble_preds, label='Prediction')\n","plt.legend()\n","plt.show()\n","\n","print(\"Smape of LSTM: \", SMAPE(lstm_preds, trues[:, 0, :]))\n","print(\"Smape of Informer: \", SMAPE(informer_preds, trues[:, 0, :]))\n","print(\"Smape of Ensemble: \", SMAPE(ensemble_preds, trues[:, 0, :]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
