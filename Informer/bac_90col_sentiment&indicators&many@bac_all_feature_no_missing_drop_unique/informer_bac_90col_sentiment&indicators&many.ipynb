{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1665469219912,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"8jKmRZd6Kgt7","outputId":"6944f0e3-7138-41a2-8f38-4ebeace1254e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.9.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469209225,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"l--MmZAZKiBt","outputId":"ec6f28ba-6b30-41fe-f86c-6b095d1d6c43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Nov  1 13:17:56 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P40           On   | 00000000:01:00.0 Off |                    0 |\n","| N/A   53C    P0    51W / 250W |   8938MiB / 23040MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A       994      G   /usr/lib/xorg/Xorg                 95MiB |\n","|    0   N/A  N/A      1163      G   /usr/bin/gnome-shell               13MiB |\n","|    0   N/A  N/A      4923      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      5098      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      6441      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      6779      C   ...sean/anaconda3/bin/python     1558MiB |\n","|    0   N/A  N/A      7088      C   ...sean/anaconda3/bin/python     2594MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXwkNV16NBYJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"x0gb4vhQNIV9"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"3-_EwnEwNIV-"},"source":["## masking"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1645,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"BQVaV-ZSNIV_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"]},{"cell_type":"markdown","metadata":{"id":"5DXqesX3NIWA"},"source":["## metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469586621,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"DJphxr1hNIWB"},"outputs":[],"source":["import numpy as np\n","\n","def RSE(pred, true):\n","    return np.sqrt(np.sum((true-pred)**2)) / np.sqrt(np.sum((true-true.mean())**2))\n","\n","def CORR(pred, true):\n","    u = ((true-true.mean(0))*(pred-pred.mean(0))).sum(0) \n","    d = np.sqrt(((true-true.mean(0))**2*(pred-pred.mean(0))**2).sum(0))\n","    return (u/d).mean(-1)\n","\n","def MAE(pred, true):\n","    return np.mean(np.abs(pred-true))\n","\n","def MSE(pred, true):\n","    return np.mean((pred-true)**2)\n","\n","def RMSE(pred, true):\n","    return np.sqrt(MSE(pred, true))\n","\n","def MAPE(pred, true):\n","    return np.mean(np.abs((pred - true) / true))\n","\n","def MSPE(pred, true):\n","    return np.mean(np.square((pred - true) / true))\n","\n","def SMAPE(pred, true):\n","    return np.mean(np.abs(pred - true) / (np.abs(pred) + np.abs(true)/2))\n","\n","def metric(pred, true):\n","    mae = MAE(pred, true)\n","    mse = MSE(pred, true)\n","    rmse = RMSE(pred, true)\n","    mape = MAPE(pred, true)\n","    mspe = MSPE(pred, true)\n","    smape = SMAPE(pred, true)\n","    \n","    return mae,mse,rmse,mape,mspe,smape\n","\n","# def divide_no_nan(a, b):\n","#     \"\"\"\n","#     Auxiliary funtion to handle divide by 0\n","#     \"\"\"\n","#     div = a / b\n","#     div[div != div] = 0.0\n","#     div[div == float('inf')] = 0.0\n","#     return div\n","\n","# def SMAPELoss(y, y_hat, mask=None):\n","#     \"\"\"SMAPE2 Loss\n","#     Parameters\n","#     ----------\n","#     y: tensor (batch_size, output_size)\n","#         actual values in torch tensor.\n","#     y_hat: tensor (batch_size, output_size)\n","#         predicted values in torch tensor.\n","\n","#     \"\"\"\n","#     if mask is None:\n","#         mask = torch.ones(y_hat.size())\n","#     delta_y = torch.abs((y - y_hat))\n","#     scale = torch.abs(y) + torch.abs(y_hat)\n","#     smape = divide_no_nan(delta_y, scale)\n","#     smape = smape * mask\n","#     smape = 2 * torch.mean(smape)\n","#     return "]},{"cell_type":"markdown","metadata":{"id":"WEMqIOORNIWC"},"source":["## timefeatures"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1665469587802,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bH2peHltNIWD"},"outputs":[],"source":["from typing import List\n","\n","import pandas as pd\n","from pandas.tseries import offsets\n","from pandas.tseries.frequencies import to_offset\n","\n","class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class SecondOfMinute(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.second / 59.0 - 0.5\n","\n","class MinuteOfHour(TimeFeature):\n","    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.minute / 59.0 - 0.5\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","class MonthOfYear(TimeFeature):\n","    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.month - 1) / 11.0 - 0.5\n","\n","class WeekOfYear(TimeFeature):\n","    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.week - 1) / 52.0 - 0.5\n","\n","def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n","    \"\"\"\n","    Returns a list of time features that will be appropriate for the given frequency string.\n","    Parameters\n","    ----------\n","    freq_str\n","        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n","    \"\"\"\n","\n","    features_by_offsets = {\n","        offsets.YearEnd: [],\n","        offsets.QuarterEnd: [MonthOfYear],\n","        offsets.MonthEnd: [MonthOfYear],\n","        offsets.Week: [DayOfMonth, WeekOfYear],\n","        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n","        offsets.Minute: [\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","        offsets.Second: [\n","            SecondOfMinute,\n","            MinuteOfHour,\n","            HourOfDay,\n","            DayOfWeek,\n","            DayOfMonth,\n","            DayOfYear,\n","        ],\n","    }\n","\n","    offset = to_offset(freq_str)\n","\n","    for offset_type, feature_classes in features_by_offsets.items():\n","        if isinstance(offset, offset_type):\n","            return [cls() for cls in feature_classes]\n","\n","    supported_freq_msg = f\"\"\"\n","    Unsupported frequency {freq_str}\n","    The following frequencies are supported:\n","        Y   - yearly\n","            alias: A\n","        M   - monthly\n","        W   - weekly\n","        D   - daily\n","        B   - business days\n","        H   - hourly\n","        T   - minutely\n","            alias: min\n","        S   - secondly\n","    \"\"\"\n","    raise RuntimeError(supported_freq_msg)\n","\n","def time_features(dates, timeenc=1, freq='h'):\n","    \"\"\"\n","    > `time_features` takes in a `dates` dataframe with a 'dates' column and extracts the date down to `freq` where freq can be any of the following if `timeenc` is 0: \n","    > * m - [month]\n","    > * w - [month]\n","    > * d - [month, day, weekday]\n","    > * b - [month, day, weekday]\n","    > * h - [month, day, weekday, hour]\n","    > * t - [month, day, weekday, hour, *minute]\n","    > \n","    > If `timeenc` is 1, a similar, but different list of `freq` values are supported (all encoded between [-0.5 and 0.5]): \n","    > * Q - [month]\n","    > * M - [month]\n","    > * W - [Day of month, week of year]\n","    > * D - [Day of week, day of month, day of year]\n","    > * B - [Day of week, day of month, day of year]\n","    > * H - [Hour of day, day of week, day of month, day of year]\n","    > * T - [Minute of hour*, hour of day, day of week, day of month, day of year]\n","    > * S - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year]\n","\n","    *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n","    \"\"\"\n","    if timeenc==0:\n","        dates['month'] = dates.date.apply(lambda row:row.month,1)\n","        dates['day'] = dates.date.apply(lambda row:row.day,1)\n","        dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n","        dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n","        dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n","        dates['minute'] = dates.minute.map(lambda x:x//15)\n","        freq_map = {\n","            'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n","            'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n","            't':['month','day','weekday','hour','minute'],\n","        }\n","        return dates[freq_map[freq.lower()]].values\n","    if timeenc==1:\n","        dates = pd.to_datetime(dates.date.values)\n","        return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)]).transpose(1,0)\n"]},{"cell_type":"markdown","metadata":{"id":"WEn9yTj-NIWE"},"source":["## tools"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"rvjENJo0NIWF"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, args):\n","    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n","    if args.lradj=='type1':\n","        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n","    elif args.lradj=='type2':\n","        lr_adjust = {\n","            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n","            10: 5e-7, 15: 1e-7, 20: 5e-8\n","        }\n","    if epoch in lr_adjust.keys():\n","        lr = lr_adjust[epoch]\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","        print('Updating learning rate to {}'.format(lr))\n","\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n","        self.val_loss_min = val_loss\n","\n","class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean"]},{"cell_type":"markdown","metadata":{"id":"KiYyHfUiHBbA"},"source":["# models"]},{"cell_type":"markdown","metadata":{"id":"UH3R2NVkHBbB"},"source":["## atten.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587803,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"ZYDX5sjnHBbC"},"outputs":[],"source":["from math import sqrt\n","\n","class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn\n"]},{"cell_type":"markdown","metadata":{"id":"FrprJAG1HFlp"},"source":["## decoder"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9MnNLJZEHIvW"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"HSSrVEBWHQJV"},"source":["## embed"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"nPHq_OsoHRYn"},"outputs":[],"source":["import math\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        hour_x = self.hour_embed(x[:,:,3])\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        day_x = self.day_embed(x[:,:,1])\n","        month_x = self.month_embed(x[:,:,0])\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"iyMtsCEWHWXZ"},"source":["## encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"bqOhEHsnHW1F"},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","class EncoderStack(nn.Module):\n","    def __init__(self, encoders, inp_lens):\n","        super(EncoderStack, self).__init__()\n","        self.encoders = nn.ModuleList(encoders)\n","        self.inp_lens = inp_lens\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        x_stack = []; attns = []\n","        for i_len, encoder in zip(self.inp_lens, self.encoders):\n","            inp_len = x.shape[1]//(2**i_len)\n","            x_s, attn = encoder(x[:, -inp_len:, :])\n","            x_stack.append(x_s); attns.append(attn)\n","        x_stack = torch.cat(x_stack, -2)\n","        \n","        return x_stack, attns\n"]},{"cell_type":"markdown","metadata":{"id":"cr0L8sQBHcUZ"},"source":["## model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665469587804,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qhvqSrONHdLg"},"outputs":[],"source":["class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n","\n","\n","class InformerStack(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n","                factor=5, d_model=512, n_heads=8, e_layers=[3,2,1], d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu',\n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(InformerStack, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","\n","        inp_lens = list(range(len(e_layers))) # [0,1,2,...] you can customize here\n","        encoders = [\n","            Encoder(\n","                [\n","                    EncoderLayer(\n","                        AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                    d_model, n_heads, mix=False),\n","                        d_model,\n","                        d_ff,\n","                        dropout=dropout,\n","                        activation=activation\n","                    ) for l in range(el)\n","                ],\n","                [\n","                    ConvLayer(\n","                        d_model\n","                    ) for l in range(el-1)\n","                ] if distil else None,\n","                norm_layer=torch.nn.LayerNorm(d_model)\n","            ) for el in e_layers]\n","        self.encoder = EncoderStack(encoders, inp_lens)\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]\n"]},{"cell_type":"markdown","metadata":{"id":"zpHjnFKYIG14"},"source":["# data"]},{"cell_type":"markdown","metadata":{"id":"O7bJTCetIJPQ"},"source":["## data_loader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TjTpmD0VIHwJ"},"outputs":[],"source":["import os\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","# from sklearn.preprocessing import StandardScaler\n","\n","# from utils.tools import StandardScaler\n","# from utils.timefeatures import time_features\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Dataset_ETT_hour(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24 - self.seq_len, 12*30*24+4*30*24 - self.seq_len]\n","        border2s = [12*30*24, 12*30*24+4*30*24, 12*30*24+8*30*24]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTm1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='t', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        \n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12*30*24*4 - self.seq_len, 12*30*24*4+4*30*24*4 - self.seq_len]\n","        border2s = [12*30*24*4, 12*30*24*4+4*30*24*4, 12*30*24*4+8*30*24*4]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","        \n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","\n","class Dataset_Custom(Dataset):\n","    def __init__(self, root_path, flag='train', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='h', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        # cols = list(df_raw.columns); \n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","\n","        num_train = int(len(df_raw)*0.7)\n","        num_test = int(len(df_raw)*0.2)\n","        num_vali = len(df_raw) - num_train - num_test\n","        border1s = [0, num_train-self.seq_len, len(df_raw)-num_test-self.seq_len]\n","        border2s = [num_train, num_train+num_vali, len(df_raw)]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq)\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n","\n","class Dataset_Pred(Dataset):\n","    def __init__(self, root_path, flag='pred', size=None, \n","                 features='S', data_path='ETTh1.csv', \n","                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24*4*4\n","            self.label_len = 24*4\n","            self.pred_len = 24*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['pred']\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.freq = freq\n","        self.cols=cols\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","        '''\n","        df_raw.columns: ['date', ...(other features), target feature]\n","        '''\n","        if self.cols:\n","            cols=self.cols.copy()\n","            cols.remove(self.target)\n","        else:\n","            cols = list(df_raw.columns); cols.remove(self.target); cols.remove('date')\n","        df_raw = df_raw[['date']+cols+[self.target]]\n","        print(len(df_raw))\n","        print(self.seq_len)\n","        \n","        border1 = len(df_raw)-self.seq_len\n","        border2 = len(df_raw)\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df_raw.columns[1:]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            self.scaler.fit(df_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        tmp_stamp = df_raw[['date']][border1:border2]\n","        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n","        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n","        print(pred_dates)\n","        \n","        df_stamp = pd.DataFrame(columns = ['date'])\n","        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n","        data_stamp = time_features(df_stamp, timeenc=self.timeenc, freq=self.freq[-1:])\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = self.data_x[r_begin:r_begin+self.label_len]\n","        else:\n","            seq_y = self.data_y[r_begin:r_begin+self.label_len]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)\n"]},{"cell_type":"markdown","metadata":{"id":"IUuBwAKpIQ24"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"3qOgjpZfISte"},"source":["## exp_basic"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589184,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"qGfCDssuIRiT"},"outputs":[],"source":["class Exp_Basic(object):\n","    def __init__(self, args):\n","        self.args = args\n","        self.device = self._acquire_device()\n","        self.model = self._build_model().to(self.device)\n","\n","    def _build_model(self):\n","        raise NotImplementedError\n","        return None\n","    \n","    def _acquire_device(self):\n","        if self.args.use_gpu:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n","            device = torch.device('cuda:{}'.format(self.args.gpu))\n","            print('Use GPU: cuda:{}'.format(self.args.gpu))\n","        else:\n","            device = torch.device('cpu')\n","            print('Use CPU')\n","        return device\n","\n","    def _get_data(self):\n","        pass\n","\n","    def vali(self):\n","        pass\n","\n","    def train(self):\n","        pass\n","\n","    def test(self):\n","        pass\n","    "]},{"cell_type":"markdown","metadata":{"id":"F83xFE3dJdBE"},"source":["## exp_informer"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665469589185,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"Qv9nHM78JdrH"},"outputs":[],"source":["from torch import optim\n","from torch.utils.data import DataLoader\n","import time\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class Exp_Informer(Exp_Basic):\n","    def __init__(self, args):\n","        super(Exp_Informer, self).__init__(args)\n","    \n","    def _build_model(self):\n","        model_dict = {\n","            'informer':Informer,\n","            'informerstack':InformerStack,\n","        }\n","        if self.args.model=='informer' or self.args.model=='informerstack':\n","            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n","            model = model_dict[self.args.model](\n","                self.args.enc_in,\n","                self.args.dec_in, \n","                self.args.c_out, \n","                self.args.seq_len, \n","                self.args.label_len,\n","                self.args.pred_len, \n","                self.args.factor,\n","                self.args.d_model, \n","                self.args.n_heads, \n","                e_layers, # self.args.e_layers,\n","                self.args.d_layers, \n","                self.args.d_ff,\n","                self.args.dropout, \n","                self.args.attn,\n","                self.args.embed,\n","                self.args.freq,\n","                self.args.activation,\n","                self.args.output_attention,\n","                self.args.distil,\n","                self.args.mix,\n","                self.device\n","            ).float()\n","        \n","        if self.args.use_multi_gpu and self.args.use_gpu:\n","            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n","        return model\n","\n","    def _get_data(self, flag):\n","        args = self.args\n","\n","        data_dict = {\n","            'ETTh1':Dataset_ETT_hour,\n","            'ETTh2':Dataset_ETT_hour,\n","            'ETTm1':Dataset_ETT_minute,\n","            'ETTm2':Dataset_ETT_minute,\n","            'WTH':Dataset_Custom,\n","            'ECL':Dataset_Custom,\n","            'Solar':Dataset_Custom,\n","            'custom':Dataset_Custom,\n","        }\n","        Data = data_dict[self.args.data]\n","        timeenc = 0 if args.embed!='timeF' else 1\n","\n","        if flag == 'test':\n","            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        elif flag=='pred':\n","            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n","            Data = Dataset_Pred\n","        else:\n","            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n","        data_set = Data(\n","            root_path=args.root_path,\n","            data_path=args.data_path,\n","            flag=flag,\n","            size=[args.seq_len, args.label_len, args.pred_len],\n","            features=args.features,\n","            target=args.target,\n","            inverse=args.inverse,\n","            timeenc=timeenc,\n","            freq=freq,\n","            cols=args.cols\n","        )\n","        print(flag, len(data_set))\n","        data_loader = DataLoader(\n","            data_set,\n","            batch_size=batch_size,\n","            shuffle=shuffle_flag,\n","            num_workers=args.num_workers,\n","            drop_last=drop_last)\n","\n","        return data_set, data_loader\n","\n","    def _select_optimizer(self):\n","        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        return model_optim\n","    \n","    def _select_criterion(self):\n","        criterion =  nn.MSELoss()\n","        return criterion\n","\n","    def vali(self, vali_data, vali_loader, criterion):\n","        self.model.eval()\n","        total_loss = []\n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n","            pred, true = self._process_one_batch(\n","                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n","            total_loss.append(loss)\n","        total_loss = np.average(total_loss)\n","        self.model.train()\n","        return total_loss\n","\n","    def train(self, setting):\n","        train_data, train_loader = self._get_data(flag = 'train')\n","        vali_data, vali_loader = self._get_data(flag = 'val')\n","        test_data, test_loader = self._get_data(flag = 'test')\n","\n","        path = os.path.join(self.args.checkpoints, setting)\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","\n","        time_now = time.time()\n","        \n","        train_steps = len(train_loader)\n","        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","        \n","        model_optim = self._select_optimizer()\n","        criterion =  self._select_criterion()\n","\n","        if self.args.use_amp:\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","        for epoch in range(self.args.train_epochs):\n","            iter_count = 0\n","            train_loss = []\n","            \n","            self.model.train()\n","            epoch_time = time.time()\n","            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n","                iter_count += 1\n","                \n","                model_optim.zero_grad()\n","                pred, true = self._process_one_batch(\n","                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","                loss = criterion(pred, true)\n","                train_loss.append(loss.item())\n","                \n","                if (i+1) % 100==0:\n","                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                    speed = (time.time()-time_now)/iter_count\n","                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n","                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                    iter_count = 0\n","                    time_now = time.time()\n","                \n","                if self.args.use_amp:\n","                    scaler.scale(loss).backward()\n","                    scaler.step(model_optim)\n","                    scaler.update()\n","                else:\n","                    loss.backward()\n","                    model_optim.step()\n","\n","            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n","            train_loss = np.average(train_loss)\n","            vali_loss = self.vali(vali_data, vali_loader, criterion)\n","            test_loss = self.vali(test_data, test_loader, criterion)\n","\n","            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","            early_stopping(vali_loss, self.model, path)\n","            if early_stopping.early_stop:\n","                print(\"Early stopping\")\n","                break\n","\n","            adjust_learning_rate(model_optim, epoch+1, self.args)\n","            \n","        best_model_path = path+'/'+'checkpoint.pth'\n","        self.model.load_state_dict(torch.load(best_model_path))\n","        \n","        return self.model\n","\n","    def test(self, setting):\n","        test_data, test_loader = self._get_data(flag='test')\n","        \n","        self.model.eval()\n","        \n","        preds = []\n","        trues = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n","            pred, true = self._process_one_batch(\n","                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","            trues.append(true.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        trues = np.array(trues)\n","        print('test shape:', preds.shape, trues.shape)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","        print('test shape:', preds.shape, trues.shape)\n","\n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","\n","        mae, mse, rmse, mape, mspe, smape = metric(preds, trues)\n","        print('mse:{}, mae:{}, smape:{}'.format(mse, mae, smape))\n","\n","        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe, smape]))\n","        np.save(folder_path+'pred.npy', preds)\n","        np.save(folder_path+'true.npy', trues)\n","\n","        return\n","\n","    def predict(self, setting, load=False):\n","        pred_data, pred_loader = self._get_data(flag='pred')\n","        \n","        if load:\n","            path = os.path.join(self.args.checkpoints, setting)\n","            best_model_path = path+'/'+'checkpoint.pth'\n","            self.model.load_state_dict(torch.load(best_model_path))\n","\n","        self.model.eval()\n","        \n","        preds = []\n","        \n","        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n","            pred, true = self._process_one_batch(\n","                pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n","            preds.append(pred.detach().cpu().numpy())\n","\n","        preds = np.array(preds)\n","        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","        \n","        # result save\n","        folder_path = './results/' + setting +'/'\n","        if not os.path.exists(folder_path):\n","            os.makedirs(folder_path)\n","        \n","        np.save(folder_path+'real_prediction.npy', preds)\n","        \n","        return\n","\n","    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n","        batch_x = batch_x.float().to(self.device)\n","        batch_y = batch_y.float()\n","\n","        batch_x_mark = batch_x_mark.float().to(self.device)\n","        batch_y_mark = batch_y_mark.float().to(self.device)\n","\n","        # decoder input\n","        if self.args.padding==0:\n","            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        elif self.args.padding==1:\n","            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n","        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n","        # encoder - decoder\n","        if self.args.use_amp:\n","            with torch.cuda.amp.autocast():\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        else:\n","            if self.args.output_attention:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","            else:\n","                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","        if self.args.inverse:\n","            outputs = dataset_object.inverse_transform(outputs)\n","        f_dim = -1 if self.args.features=='MS' else 0\n","        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n","\n","        return outputs, batch_y\n"]},{"cell_type":"markdown","metadata":{"id":"PWVRIjPFJnjH"},"source":["# Informer2020"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# df_bac_indicators = pd.read_csv('/home/sean/5703/informer/data/bac_full_indicators.csv')\n","\n","# df_bac_sentiment = pd.read_csv('/home/sean/5703/informer/data/BAC_with_sentiment_1762_rows.csv')\n","\n","# # drop open, close, high, low, volume in df_bac_sentiment\n","# df_bac_sentiment = df_bac_sentiment.drop(['open', 'close', 'high', 'low', 'volume'], axis=1)\n","\n","\n","# # merge df_bac_indicators and df_bac_sentiment\n","# df_bac_sent_ind = pd.merge(df_bac_indicators, df_bac_sentiment, on='date')\n","\n","# df_bac_sent_ind.to_csv('/home/sean/5703/informer/data/bac_sent_ind.csv', index=False)\n","\n","#-----------------------------------------------------------#\n","# df_bac_sent_ind = pd.read_csv('/home/sean/5703/informer/data/bac_sent_ind.csv')\n","# # move the column 'Close' to the last column\n","# cols = list(df_bac_sent_ind.columns.values)\n","# cols.pop(cols.index('close'))\n","# df_bac_sent_ind = df_bac_sent_ind[cols+['close']]\n","# df_bac_sent_ind.to_csv('/home/sean/5703/informer/data/bac_sent_ind.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"uuJaK1sRJzK9"},"source":["## code"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469917066,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"cF_u9sCiJ-uO"},"outputs":[],"source":["args = dotdict()\n","\n","args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n","\n","args.data = 'custom' # data\n","args.root_path = '../../../../5703/dataset'\n","args.data_path = 'bac_all_feature_no_missing_drop_unique.csv'\n","args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n","args.target = 'close'\n","args.freq = 'b'\n","args.checkpoints = './informer_checkpoints' # location of model checkpoints\n","\n","args.seq_len = 270 # input sequence length of Informer encoder\n","args.label_len = 7 # start token length of Informer decoder\n","args.pred_len = 14 # prediction sequence length\n","# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n","\n","#----------------------------------------#\n","# number of columns minus 1\n","args.enc_in = 70 # encoder input size\n","args.dec_in = 70 # decoder input size\n","args.c_out = 1 # output size\n","#----------------------------------------#\n","\n","args.factor = 5 # probsparse attn factor\n","args.d_model = 1024 # dimension of model\n","args.n_heads = 64 # num of heads\n","args.e_layers = 2 # num of encoder layers\n","args.d_layers = 1 # num of decoder layers\n","args.d_ff = 2048 # dimension of fcn in model\n","args.dropout = 0.05 # dropout\n","args.attn = 'full' # attention used in encoder, options:[prob, full]\n","args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n","args.activation = 'gelu' # activation\n","args.distil = True # whether to use distilling in encoder\n","args.output_attention = False # whether to output attention in ecoder\n","args.mix = True\n","args.padding = 0\n","args.freq = 'b'\n","# args.inverse = True\n","\n","args.batch_size = 32\n","args.learning_rate = 0.0001\n","args.loss = 'mse'\n","args.lradj = 'type1'\n","args.use_amp = False # whether to use automatic mixed precision training\n","\n","args.num_workers = 0\n","args.itr = 1\n","args.train_epochs = 12\n","args.patience = 4\n","args.des = 'exp'\n","\n","args.use_gpu = True if torch.cuda.is_available() else False\n","args.gpu = 0\n","\n","args.use_multi_gpu = False\n","args.devices = '0,1,2,3'\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469918956,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eQxRec9POM0k"},"outputs":[],"source":["Data = Dataset_Custom\n","timeenc = 0 if args.embed!='timeF' else 1\n","flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n","\n","data_set = Data(\n","    root_path=args.root_path,\n","    data_path=args.data_path,\n","    flag=flag,\n","    size=[args.seq_len, args.label_len, args.pred_len],\n","    features=args.features,\n","    timeenc=timeenc,\n","    target=args.target, # HULL here\n","    freq=args.freq # 'h': hourly, 't':minutely\n",")\n","data_loader = DataLoader(\n","    data_set,\n","    batch_size=batch_size,\n","    shuffle=shuffle_flag,\n","    num_workers=args.num_workers,\n","    drop_last=drop_last)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665469920450,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"eXd28rvGKBcK","outputId":"8544d098-8ee1-4155-a7c6-122052c1130a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Args in experiment:\n","{'model': 'informer', 'data': 'custom', 'root_path': '../../../../5703/dataset', 'data_path': 'bac_all_feature_no_missing_drop_unique.csv', 'features': 'MS', 'target': 'close', 'freq': 'b', 'checkpoints': './informer_checkpoints', 'seq_len': 270, 'label_len': 7, 'pred_len': 14, 'enc_in': 70, 'dec_in': 70, 'c_out': 1, 'factor': 5, 'd_model': 1024, 'n_heads': 64, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 12, 'patience': 4, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'b'}\n"]}],"source":["args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n","\n","if args.use_gpu and args.use_multi_gpu:\n","    args.devices = args.devices.replace(' ','')\n","    device_ids = args.devices.split(',')\n","    args.device_ids = [int(id_) for id_ in device_ids]\n","    args.gpu = args.device_ids[0]\n","\n","args.detail_freq = args.freq\n","args.freq = args.freq[-1:]\n","\n","print('Args in experiment:')\n","print(args)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import random\n","def seed_everything(seed: int):   \n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","seed_everything(666)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":89640,"status":"ok","timestamp":1665470010782,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"hHtNp4qVKHxa","outputId":"3ddc9739-e3dc-4c46-c11f-bb6a646824ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n",">>>>>>>start training : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n","train 425\n","val 89\n","test 189\n","Epoch: 1 cost time: 4.224782705307007\n","Epoch: 1, Steps: 13 | Train Loss: 0.7511227 Vali Loss: 1.1319997 Test Loss: 0.7393566\n","Validation loss decreased (inf --> 1.132000).  Saving model ...\n","Updating learning rate to 0.0001\n","Epoch: 2 cost time: 3.2552239894866943\n","Epoch: 2, Steps: 13 | Train Loss: 0.1834734 Vali Loss: 0.7955751 Test Loss: 0.7096928\n","Validation loss decreased (1.132000 --> 0.795575).  Saving model ...\n","Updating learning rate to 5e-05\n","Epoch: 3 cost time: 3.2483749389648438\n","Epoch: 3, Steps: 13 | Train Loss: 0.1229814 Vali Loss: 1.0411630 Test Loss: 0.8049842\n","EarlyStopping counter: 1 out of 4\n","Updating learning rate to 2.5e-05\n","Epoch: 4 cost time: 3.241154432296753\n","Epoch: 4, Steps: 13 | Train Loss: 0.1147888 Vali Loss: 0.8437313 Test Loss: 0.7440363\n","EarlyStopping counter: 2 out of 4\n","Updating learning rate to 1.25e-05\n","Epoch: 5 cost time: 3.2401232719421387\n","Epoch: 5, Steps: 13 | Train Loss: 0.1059198 Vali Loss: 0.8741761 Test Loss: 0.7230611\n","EarlyStopping counter: 3 out of 4\n","Updating learning rate to 6.25e-06\n","Epoch: 6 cost time: 3.2392826080322266\n","Epoch: 6, Steps: 13 | Train Loss: 0.1049619 Vali Loss: 0.8577930 Test Loss: 0.6916745\n","EarlyStopping counter: 4 out of 4\n","Early stopping\n",">>>>>>>testing : informer_custom_ftMS_sl270_ll7_pl14_dm1024_nh64_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","test 189\n","test shape: (5, 32, 14, 1) (5, 32, 14, 1)\n","test shape: (160, 14, 1) (160, 14, 1)\n","mse:0.7096928358078003, mae:0.6718194484710693, smape:1.015067458152771\n"]}],"source":["Exp = Exp_Informer\n","for ii in range(args.itr):\n","    # setting record of experiments\n","    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n","                args.seq_len, args.label_len, args.pred_len,\n","                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n","\n","    # set experiments\n","    exp = Exp(args)\n","    \n","    # train\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    exp.train(setting)\n","    \n","    # test\n","    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","    exp.test(setting)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bAggQpbtUgoC"},"source":["# Prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1665470015210,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"EUWgSjtiUj0V","outputId":"49dc4706-8eb0-404b-ffab-ea77007f9566"},"outputs":[{"name":"stdout","output_type":"stream","text":["Use GPU: cuda:0\n","1012\n","270\n","DatetimeIndex(['2016-12-30', '2017-01-02', '2017-01-03', '2017-01-04',\n","               '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10',\n","               '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16',\n","               '2017-01-17', '2017-01-18', '2017-01-19'],\n","              dtype='datetime64[ns]', freq='B')\n","pred 1\n"]}],"source":["# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n","# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n","# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n","\n","exp = Exp(args)\n","\n","exp.predict(setting, True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"G_PEvsjSUuWC","outputId":"605209ef-4bd3-4c17-d4b8-b7f1e7793ddb"},"outputs":[{"data":{"text/plain":["(1, 14, 1)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# the prediction will be saved in ./results/{setting}/real_prediction.npy\n","\n","prediction = np.load('./results/'+setting+'/real_prediction.npy')\n","\n","prediction.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470015637,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"uEHQLTV4Ujnj","outputId":"4a036033-165c-4b6b-b791-b5ab0137b028"},"outputs":[],"source":["# prediction\n"]},{"cell_type":"markdown","metadata":{"id":"1FcUJPRBQvMu"},"source":["# Visualization"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470016903,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"9x1gDSgWQmV2","outputId":"f5dc7093-80b6-4286-f2e5-18844f6dff81"},"outputs":[{"data":{"text/plain":["((160, 14, 1), (160, 14, 1))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n","# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n","\n","preds = np.load('./results/'+setting+'/pred.npy')\n","trues = np.load('./results/'+setting+'/true.npy')\n","\n","# [samples, pred_len, dimensions]\n","preds.shape, trues.shape"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470017507,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"CmqVKPLOOM0n","outputId":"c9b67a4c-5021-4c58-826e-229bf0267be8"},"outputs":[{"data":{"text/plain":["array([-1.1544745 , -1.1029882 , -0.8798809 , -0.85127735, -0.897043  ,\n","       -0.9771328 , -0.94280857, -0.9771328 , -1.0915468 , -1.0572226 ,\n","       -1.0343398 , -1.011457  , -1.0400605 , -1.2231228 ], dtype=float32)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trues[0,:,-1]"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665470018724,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"_KWBtvfSOM0o","outputId":"f54ef57e-f565-4795-840e-d8fddcd90c24"},"outputs":[{"data":{"text/plain":["array([-0.660506  ,  0.33163786, -0.64704144, -0.20595197, -0.57585484,\n","        0.0684288 ,  0.68141794,  0.50473183,  0.18069291, -0.2883299 ,\n","       -0.35951802,  0.48192823,  0.12418197,  0.04251476], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["preds[0,:,-1,]"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665470022376,"user":{"displayName":"Shang Gao","userId":"16905850390448805839"},"user_tz":-480},"id":"TnN-s__UQ4lr","outputId":"3796b474-f360-4e61-909f-c3e0b4a0705c"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","plt.plot(trues[:, -1, :], label='GroundTruth')\n","plt.plot(preds[:, -1, :], label='Prediction')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vr-HMEUyRMsX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["x0gb4vhQNIV9","3-_EwnEwNIV-","KiYyHfUiHBbA","UH3R2NVkHBbB","FrprJAG1HFlp","HSSrVEBWHQJV","iyMtsCEWHWXZ","zpHjnFKYIG14","O7bJTCetIJPQ","2EYUbEKzJogc"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.7 ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0edef247045f2f5f35ac9d6435770b0c68a1ddd7eb34b4959830e587ac51e2"}}},"nbformat":4,"nbformat_minor":0}
